<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 2.4.0">
  <meta name="generator" content="Hugo 0.66.0" />
  <meta name="author" content="A. Solomon Kurz">

  
  
  
  
    
  
  <meta name="description" content="A colleague reached out to me earlier this week with a plotting question. They had fit a series of Bayesian models, all containing a common parameter of interest. They knew how to plot their focal parameter one model at a time, but were stumped on how to combine the plots across models into a seamless whole. It reminded me a bit of this gif
which I originally got from Jenny Bryan’s great talk, Behind every great plot there’s a great deal of wrangling.">

  
  <link rel="alternate" hreflang="en-us" href="/post/would-you-like-all-your-posteriors-in-one-plot/">

  


  

  

  

  
  
  
  <meta name="theme-color" content="#0095eb">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha256-eSi1q2PG6J7g7ib17yAaWMcrr5GrtohYChqibrV7PBE=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" crossorigin="anonymous">
      
    

    

    

  

  
  
  <link rel="stylesheet" href=//fonts.googleapis.com/css?family=Montserrat:400,700|Roboto:400,400italic,700|Roboto+Mono>
  

  <link rel="stylesheet" href="/styles.css">
  

  
  
  

  
  <link rel="alternate" href="/index.xml" type="application/rss+xml" title="A. Solomon Kurz">
  <link rel="feed" href="/index.xml" type="application/rss+xml" title="A. Solomon Kurz">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="/post/would-you-like-all-your-posteriors-in-one-plot/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@SolomonKurz">
  <meta property="twitter:creator" content="@SolomonKurz">
  
  <meta property="og:site_name" content="A. Solomon Kurz">
  <meta property="og:url" content="/post/would-you-like-all-your-posteriors-in-one-plot/">
  <meta property="og:title" content="Would you like all your posteriors in one plot? | A. Solomon Kurz">
  <meta property="og:description" content="A colleague reached out to me earlier this week with a plotting question. They had fit a series of Bayesian models, all containing a common parameter of interest. They knew how to plot their focal parameter one model at a time, but were stumped on how to combine the plots across models into a seamless whole. It reminded me a bit of this gif
which I originally got from Jenny Bryan’s great talk, Behind every great plot there’s a great deal of wrangling.">
  
  
    
  <meta property="og:image" content="/img/Solomon%20at%20Double%20Decker.jpg">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2019-07-13T00:00:00&#43;00:00">
  
  <meta property="article:modified_time" content="2019-07-13T00:00:00&#43;00:00">
  

  

  

  <title>Would you like all your posteriors in one plot? | A. Solomon Kurz</title>

</head>
<body id="top" data-spy="scroll" data-target="#TableOfContents" data-offset="71" >

<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">A. Solomon Kurz</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav ml-auto">
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/post/">
            
            <span>Blog posts</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/bookdown/">
            
            <span>Book-length projects</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/teaching/">
            
            <span>Teaching</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/conflicts_of_interest/">
            
            <span>Conflicts of interest</span>
            
          </a>
        </li>

        
        

      

        

        
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  





  <div class="article-container">
    <h1 itemprop="name">Would you like all your posteriors in one plot?</h1>

    

<div class="article-metadata">

  
  
  <span itemscope itemprop="author" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="A. Solomon Kurz">
  </span>
  

  <span class="article-date">
    
    <meta content="2019-07-13 00:00:00 &#43;0000 UTC" itemprop="datePublished">
    <time datetime="2019-07-13 00:00:00 &#43;0000 UTC" itemprop="dateModified">
      Jul 13, 2019
    </time>
  </span>
  <span itemscope itemprop="publisher" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="A. Solomon Kurz">
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    13 min read
  </span>
  

  
  

  
  
  
  

  
  
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=Would%20you%20like%20all%20your%20posteriors%20in%20one%20plot%3f&amp;url=%2fpost%2fwould-you-like-all-your-posteriors-in-one-plot%2f"
         target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=%2fpost%2fwould-you-like-all-your-posteriors-in-one-plot%2f"
         target="_blank" rel="noopener">
        <i class="fab fa-facebook-f"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2fpost%2fwould-you-like-all-your-posteriors-in-one-plot%2f&amp;title=Would%20you%20like%20all%20your%20posteriors%20in%20one%20plot%3f"
         target="_blank" rel="noopener">
        <i class="fab fa-linkedin-in"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=%2fpost%2fwould-you-like-all-your-posteriors-in-one-plot%2f&amp;title=Would%20you%20like%20all%20your%20posteriors%20in%20one%20plot%3f"
         target="_blank" rel="noopener">
        <i class="fab fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=Would%20you%20like%20all%20your%20posteriors%20in%20one%20plot%3f&amp;body=%2fpost%2fwould-you-like-all-your-posteriors-in-one-plot%2f">
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


  

</div>


    <div class="article-style" itemprop="articleBody">
      


<p>A colleague reached out to me earlier this week with a plotting question. They had fit a series of Bayesian models, all containing a common parameter of interest. They knew how to plot their focal parameter one model at a time, but were stumped on how to combine the plots across models into a seamless whole. It reminded me a bit of this gif</p>
<p><img src="https://media.giphy.com/media/Bqn8Z7xdPCFy0/giphy.gif" /></p>
<p>which I originally got from <a href="https://twitter.com/JennyBryan">Jenny Bryan</a>’s great talk, <a href="https://www.youtube.com/watch?v=4MfUCX_KpdE"><em>Behind every great plot there’s a great deal of wrangling</em></a>.</p>
<p>The goal of this post is to provide solutions. We’ll practice a few different ways you can combine the posterior samples from your Bayesian models into a single plot. As usual, we’ll be fitting our models with <a href="https://github.com/paul-buerkner/brms"><strong>brms</strong></a>, wrangling with packages from the <a href="https://www.tidyverse.org"><strong>tidyverse</strong></a>, and getting a little help from the <a href="https://mjskay.github.io/tidybayes/index.html"><strong>tidybayes</strong> package</a>.</p>
<div id="i-make-assumptions." class="section level2">
<h2>I make assumptions.</h2>
<p>For this post, I’m presuming you are familiar Bayesian regression using <strong>brms.</strong> I’m also assuming you’ve coded using some of the foundational functions from the <strong>tidyverse.</strong> If you’d like to firm up your foundations a bit, check out these resources.</p>
<ul>
<li>To learn about Bayesian regression, I recommend the introductory text books by either McElreath (<a href="(%5Bhere%5D())">here</a>) or Kruschke (<a href="http://www.indiana.edu/~kruschke/DoingBayesianDataAnalysis/">here</a>). Both authors host blogs (<a href="http://doingbayesiandataanalysis.blogspot.com">here</a> and <a href="http://elevanth.org/blog/">here</a>, respectively). If you go with McElreath, do check out his <a href="https://www.youtube.com/channel/UCNJK6_DZvcMqNSzQdEkzvzA/playlists">online lectures</a> and <a href="https://bookdown.org/connect/#/apps/1850/access">my project</a> translating his text to <strong>brms</strong> and <strong>tidyverse</strong> code. I’m working on a <a href="https://github.com/ASKurz/Doing-Bayesian-Data-Analysis-in-brms-and-the-tidyverse">similar project</a> for Kruschke’s text, but it still has a ways to go before I release it in full.</li>
<li>For even more <strong>brms</strong>-related resources, you can find vignettes and documentation <a href="https://cran.r-project.org/web/packages/brms/index.html">here</a>.</li>
<li>For <strong>tidyverse</strong> introductions, your best bets are <a href="https://r4ds.had.co.nz"><em>R4DS</em></a> and <a href="https://style.tidyverse.org"><em>The tidyverse style guide</em></a>.</li>
</ul>
</div>
<div id="same-parameter-different-models" class="section level2">
<h2>Same parameter, different models</h2>
<p>Let’s load our primary statistical packages.</p>
<pre class="r"><code>library(tidyverse)
library(brms)
library(tidybayes)</code></pre>
<p>Simulate <span class="math inline">\(n = 150\)</span> draws from the standard normal distribution.</p>
<pre class="r"><code>n &lt;- 150

set.seed(1)
d &lt;-
  tibble(y = rnorm(n, mean = 0, sd = 1))

head(d)</code></pre>
<pre><code>## # A tibble: 6 x 1
##        y
##    &lt;dbl&gt;
## 1 -0.626
## 2  0.184
## 3 -0.836
## 4  1.60 
## 5  0.330
## 6 -0.820</code></pre>
<p>Here we’ll fit three intercept-only models for <code>y</code>. Each will follow the form</p>
<p><span class="math display">\[
\begin{align*}
y_i     &amp; \sim \text{Normal} (\mu, \sigma) \\
\mu     &amp; = \beta_0 \\
\beta_0 &amp; \sim \text{Normal} (0, x) \\
\sigma  &amp; \sim \text{Student-t}(3, 0, 10)
\end{align*}
\]</span></p>
<p>where <span class="math inline">\(\beta_0\)</span> is the unconditional intercept (i.e., an intercept not conditioned on any predictors). We will be fitting three alternative models. All will have the same prior for <span class="math inline">\(\sigma\)</span>, <span class="math inline">\(\text{Student-t}(3, 0, 10)\)</span>, which is the <strong>brms</strong> default in this case. [If you’d like to check, use the <code>get_prior()</code> function.] The only way the models will differ is by their prior on the intercept <span class="math inline">\(\beta_0\)</span>. By model, those priors will be</p>
<ul>
<li><code>fit1</code>: <span class="math inline">\(\beta_0 \sim \text{Normal} (0, 10)\)</span>,</li>
<li><code>fit2</code>: <span class="math inline">\(\beta_0 \sim \text{Normal} (0, 1)\)</span>, and</li>
<li><code>fit3</code>: <span class="math inline">\(\beta_0 \sim \text{Normal} (0, 0.1)\)</span>.</li>
</ul>
<p>So if you were wondering, the <span class="math inline">\(x\)</span> in the <span class="math inline">\(\beta_0 \sim \text{Normal} (0, x)\)</span> line, above, was a stand-in for the varying <a href="https://en.wikipedia.org/wiki/Hyperparameter">hyperparameter</a>.</p>
<p>Here we fit the models in bulk.</p>
<pre class="r"><code>fit1 &lt;-
  brm(data = d,
      family = gaussian,
      y ~ 1,
      prior(normal(0, 10), class = Intercept),
      seed = 1)

fit2 &lt;-
  update(fit1,
         prior = prior(normal(0, 1), class = Intercept),
         seed = 1)

fit3 &lt;-
  update(fit1,
         prior = prior(normal(0, 0.1), class = Intercept),
         seed = 1)</code></pre>
<p>Normally we’d use <code>plot()</code> to make sure the chains look good and then use something like <code>print()</code> or <code>posterior_summary()</code> to summarize the models’ results. I’ve checked and they’re all fine. For the sake of space, let’s press forward.</p>
<p>If you were going to plot the results of an individual fit using something like the <code>tidybayes::geom_halfeyeh()</code> function, the next step would be extracting the posterior draws. Here we’ll do so with the <code>brms::posterior_samples()</code> function.</p>
<pre class="r"><code>post1 &lt;- posterior_samples(fit1)
post2 &lt;- posterior_samples(fit2)
post3 &lt;- posterior_samples(fit3)</code></pre>
<p>Focusing on <code>fit1</code>, here’s how we’d plot the results for the intercept <span class="math inline">\(\beta_0\)</span>.</p>
<pre class="r"><code># this part is unnecessary; it just adjusts some theme defaults to my liking
theme_set(theme_gray() +
            theme(axis.text.y  = element_text(hjust = 0),
                  axis.ticks.y = element_blank(),
                  panel.grid   = element_blank()))

# plot!
post1 %&gt;% 
  ggplot(aes(x = b_Intercept, y = 0)) +
  geom_halfeyeh() +
  scale_y_continuous(NULL, breaks = NULL)</code></pre>
<p><img src="/post/2019-07-13-would-you-like-all-your-posteriors-in-one-plot_files/figure-html/unnamed-chunk-6-1.png" width="480" /></p>
<p><em>But how might we get the posterior draws from all three fits into one plot?</em> The answer is by somehow combining the posterior draws from each into one data frame. There are many ways to do this. Perhaps the simplest is with the <code>bind_rows()</code> function.</p>
<pre class="r"><code>posts &lt;-
  bind_rows(
    post1,
    post2,
    post3
  ) %&gt;% 
  mutate(prior = str_c(&quot;normal(0, &quot;, c(10, 1, 0.1), &quot;)&quot;) %&gt;% rep(., each = 4000))

head(posts)</code></pre>
<pre><code>##    b_Intercept     sigma      lp__         prior
## 1 -0.052176422 0.8568091 -204.1751 normal(0, 10)
## 2  0.124990457 0.8983495 -204.1663 normal(0, 10)
## 3 -0.006294612 0.9475288 -203.5528 normal(0, 10)
## 4  0.060904410 0.9410559 -203.5319 normal(0, 10)
## 5  0.177594575 0.9457762 -205.4991 normal(0, 10)
## 6  0.134879573 0.9267331 -204.3765 normal(0, 10)</code></pre>
<p>The <code>bind_rows()</code> function worked well, here, because all three post objects had the same number of columns of the same names. So we just stacked them three high. That is, we went from three data objects of 4,000 rows and 3 columns to one data object with 12,000 rows and 3 columns. But with the <code>mutate()</code> function we did add a fourth column, <code>prior</code>, that indexed which model each row came from. Now our data are ready, we can plot.</p>
<pre class="r"><code>posts %&gt;% 
  ggplot(aes(x = b_Intercept, y = prior)) +
  geom_halfeyeh()</code></pre>
<p><img src="/post/2019-07-13-would-you-like-all-your-posteriors-in-one-plot_files/figure-html/unnamed-chunk-8-1.png" width="576" /></p>
<p>Our plot arrangement made it easy to compare the results of tightening the prior on <span class="math inline">\(\beta_0\)</span>; the narrower the prior, the narrower the posterior.</p>
</div>
<div id="what-if-my-posterior_samples-arent-of-the-same-dimensions-across-models" class="section level2">
<h2>What if my <code>posterior_samples()</code> aren’t of the same dimensions across models?</h2>
<p>For the next examples, we need new data. Here we’ll simulate three predictors–<code>x1</code>, <code>x2</code>, and <code>x3</code>. We then simulate our criterion <code>y</code> as a linear additive function of those predictors.</p>
<pre class="r"><code>set.seed(1)
d &lt;-
  tibble(x1 = rnorm(n, mean = 0, sd = 1),
         x2 = rnorm(n, mean = 0, sd = 1),
         x3 = rnorm(n, mean = 0, sd = 1)) %&gt;% 
  mutate(y  = rnorm(n, mean = 0 + x1 * 0 + x2 * 0.2 + x3 * -0.4))

head(d)</code></pre>
<pre><code>## # A tibble: 6 x 4
##       x1      x2     x3      y
##    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1 -0.626  0.450   0.894  0.694
## 2  0.184 -0.0186 -1.05  -0.189
## 3 -0.836 -0.318   1.97  -1.61 
## 4  1.60  -0.929  -0.384 -1.59 
## 5  0.330 -1.49    1.65  -2.41 
## 6 -0.820 -1.08    1.51  -0.764</code></pre>
<p>We are going to work with these data in two ways. For the first example, we’ll fit a series of univariable models following the same basic form, but each with a different predictor. For the second example, we’ll fit a series of multivariable models with various combinations of the predictors. Each requires its own approach.</p>
<div id="same-form-different-predictors." class="section level3">
<h3>Same form, different predictors.</h3>
<p>This time we’re just using the <strong>brms</strong> default priors. As such, the models all follow the form</p>
<p><span class="math display">\[
\begin{align*}
y_i     &amp; \sim \text{Normal} (\mu_i, \sigma) \\
\mu_i   &amp; = \beta_0 + \beta_n x_n\\
\beta_0 &amp; \sim \text{Student-t}(3, 0, 10) \\
\sigma  &amp; \sim \text{Student-t}(3, 0, 10)
\end{align*}
\]</span></p>
<p>You may be wondering <em>What about the prior for</em> <span class="math inline">\(\beta_n\)</span><em>?</em> The <strong>brms</strong> defaults for those are improper flat priors. We define <span class="math inline">\(\beta_n x_n\)</span> for the next three models as</p>
<ul>
<li><code>fit4</code>: <span class="math inline">\(\beta_1 x_1\)</span>,</li>
<li><code>fit5</code>: <span class="math inline">\(\beta_2 x_2\)</span>, and</li>
<li><code>fit5</code>: <span class="math inline">\(\beta_3 x_3\)</span>.</li>
</ul>
<p>Let’s fit the models.</p>
<pre class="r"><code>fit4 &lt;-
  brm(data = d,
      family = gaussian,
      y ~ 1 + x1,
      seed = 1)

fit5 &lt;-
  update(fit4,
         newdata = d,
         y ~ 1 + x2,
         seed = 1)

fit6 &lt;-
  update(fit4,
         newdata = d,
         y ~ 1 + x3,
         seed = 1)</code></pre>
<p>Like before, save the posterior draws for each as separate data frames.</p>
<pre class="r"><code>post4 &lt;- posterior_samples(fit4)
post5 &lt;- posterior_samples(fit5)
post6 &lt;- posterior_samples(fit6)</code></pre>
<p>This time, our simple <code>bind_rows()</code> trick won’t work well.</p>
<pre class="r"><code>bind_rows(
  post4,
  post5,
  post6
) %&gt;% 
  head()</code></pre>
<pre><code>##    b_Intercept         b_x1    sigma      lp__ b_x2 b_x3
## 1  0.167513067 -0.179568244 1.154730 -243.4799   NA   NA
## 2 -0.017092084 -0.281401589 1.145705 -243.1930   NA   NA
## 3 -0.036944855 -0.204756757 1.191577 -242.1853   NA   NA
## 4  0.041075341 -0.009902425 1.183252 -242.0840   NA   NA
## 5  0.032423912 -0.050100545 1.147125 -241.8424   NA   NA
## 6  0.003649314 -0.161764444 1.183537 -241.7794   NA   NA</code></pre>
<p>We don’t want separate columns for <code>b_x1</code>, <code>b_x2</code>, and <code>b_x3</code>. We want them all stacked atop one another. One simple solution is a two-step wherein we (1) select the relevant columns from each and bind them together with <code>bind_cols()</code> and then (2) stack them atop one another with the <code>gather()</code> function.</p>
<pre class="r"><code>posts &lt;-
  bind_cols(
    post4 %&gt;% select(b_x1),
    post5 %&gt;% select(b_x2),
    post6 %&gt;% select(b_x3)
  ) %&gt;% 
  gather() %&gt;% 
  mutate(predictor = str_remove(key, &quot;b_&quot;))

head(posts)</code></pre>
<pre><code>##    key        value predictor
## 1 b_x1 -0.179568244        x1
## 2 b_x1 -0.281401589        x1
## 3 b_x1 -0.204756757        x1
## 4 b_x1 -0.009902425        x1
## 5 b_x1 -0.050100545        x1
## 6 b_x1 -0.161764444        x1</code></pre>
<p>That <code>mutate()</code> line at the end wasn’t necessary, but it will make the plot more attractive.</p>
<pre class="r"><code>posts %&gt;% 
  ggplot(aes(x = value, y = predictor)) +
  geom_halfeyeh()</code></pre>
<p><img src="/post/2019-07-13-would-you-like-all-your-posteriors-in-one-plot_files/figure-html/unnamed-chunk-14-1.png" width="576" /></p>
</div>
<div id="different-combinations-of-predictors-in-different-forms." class="section level3">
<h3>Different combinations of predictors in different forms.</h3>
<p>Now we fit a series of multivariable models. The first three will have combinations of two of the predictors. The final model will have all three. For simplicity, we continue to use the <strong>brms</strong> default priors.</p>
<pre class="r"><code>fit7 &lt;-
  brm(data = d,
      family = gaussian,
      y ~ 1 + x1 + x2,
      seed = 1)

fit8 &lt;-
  update(fit7,
         newdata = d,
         y ~ 1 + x1 + x3,
         seed = 1)

fit9 &lt;-
  update(fit7,
         newdata = d,
         y ~ 1 + x2 + x3,
         seed = 1)

fit10 &lt;-
  update(fit7,
         newdata = d,
         y ~ 1 + x1 + x2 + x3,
         seed = 1)</code></pre>
<p>Individually extract the posterior draws.</p>
<pre class="r"><code>post7  &lt;- posterior_samples(fit7)
post8  &lt;- posterior_samples(fit8)
post9  &lt;- posterior_samples(fit9)
post10 &lt;- posterior_samples(fit10)</code></pre>
<p>Take a look at what happens this time when we use the <code>bind_rows()</code> approach.</p>
<pre class="r"><code>posts &lt;-
  bind_rows(
    post7,
    post8,
    post9,
    post10
  ) 

glimpse(posts)</code></pre>
<pre><code>## Observations: 16,000
## Variables: 6
## $ b_Intercept &lt;dbl&gt; 0.09509318, 0.08186866, 0.02571336, -0.18844144, -0.06763395, 0.06137342, 0.0…
## $ b_x1        &lt;dbl&gt; -0.117031758, 0.004563560, -0.129202123, -0.125793634, -0.041442345, -0.02864…
## $ b_x2        &lt;dbl&gt; 0.19180539, 0.19254784, 0.31151419, 0.33083881, 0.08777655, 0.32273994, 0.158…
## $ sigma       &lt;dbl&gt; 1.118284, 1.122873, 1.159854, 1.108438, 1.041766, 1.214929, 1.220967, 1.28653…
## $ lp__        &lt;dbl&gt; -239.1799, -239.4599, -238.7769, -240.8443, -241.7296, -239.6411, -239.5687, …
## $ b_x3        &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…</code></pre>
<p>We still have the various data frames stacked atop another, with the data from <code>post7</code> in the first 4,000 rows. See how the values in the <code>b_x3</code> column are all missing (i.e., filled with <code>NA</code> values)? That’s because <code>fit7</code> didn’t contain <code>x3</code> as a predictor. Similarly, if we were to look at rows 4,001 through 8,000, we’d see column <code>b_x2</code> would be the one filled with <code>NA</code>s. This behavior is a good thing, here. After a little more wrangling, we’ll plot and it should be become clear why. Here’s the wrangling.</p>
<pre class="r"><code>posts &lt;-
  posts %&gt;% 
  select(starts_with(&quot;b_x&quot;)) %&gt;% 
  mutate(contains = rep(c(&quot;&lt;1, 1, 0&gt;&quot;, &quot;&lt;1, 0, 1&gt;&quot;, &quot;&lt;0, 1, 1&gt;&quot;, &quot;&lt;1, 1, 1&gt;&quot;), each = 4000)) %&gt;% 
  gather(key, value, -contains) %&gt;% 
  mutate(coefficient = str_remove(key, &quot;b_x&quot;) %&gt;% str_c(&quot;beta[&quot;, ., &quot;]&quot;))

head(posts)</code></pre>
<pre><code>##    contains  key       value coefficient
## 1 &lt;1, 1, 0&gt; b_x1 -0.11703176     beta[1]
## 2 &lt;1, 1, 0&gt; b_x1  0.00456356     beta[1]
## 3 &lt;1, 1, 0&gt; b_x1 -0.12920212     beta[1]
## 4 &lt;1, 1, 0&gt; b_x1 -0.12579363     beta[1]
## 5 &lt;1, 1, 0&gt; b_x1 -0.04144234     beta[1]
## 6 &lt;1, 1, 0&gt; b_x1 -0.02864308     beta[1]</code></pre>
<p>With the <code>contains</code> variable, we indexed which fit the draws came from. The 1s and 0s within the angle brackets indicate which of the three predictors were present within the model with the 1s indicating they were and the 0s indicating they were not. For example, <code>&lt;1, 1, 0&gt;</code> in the first row indicated this was the model including <code>x1</code> and <code>x2</code>. Importantly, we also added a <code>coefficient</code> index. This is just a variant of <code>key</code> that’ll make the strip labels in our plot more attractive. Behold:</p>
<pre class="r"><code>posts %&gt;% 
  ggplot(aes(x = value, y = contains)) +
  geom_halfeyeh() +
  ylab(NULL) +
  facet_wrap(~coefficient, ncol = 1, labeller = label_parsed)</code></pre>
<p><img src="/post/2019-07-13-would-you-like-all-your-posteriors-in-one-plot_files/figure-html/unnamed-chunk-18-1.png" width="576" /></p>
<p>Hopefully now it’s clear why it was good to save those cells with the <code>NA</code>s.</p>
</div>
</div>
<div id="bonus-you-can-streamline-your-workflow." class="section level2">
<h2>Bonus: You can streamline your workflow.</h2>
<p>The workflows above are generally fine. But they’re a little inefficient. If you’d like to reduce the amount of code you’re writing and the number of objects you have floating around in your environment, you might consider a more streamlined workflow where you work with your fit objects in bulk. Here we’ll demonstrate a nested tibble approach with the first three fits.</p>
<pre class="r"><code>posts &lt;-
  tibble(name  = str_c(&quot;fit&quot;, 1:3),
         prior = str_c(&quot;normal(0, &quot;, c(10, 1, 0.1), &quot;)&quot;)) %&gt;% 
  mutate(fit   = map(name, get)) %&gt;% 
  mutate(post  = map(fit, posterior_samples))
  
head(posts)</code></pre>
<pre><code>## # A tibble: 3 x 4
##   name  prior          fit       post                
##   &lt;chr&gt; &lt;chr&gt;          &lt;list&gt;    &lt;list&gt;              
## 1 fit1  normal(0, 10)  &lt;brmsfit&gt; &lt;df[,3] [4,000 × 3]&gt;
## 2 fit2  normal(0, 1)   &lt;brmsfit&gt; &lt;df[,3] [4,000 × 3]&gt;
## 3 fit3  normal(0, 0.1) &lt;brmsfit&gt; &lt;df[,3] [4,000 × 3]&gt;</code></pre>
<p>We have a 3-row nested tibble. The first column, <code>name</code> is just a character vector with the names of the fits. The next column isn’t necessary, but it nicely explicates the main difference in the models: the prior we used on the intercept. It’s in the <code>map()</code> functions within the two <code>mutate()</code>lines where all the magic happens. With the first, we used the <code>get()</code> function to snatch up the <strong>brms</strong> fit objects matching the names in the <code>name</code> column. In the second, we used the <code>posterior_samples()</code> function to extract the posterior draws from each of the fits saved in <code>fit</code>. Do you see how each for in the <code>post</code> column contains an entire <span class="math inline">\(4,000 \times 3\)</span> data frame? That’s why we refer to this as a nested tibble. We have data frames compressed within data frames. If you’d like to access the data within the <code>post</code> column, just <code>unnest()</code>.</p>
<pre class="r"><code>posts %&gt;% 
  unnest(post)</code></pre>
<pre><code>## # A tibble: 12,000 x 6
##    name  prior         fit       b_Intercept sigma  lp__
##    &lt;chr&gt; &lt;chr&gt;         &lt;list&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
##  1 fit1  normal(0, 10) &lt;brmsfit&gt;    -0.0522  0.857 -204.
##  2 fit1  normal(0, 10) &lt;brmsfit&gt;     0.125   0.898 -204.
##  3 fit1  normal(0, 10) &lt;brmsfit&gt;    -0.00629 0.948 -204.
##  4 fit1  normal(0, 10) &lt;brmsfit&gt;     0.0609  0.941 -204.
##  5 fit1  normal(0, 10) &lt;brmsfit&gt;     0.178   0.946 -205.
##  6 fit1  normal(0, 10) &lt;brmsfit&gt;     0.135   0.927 -204.
##  7 fit1  normal(0, 10) &lt;brmsfit&gt;    -0.0777  0.874 -204.
##  8 fit1  normal(0, 10) &lt;brmsfit&gt;     0.116   0.973 -205.
##  9 fit1  normal(0, 10) &lt;brmsfit&gt;     0.134   0.852 -205.
## 10 fit1  normal(0, 10) &lt;brmsfit&gt;     0.0197  0.929 -203.
## # … with 11,990 more rows</code></pre>
<p>After un-nesting, we can remake the plot from above.</p>
<pre class="r"><code>posts %&gt;% 
  unnest(post) %&gt;% 

  ggplot(aes(x = b_Intercept, y = prior)) +
  geom_halfeyeh()</code></pre>
<p><img src="/post/2019-07-13-would-you-like-all-your-posteriors-in-one-plot_files/figure-html/unnamed-chunk-21-1.png" width="576" /></p>
<p>To learn more about using the <strong>tidyverse</strong> for iterating and saving the results in nested tibbles, check out <a href="https://twitter.com/hadleywickham">Hadley Wickham</a>’s great talk, <a href="https://www.youtube.com/watch?v=rz3_FDVt9eg"><em>Managing many models</em></a>.</p>
</div>
<div id="session-information" class="section level2">
<h2>Session information</h2>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>## R version 3.6.2 (2019-12-12)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS High Sierra 10.13.6
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] tidybayes_2.0.1.9000 brms_2.12.0          Rcpp_1.0.3           forcats_0.4.0       
##  [5] stringr_1.4.0        dplyr_0.8.4          purrr_0.3.3          readr_1.3.1         
##  [9] tidyr_1.0.2          tibble_2.1.3         ggplot2_3.2.1        tidyverse_1.3.0     
## 
## loaded via a namespace (and not attached):
##   [1] colorspace_1.4-1          ellipsis_0.3.0            ggridges_0.5.2           
##   [4] rsconnect_0.8.16          markdown_1.1              base64enc_0.1-3          
##   [7] fs_1.3.1                  rstudioapi_0.10           farver_2.0.3             
##  [10] rstan_2.19.2              svUnit_0.7-12             DT_0.11                  
##  [13] fansi_0.4.1               mvtnorm_1.0-12            lubridate_1.7.4          
##  [16] xml2_1.2.2                bridgesampling_0.8-1      knitr_1.26               
##  [19] shinythemes_1.1.2         bayesplot_1.7.1           jsonlite_1.6.1           
##  [22] broom_0.5.3               dbplyr_1.4.2              shiny_1.4.0              
##  [25] compiler_3.6.2            httr_1.4.1                backports_1.1.5          
##  [28] assertthat_0.2.1          Matrix_1.2-18             fastmap_1.0.1            
##  [31] lazyeval_0.2.2            cli_2.0.1                 later_1.0.0              
##  [34] htmltools_0.4.0           prettyunits_1.1.1         tools_3.6.2              
##  [37] igraph_1.2.4.2            coda_0.19-3               gtable_0.3.0             
##  [40] glue_1.3.1                reshape2_1.4.3            cellranger_1.1.0         
##  [43] vctrs_0.2.2               nlme_3.1-142              blogdown_0.17            
##  [46] crosstalk_1.0.0           xfun_0.12                 ps_1.3.0                 
##  [49] rvest_0.3.5               mime_0.8                  miniUI_0.1.1.1           
##  [52] lifecycle_0.1.0           gtools_3.8.1              zoo_1.8-7                
##  [55] scales_1.1.0              colourpicker_1.0          hms_0.5.3                
##  [58] promises_1.1.0            Brobdingnag_1.2-6         parallel_3.6.2           
##  [61] inline_0.3.15             shinystan_2.5.0           yaml_2.2.1               
##  [64] gridExtra_2.3             loo_2.2.0                 StanHeaders_2.19.0       
##  [67] stringi_1.4.6             dygraphs_1.1.1.6          pkgbuild_1.0.6           
##  [70] rlang_0.4.5               pkgconfig_2.0.3           matrixStats_0.55.0       
##  [73] evaluate_0.14             lattice_0.20-38           labeling_0.3             
##  [76] rstantools_2.0.0          htmlwidgets_1.5.1         tidyselect_1.0.0         
##  [79] processx_3.4.1            plyr_1.8.5                magrittr_1.5             
##  [82] bookdown_0.17             R6_2.4.1                  generics_0.0.2           
##  [85] DBI_1.1.0                 pillar_1.4.3              haven_2.2.0              
##  [88] withr_2.1.2               xts_0.12-0                abind_1.4-5              
##  [91] modelr_0.1.5              crayon_1.3.4              arrayhelpers_1.0-20160527
##  [94] utf8_1.1.4                rmarkdown_2.0             grid_3.6.2               
##  [97] readxl_1.3.1              callr_3.4.1               threejs_0.3.3            
## [100] reprex_0.3.0              digest_0.6.23             xtable_1.8-4             
## [103] httpuv_1.5.2              stats4_3.6.2              munsell_0.5.0            
## [106] shinyjs_1.1</code></pre>
</div>

    </div>

    


<div class="article-tags">
  
  <a class="badge badge-light" href="/tags/bayesian/">Bayesian</a>
  
  <a class="badge badge-light" href="/tags/brms/">brms</a>
  
  <a class="badge badge-light" href="/tags/plot/">plot</a>
  
  <a class="badge badge-light" href="/tags/r/">R</a>
  
  <a class="badge badge-light" href="/tags/tidyerse/">tidyerse</a>
  
  <a class="badge badge-light" href="/tags/tutorial/">tutorial</a>
  
</div>




    
    
    <div class="article-widget">
      <div class="hr-light"></div>
      <h3>Related</h3>
      <ul>
        
        <li><a href="/post/make-rotated-gaussians-kruschke-style/">Make rotated Gaussians, Kruschke style</a></li>
        
        <li><a href="/post/stein-s-paradox-and-what-partial-pooling-can-do-for-you/">Stein’s Paradox and What Partial Pooling Can Do For You</a></li>
        
        <li><a href="/post/bayesian-correlations-let-s-talk-options/">Bayesian Correlations: Let’s Talk Options.</a></li>
        
        <li><a href="/post/bayesian-robust-correlations-with-brms-and-why-you-should-love-student-s-t/">Bayesian robust correlations with brms (and why you should love Student’s $t$)</a></li>
        
        <li><a href="/post/robust-linear-regression-with-the-robust-student-s-t-distribution/">Robust Linear Regression with Student’s $t$-Distribution</a></li>
        
      </ul>
    </div>
    

    

    


  </div>
</article>

<div class="container">
  <footer class="site-footer">
  

  <p class="powered-by">
    © 2018 &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

</div>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        CommonHTML: { linebreaks: { automatic: true } },
        tex2jax: { inlineMath: [ ['$', '$'], ['\\(','\\)'] ], displayMath: [ ['$$','$$'], ['\\[', '\\]'] ], processEscapes: false },
        TeX: { noUndefined: { attributes: { mathcolor: 'red', mathbackground: '#FFEEEE', mathsize: '90%' } } },
        messageStyle: 'none'
      });
    </script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha512-+NqPlbbtM1QqiK8ZAo4Yrj2c4lNQoGv8P79DPtKzj++l5jnN39rHA/xsqn8zE9l0uSoxaCdrOgFs6yjyfbBxSg==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha256-VsEqElsCHSGmnmHXGQzvoWjWwoznFSZc6hs7ARLRacQ=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    <script src="/js/hugo-academic.js"></script>
    

    
    

    
    
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "Search Results",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    <script src="/js/search.js"></script>
    

    
    

  </body>
</html>

