<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 2.4.0">
  <meta name="generator" content="Hugo 0.74.3" />
  <meta name="author" content="A. Solomon Kurz">

  
  
  
  
    
  
  <meta name="description" content="tl;dr There’s more than one way to fit a Bayesian correlation in brms.
 Here’s the deal. In the last post, we considered how we might estimate correlations when our data contain influential outlier values. Our big insight was that if we use variants of Student’s \(t\)-distribution as the likelihood rather than the conventional normal distribution, our correlation estimates were less influenced by those outliers. And we mainly did that as Bayesians using the brms package.">

  
  <link rel="alternate" hreflang="en-us" href="/post/bayesian-correlations-let-s-talk-options/">

  


  

  

  

  
  
  
  <meta name="theme-color" content="#0095eb">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha256-eSi1q2PG6J7g7ib17yAaWMcrr5GrtohYChqibrV7PBE=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" crossorigin="anonymous">
      
    

    

    

  

  
  
  <link rel="stylesheet" href=//fonts.googleapis.com/css?family=Montserrat:400,700|Roboto:400,400italic,700|Roboto+Mono>
  

  <link rel="stylesheet" href="/styles.css">
  

  
  
  

  
  <link rel="alternate" href="/index.xml" type="application/rss+xml" title="A. Solomon Kurz">
  <link rel="feed" href="/index.xml" type="application/rss+xml" title="A. Solomon Kurz">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="/post/bayesian-correlations-let-s-talk-options/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@SolomonKurz">
  <meta property="twitter:creator" content="@SolomonKurz">
  
  <meta property="og:site_name" content="A. Solomon Kurz">
  <meta property="og:url" content="/post/bayesian-correlations-let-s-talk-options/">
  <meta property="og:title" content="Bayesian Correlations: Let’s Talk Options. | A. Solomon Kurz">
  <meta property="og:description" content="tl;dr There’s more than one way to fit a Bayesian correlation in brms.
 Here’s the deal. In the last post, we considered how we might estimate correlations when our data contain influential outlier values. Our big insight was that if we use variants of Student’s \(t\)-distribution as the likelihood rather than the conventional normal distribution, our correlation estimates were less influenced by those outliers. And we mainly did that as Bayesians using the brms package.">
  
  
    
  <meta property="og:image" content="/img/Solomon%20at%20Double%20Decker.jpg">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2019-02-16T00:00:00&#43;00:00">
  
  <meta property="article:modified_time" content="2019-02-16T00:00:00&#43;00:00">
  

  

  

  <title>Bayesian Correlations: Let’s Talk Options. | A. Solomon Kurz</title>

</head>
<body id="top" data-spy="scroll" data-target="#TableOfContents" data-offset="71" >

<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">A. Solomon Kurz</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav ml-auto">
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/post/">
            
            <span>Blog posts</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/bookdown/">
            
            <span>Book-length projects</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/teaching/">
            
            <span>Teaching</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/conflicts_of_interest/">
            
            <span>Conflicts of interest</span>
            
          </a>
        </li>

        
        

      

        

        
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  





  <div class="article-container">
    <h1 itemprop="name">Bayesian Correlations: Let’s Talk Options.</h1>

    

<div class="article-metadata">

  
  
  <span itemscope itemprop="author" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="A. Solomon Kurz">
  </span>
  

  <span class="article-date">
    
    <meta content="2019-02-16 00:00:00 &#43;0000 UTC" itemprop="datePublished">
    <time datetime="2019-02-16 00:00:00 &#43;0000 UTC" itemprop="dateModified">
      Feb 16, 2019
    </time>
  </span>
  <span itemscope itemprop="publisher" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="A. Solomon Kurz">
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    19 min read
  </span>
  

  
  

  
  
  
  

  
  
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=Bayesian%20Correlations%3a%20Let%e2%80%99s%20Talk%20Options.&amp;url=%2fpost%2fbayesian-correlations-let-s-talk-options%2f"
         target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=%2fpost%2fbayesian-correlations-let-s-talk-options%2f"
         target="_blank" rel="noopener">
        <i class="fab fa-facebook-f"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2fpost%2fbayesian-correlations-let-s-talk-options%2f&amp;title=Bayesian%20Correlations%3a%20Let%e2%80%99s%20Talk%20Options."
         target="_blank" rel="noopener">
        <i class="fab fa-linkedin-in"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=%2fpost%2fbayesian-correlations-let-s-talk-options%2f&amp;title=Bayesian%20Correlations%3a%20Let%e2%80%99s%20Talk%20Options."
         target="_blank" rel="noopener">
        <i class="fab fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=Bayesian%20Correlations%3a%20Let%e2%80%99s%20Talk%20Options.&amp;body=%2fpost%2fbayesian-correlations-let-s-talk-options%2f">
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


  

</div>


    <div class="article-style" itemprop="articleBody">
      


<div id="tldr" class="section level2">
<h2>tl;dr</h2>
<p>There’s more than one way to fit a Bayesian correlation in brms.</p>
</div>
<div id="heres-the-deal." class="section level2">
<h2>Here’s the deal.</h2>
<p>In the last post, we considered how we might estimate correlations when our data contain influential outlier values. Our big insight was that if we use variants of Student’s <span class="math inline">\(t\)</span>-distribution as the likelihood rather than the conventional normal distribution, our correlation estimates were less influenced by those outliers. And we mainly did that as Bayesians using the <a href="https://github.com/paul-buerkner/brms">brms package</a>. Click <a href="https://solomonkurz.netlify.com/post/bayesian-robust-correlations-with-brms-and-why-you-should-love-student-s-t/">here</a> for a refresher.</p>
<p>Since the brms package is designed to fit regression models, <a href="https://twitter.com/tjmahr/status/1094808459239981056">it can be surprising</a> when you discover it’s handy for correlations, too. In short, you can fit them using a few tricks based on the <a href="https://cran.r-project.org/web/packages/brms/vignettes/brms_multivariate.html">multivariate syntax</a>.</p>
<p>Shortly after uploading the post, it occurred to me we had more options and it might be useful to walk through them a bit.</p>
</div>
<div id="i-assume-things." class="section level2">
<h2>I assume things.</h2>
<p>For this post, I’m presuming you are vaguely familiar with linear regression–both univariate and multivariate–, have a little background with Bayesian statistics, and have used Paul Bürkner’s brms packge. As you might imagine, all code in is <a href="https://www.r-bloggers.com/why-use-r-five-reasons/">R</a>, with a heavy use of the <a href="http://style.tidyverse.org">tidyverse</a>.</p>
</div>
<div id="we-need-data." class="section level2">
<h2>We need data.</h2>
<p>First, we’ll load our main packages.</p>
<pre class="r"><code>library(mvtnorm)
library(brms)
library(tidyverse)</code></pre>
<p>We’ll use the <a href="https://cran.r-project.org/web/packages/mvtnorm/index.html">mvtnorm package</a> to simulate three positively correlated variables.</p>
<pre class="r"><code>m &lt;- c(10, 15, 20)  # the means
s &lt;- c(10, 20, 30)  # the sigmas
r &lt;- c(.9, .6, .3)  # the correlations

# here&#39;s the variance/covariance matrix
v &lt;- 
  matrix(c((s[1] * s[1]),        (s[2] * s[1] * r[1]), (s[3] * s[1] * r[2]),
           (s[2] * s[1] * r[1]), (s[2] * s[2]),        (s[3] * s[2] * r[3]),
           (s[3] * s[1] * r[2]), (s[3] * s[2] * r[3]), (s[3] * s[3])),
         nrow = 3, ncol = 3)

# after setting our seed, we&#39;re ready to simulate with `rmvnorm()`
set.seed(1)
d &lt;- 
  rmvnorm(n = 50, mean = m, sigma = v) %&gt;% 
  as_tibble() %&gt;% 
  set_names(&quot;x&quot;, &quot;y&quot;, &quot;z&quot;)</code></pre>
<p>Our data look like so.</p>
<pre class="r"><code>library(GGally)
theme_set(theme_gray() +
            theme(panel.grid = element_blank()))

d %&gt;% 
  ggpairs()</code></pre>
<p><img src="/post/2019-02-16-bayesian-correlations-let-s-talk-options_files/figure-html/unnamed-chunk-3-1.png" width="384" /></p>
<p>Do note the Pearson’s correlation coefficients in the upper triangle.</p>
<p>In order to exploit all the methods we’ll cover in this post, we need to standardize our data. Here we do so by hand using the typical formula</p>
<p><span class="math display">\[z_{x_i} = \frac{x_i - \overline x}{s_x}\]</span></p>
<p>where <span class="math inline">\(\overline x\)</span> is the observed mean and <span class="math inline">\(s_x\)</span> is the observed standard deviation.</p>
<pre class="r"><code>d &lt;-
  d %&gt;% 
  mutate(x_s = (x - mean(x)) / sd(x),
         y_s = (y - mean(y)) / sd(y),
         z_s = (z - mean(z)) / sd(z))

head(d)</code></pre>
<pre><code>## # A tibble: 6 x 6
##       x     y     z    x_s      y_s    z_s
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;
## 1  3.90  11.5 -6.90 -0.723 -0.308   -0.928
## 2 17.7   29.5  4.01  0.758  0.653   -0.512
## 3 20.4   33.8 41.5   1.05   0.886    0.917
## 4 20.3   42.1 34.8   1.04   1.33     0.663
## 5 -3.64 -26.8 43.5  -1.53  -2.36     0.994
## 6 13.9   17.3 47.6   0.347  0.00255  1.15</code></pre>
<p>There are at least two broad ways to get correlations out of standardized data in brms. One way uses the typical univariate syntax. The other way is an extension of the multivariate <code>cbind()</code> approach. Let’s start univariate.</p>
<p>And for a point of clarification, we’re presuming the Gaussian likelihood for all the examples in this post.</p>
</div>
<div id="univariate" class="section level2">
<h2>Univariate</h2>
<p>If you fit a simple univariate model with standardized data and a single predictor, the coefficient for the slope will be in a correlation-like metric. Happily, since the data are all standardized, it’s easy to use <a href="https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations">regularizing priors</a>.</p>
<pre class="r"><code>f1 &lt;- 
  brm(data = d, 
      family = gaussian,
      y_s ~ 1 + x_s,
      prior = c(prior(normal(0, 1), class = Intercept),
                prior(normal(0, 1), class = b),
                prior(normal(0, 1), class = sigma)),
      chains = 4, cores = 4, 
      seed = 1)</code></pre>
<p>Take a look at the model summary.</p>
<pre class="r"><code>print(f1)</code></pre>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: y_s ~ 1 + x_s 
##    Data: d (Number of observations: 50) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     0.00      0.06    -0.11     0.12 1.00     3782     2599
## x_s           0.91      0.06     0.79     1.02 1.00     3847     2946
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     0.42      0.04     0.35     0.52 1.00     3811     2729
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>The ‘Population-Level Effects’ has the summary information for our intercept and slope. Notice how our <code>x_s</code> slope is the same as the Pearson’s correlation.</p>
<pre class="r"><code>cor(d$x, d$y)</code></pre>
<pre><code>## [1] 0.9119708</code></pre>
<p>Since this approach only yields one correlation at a time, we have to fit two more models to get the other two correlations. To do so with haste, we can use the <code>update()</code> syntax.</p>
<pre class="r"><code>f2 &lt;-
  update(f1,
         newdata = d,
         formula = z_s ~ 1 + x_s)

f3 &lt;-
  update(f2,
         newdata = d,
         formula = z_s ~ 1 + y_s)</code></pre>
<p>With the <code>fixef()</code> function, we can easily isolate the <span class="math inline">\(\beta\)</span> estimates.</p>
<pre class="r"><code>fixef(f2)[2, ]</code></pre>
<pre><code>##  Estimate Est.Error      Q2.5     Q97.5 
## 0.5836596 0.1155676 0.3569717 0.8123137</code></pre>
<pre class="r"><code>fixef(f3)[2, ]</code></pre>
<pre><code>##   Estimate  Est.Error       Q2.5      Q97.5 
## 0.31047431 0.13742697 0.03672921 0.57820500</code></pre>
<p>There’s another thing I’d like to point out. Plotting the model results will help make the point.</p>
<pre class="r"><code># define the predictor values you&#39;d like the fitted values for
nd &lt;- tibble(x_s = seq(from = -3, to = 3, length.out = d %&gt;% nrow()))

# wrangle
fitted(f1,
       newdata = nd) %&gt;% 
  as_tibble() %&gt;% 
  bind_cols(nd) %&gt;% 
  
  # plot
  ggplot(aes(x_s)) +
  geom_vline(xintercept = 0, color = &quot;white&quot;) +
  geom_hline(yintercept = 0, color = &quot;white&quot;) +
  geom_point(data = d,
             aes(y = y_s)) +
  geom_smooth(aes(y = Estimate, ymin = Q2.5, ymax = Q97.5),
              stat = &quot;identity&quot;,
              alpha = 1/4, size = 1/2) +
  coord_cartesian(xlim = range(d$x_s),
                  ylim = range(d$y_s))</code></pre>
<p><img src="/post/2019-02-16-bayesian-correlations-let-s-talk-options_files/figure-html/unnamed-chunk-8-1.png" width="336" /></p>
<p>The blue line is the posterior mean and the surrounding gray ribbon depicts the 95% posterior interval. Notice how the data and their respective fitted lines pass through [0, 0]? This is a consequence of modeling standardized data. We should always expect the intercept of a model like this to be 0. Here are the intercept summaries for all three models.</p>
<pre class="r"><code>fixef(f1)[&quot;Intercept&quot;, ] %&gt;% round(3)</code></pre>
<pre><code>##  Estimate Est.Error      Q2.5     Q97.5 
##     0.001     0.060    -0.114     0.119</code></pre>
<pre class="r"><code>fixef(f2)[&quot;Intercept&quot;, ] %&gt;% round(3)</code></pre>
<pre><code>##  Estimate Est.Error      Q2.5     Q97.5 
##     0.002     0.117    -0.226     0.233</code></pre>
<pre class="r"><code>fixef(f3)[&quot;Intercept&quot;, ] %&gt;% round(3)</code></pre>
<pre><code>##  Estimate Est.Error      Q2.5     Q97.5 
##     0.000     0.134    -0.261     0.266</code></pre>
<p>Within simulation error, they’re all centered on zero. So instead of estimating the intercept, why not just bake that into the models? Here we refit the models by fixing the intercept for each to zero.</p>
<pre class="r"><code>f4 &lt;-
  update(f1,
         formula = y_s ~ 0 + x_s)

f5 &lt;-
  update(f4,
         newdata = d,
         formula = z_s ~ 0 + x_s)

f6 &lt;-
  update(f4,
         newdata = d,
         formula = z_s ~ 0 + y_s)</code></pre>
<p>Let’s take a look at the summary for the first.</p>
<pre class="r"><code>print(f4)</code></pre>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: y_s ~ x_s - 1 
##    Data: d (Number of observations: 50) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## x_s     0.91      0.06     0.79     1.03 1.00     2390     2083
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     0.42      0.04     0.35     0.51 1.00     2791     2916
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Even though it may have seemed like we substantially changed the models by fixing the intercepts to 0, the summaries are essentially the same as when we estimated the intercepts. Here we’ll confirm the summaries with a plot, like above.</p>
<pre class="r"><code># wrangle
fitted(f4,
       newdata = nd) %&gt;% 
  as_tibble() %&gt;% 
  bind_cols(nd) %&gt;% 
  
  # plot
  ggplot(aes(x_s)) +
  geom_vline(xintercept = 0, color = &quot;white&quot;) +
  geom_hline(yintercept = 0, color = &quot;white&quot;) +
  geom_point(data = d,
             aes(y = y_s)) +
  geom_smooth(aes(y = Estimate, ymin = Q2.5, ymax = Q97.5),
              stat = &quot;identity&quot;,
              alpha = 1/4, size = 1/2) +
  coord_cartesian(xlim = range(d$x_s),
                  ylim = range(d$y_s))</code></pre>
<p><img src="/post/2019-02-16-bayesian-correlations-let-s-talk-options_files/figure-html/unnamed-chunk-11-1.png" width="336" /></p>
<p>The difference is subtle. By fixing the intercepts at 0, we estimated the slopes (i.e., the correlations) with increased precision as demonstrated by the slightly smaller posterior standard deviations (i.e., the values in the ‘Est.Error’ columns).</p>
<p>Here are the correlation summaries for those last three models.</p>
<pre class="r"><code>fixef(f4) %&gt;% round(3)</code></pre>
<pre><code>##     Estimate Est.Error  Q2.5 Q97.5
## x_s    0.909      0.06 0.789 1.033</code></pre>
<pre class="r"><code>fixef(f5) %&gt;% round(3)</code></pre>
<pre><code>##     Estimate Est.Error  Q2.5 Q97.5
## x_s    0.581     0.117 0.356 0.809</code></pre>
<pre class="r"><code>fixef(f6) %&gt;% round(3)</code></pre>
<pre><code>##     Estimate Est.Error  Q2.5 Q97.5
## y_s    0.311     0.137 0.047 0.585</code></pre>
<p>But anyway, you get the idea. If you want to estimate a correlation in brms using simple univariate syntax, just (a) standardize the data and (b) fit a univariate model with or without an intercept. The slop will be in a correlation-like metric.</p>
</div>
<div id="lets-go-multivariate." class="section level2">
<h2>Let’s go multivariate.</h2>
<p>If you don’t recall the steps to fit correlations in brms with the multivariate syntax, here they are:</p>
<ul>
<li>List the variables you’d like correlations for within <code>cbind()</code>.</li>
<li>Place the <code>cbind()</code> function within the left side of the model formula.</li>
<li>On the right side of the model formula, indicate you only want intercepts (i.e., <code>~ 1</code>).</li>
</ul>
<pre class="r"><code>f7 &lt;- 
  brm(data = d, 
      family = gaussian,
      cbind(x_s, y_s, z_s) ~ 1,
      prior = c(prior(normal(0, 1), class = Intercept),
                prior(normal(1, 1), class = sigma, resp = xs),
                prior(normal(1, 1), class = sigma, resp = ys),
                prior(normal(1, 1), class = sigma, resp = zs),
                prior(lkj(2), class = rescor)),
      chains = 4, cores = 4, 
      seed = 1)</code></pre>
<pre><code>## Warning: Using &#39;cbind&#39; for multivariate models is deprecated. Please use
## &#39;mvbind&#39; instead.

## Warning: Using &#39;cbind&#39; for multivariate models is deprecated. Please use
## &#39;mvbind&#39; instead.</code></pre>
<pre><code>## Warning: Specifying global priors for regression coefficients in multivariate
## models is deprecated and may not work as expected.</code></pre>
<p>Behold the summary.</p>
<pre class="r"><code>print(f7)</code></pre>
<pre><code>##  Family: MV(gaussian, gaussian, gaussian) 
##   Links: mu = identity; sigma = identity
##          mu = identity; sigma = identity
##          mu = identity; sigma = identity 
## Formula: x_s ~ 1 
##          y_s ~ 1 
##          z_s ~ 1 
##    Data: d (Number of observations: 50) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## xs_Intercept    -0.00      0.14    -0.27     0.27 1.00     2290     2309
## ys_Intercept    -0.00      0.14    -0.28     0.26 1.00     2576     2541
## zs_Intercept     0.00      0.14    -0.28     0.28 1.00     3207     2724
## 
## Family Specific Parameters: 
##          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma_xs     0.98      0.10     0.82     1.19 1.00     2378     2551
## sigma_ys     1.00      0.10     0.83     1.22 1.00     2596     2477
## sigma_zs     1.02      0.10     0.84     1.25 1.00     2891     2257
## 
## Residual Correlations: 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## rescor(xs,ys)     0.89      0.03     0.83     0.94 1.00     2778     2696
## rescor(xs,zs)     0.55      0.09     0.35     0.72 1.00     3279     2744
## rescor(ys,zs)     0.25      0.13    -0.01     0.48 1.00     3036     2845
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Look at the ‘Residual Correlations:’ section at the bottom of the output. Since there are no predictors in the model, the residual correlations are just correlations. Now notice how the intercepts in this model are also hovering around 0, just like in our univariate models. Yep, we can fix those, too.</p>
<pre class="r"><code>f8 &lt;- 
  brm(data = d, 
      family = gaussian,
      cbind(x_s, y_s, z_s) ~ 0,
      prior = c(prior(normal(1, 1), class = sigma, resp = xs),
                prior(normal(1, 1), class = sigma, resp = ys),
                prior(normal(1, 1), class = sigma, resp = zs),
                prior(lkj(2), class = rescor)),
      chains = 4, cores = 4, 
      seed = 1)</code></pre>
<pre><code>## Warning: Using &#39;cbind&#39; for multivariate models is deprecated. Please use
## &#39;mvbind&#39; instead.

## Warning: Using &#39;cbind&#39; for multivariate models is deprecated. Please use
## &#39;mvbind&#39; instead.</code></pre>
<p>Without the intercepts, the rest of the model is the same within simulation variance.</p>
<pre class="r"><code>print(f8)</code></pre>
<pre><code>##  Family: MV(gaussian, gaussian, gaussian) 
##   Links: mu = identity; sigma = identity
##          mu = identity; sigma = identity
##          mu = identity; sigma = identity 
## Formula: x_s ~ 0 
##          y_s ~ 0 
##          z_s ~ 0 
##    Data: d (Number of observations: 50) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Family Specific Parameters: 
##          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma_xs     0.98      0.10     0.81     1.18 1.00     2128     2303
## sigma_ys     0.99      0.10     0.82     1.19 1.00     2426     2507
## sigma_zs     1.01      0.10     0.84     1.23 1.00     2749     2157
## 
## Residual Correlations: 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## rescor(xs,ys)     0.90      0.03     0.83     0.94 1.00     2497     2317
## rescor(xs,zs)     0.55      0.09     0.35     0.72 1.00     2865     2147
## rescor(ys,zs)     0.26      0.13    -0.00     0.50 1.00     2631     2201
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>If you wanna get silly, we can prune even further. Did you notice how the estimates for <span class="math inline">\(\sigma\)</span> are all hovering around 1? Since we have no predictors, <span class="math inline">\(\sigma\)</span> is just an estimate of the population standard deviation. And since we’re working with standardized data, the population standard deviation has to be 1. Any other estimate would be nonsensical. So why not fix it to 1?</p>
<p>With brms, we can fix those <span class="math inline">\(\sigma\)</span>s to 1 with a trick of the nonlinear <a href="https://cran.r-project.org/web/packages/brms/vignettes/brms_distreg.html">distributional modeling syntax</a>. Recall when you model <span class="math inline">\(\sigma\)</span>, the brms default is to actually model its log. As is turns out, the log of 1 is zero.</p>
<pre class="r"><code>log(1)</code></pre>
<pre><code>## [1] 0</code></pre>
<p>Here’s how to make use of that within <code>brm()</code>.</p>
<pre class="r"><code>f9 &lt;-
  brm(data = d, 
      family = gaussian,
      bf(cbind(x_s, y_s, z_s) ~ 0,
         sigma ~ 0),
      prior = c(prior(lkj(2), class = rescor)),
      chains = 4, cores = 4, 
      seed = 1)</code></pre>
<pre><code>## Warning: Using &#39;cbind&#39; for multivariate models is deprecated. Please use
## &#39;mvbind&#39; instead.

## Warning: Using &#39;cbind&#39; for multivariate models is deprecated. Please use
## &#39;mvbind&#39; instead.</code></pre>
<p>Other than the <code>sigma ~ 0</code> syntax, the main thing to notice is we’ve wrapped the entire model <code>formula</code> into the <code>bf()</code> function. Here are the results.</p>
<pre class="r"><code>print(f9)</code></pre>
<pre><code>##  Family: MV(gaussian, gaussian, gaussian) 
##   Links: mu = identity; sigma = log
##          mu = identity; sigma = log
##          mu = identity; sigma = log 
## Formula: x_s ~ 0 
##          sigma ~ 0
##          y_s ~ 0 
##          sigma ~ 0
##          z_s ~ 0 
##          sigma ~ 0
##    Data: d (Number of observations: 50) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Residual Correlations: 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## rescor(xs,ys)     0.91      0.02     0.87     0.93 1.00     2984     2786
## rescor(xs,zs)     0.57      0.07     0.42     0.69 1.00     3255     2990
## rescor(ys,zs)     0.29      0.09     0.11     0.46 1.00     2854     2804
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>The correlations are the only things left in the model.</p>
<p>Just to be clear, the multivariate approach does not require standardized data. To demonstrate, here we refit <code>f7</code>, but with the unstandardized variables. And, since we’re no longer in the standardized metric, we’ll be less certain with our priors.</p>
<pre class="r"><code>f10 &lt;- 
  brm(data = d, 
      family = gaussian,
      cbind(x, y, z) ~ 1,
      prior = c(prior(normal(0, 10), class = Intercept),
                prior(student_t(3, 0, 10), class = sigma, resp = x),
                prior(student_t(3, 0, 10), class = sigma, resp = y),
                prior(student_t(3, 0, 10), class = sigma, resp = z),
                prior(lkj(2), class = rescor)),
      chains = 4, cores = 4, 
      seed = 1)</code></pre>
<pre><code>## Warning: Using &#39;cbind&#39; for multivariate models is deprecated. Please use
## &#39;mvbind&#39; instead.

## Warning: Using &#39;cbind&#39; for multivariate models is deprecated. Please use
## &#39;mvbind&#39; instead.</code></pre>
<pre><code>## Warning: Specifying global priors for regression coefficients in multivariate
## models is deprecated and may not work as expected.</code></pre>
<p>See, the ‘rescor()’ results are about the same as with <code>f7</code>.</p>
<pre class="r"><code>print(f10)</code></pre>
<pre><code>##  Family: MV(gaussian, gaussian, gaussian) 
##   Links: mu = identity; sigma = identity
##          mu = identity; sigma = identity
##          mu = identity; sigma = identity 
## Formula: x ~ 1 
##          y ~ 1 
##          z ~ 1 
##    Data: d (Number of observations: 50) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## x_Intercept     9.65      1.21     7.20    12.01 1.00     2188     2301
## y_Intercept    15.61      2.46    10.81    20.39 1.00     2554     2435
## z_Intercept    14.85      3.43     7.94    21.40 1.00     2849     2571
## 
## Family Specific Parameters: 
##         Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma_x     8.96      0.86     7.46    10.81 1.00     1760     2061
## sigma_y    18.14      1.78    15.01    22.04 1.00     1992     2509
## sigma_z    26.07      2.58    21.68    31.70 1.00     2921     2633
## 
## Residual Correlations: 
##             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## rescor(x,y)     0.89      0.03     0.83     0.94 1.00     2244     2470
## rescor(x,z)     0.54      0.09     0.34     0.71 1.00     3330     2827
## rescor(y,z)     0.25      0.12    -0.01     0.48 1.00     2824     2438
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
<div id="its-time-to-compare-methods." class="section level2">
<h2>It’s time to compare methods.</h2>
<p>To recap, we’ve compared several ways to fit correlations in brms. Some of the methods were with univariate syntax, others were with the multivariate syntax. Some of the models had all free parameters, others included fixed intercepts and sigmas. Whereas all the univariate models required standardized data, the multivariate approach can work with unstandardized data, too.</p>
<p>Now it might be of help to compare the results from each of the methods to get a sense of which ones you might prefer. Before we do so, we’ll define a couple custom functions to streamline the data wrangling.</p>
<pre class="r"><code>get_rho &lt;- function(fit) {
  posterior_samples(fit) %&gt;% 
    select(starts_with(&quot;b_&quot;), -contains(&quot;Intercept&quot;)) %&gt;% 
    set_names(&quot;rho&quot;) 
}

get_rescor &lt;- function(fit) {
  posterior_samples(fit) %&gt;% 
    select(starts_with(&quot;rescor&quot;)) %&gt;% 
    set_names(&quot;x with y&quot;, &quot;x with z&quot;, &quot;y with z&quot;) %&gt;% 
    gather(label, rho) %&gt;% 
    select(rho, label)
}</code></pre>
<p>Now let’s put those functions to work and plot.</p>
<pre class="r"><code>library(tidybayes)

# collect the posteriors from the univariate models
tibble(name = str_c(&quot;f&quot;, 1:6)) %&gt;% 
  mutate(fit = map(name, get)) %&gt;% 
  mutate(rho = map(fit, get_rho)) %&gt;% 
  unnest(rho) %&gt;% 
  mutate(predictor = rep(c(&quot;x&quot;, &quot;x&quot;, &quot;y&quot;), each = 4000) %&gt;% rep(., times = 2),
         criterion = rep(c(&quot;y&quot;, &quot;z&quot;, &quot;z&quot;), each = 4000) %&gt;% rep(., times = 2)) %&gt;% 
  mutate(label = str_c(predictor, &quot; with &quot;, criterion)) %&gt;% 
  select(-c(predictor:criterion)) %&gt;% 
  # add in the posteriors from the multivariate models
  bind_rows(
    tibble(name = str_c(&quot;f&quot;, 7:10)) %&gt;% 
      mutate(fit = map(name, get)) %&gt;% 
      mutate(post = map(fit, get_rescor)) %&gt;% 
      unnest(post)
  ) %&gt;% 
  # wrangle a bit just to make the y axis easier to understand
  mutate(name = factor(name, 
                       levels = c(str_c(&quot;f&quot;, 1:10)),
                       labels = c(&quot;1. standardized, univariate&quot;,
                                  &quot;2. standardized, univariate&quot;,
                                  &quot;3. standardized, univariate&quot;,
                                  &quot;4. standardized, univariate, fixed intercepts&quot;,
                                  &quot;5. standardized, univariate, fixed intercepts&quot;,
                                  &quot;6. standardized, univariate, fixed intercepts&quot;,
                                  &quot;7. standardized, multivariate, fixed intercepts&quot;,
                                  &quot;8. standardized, multivariate, fixed intercepts&quot;,
                                  &quot;9. standardized, multivariate, fixed intercepts/sigmas&quot;,
                                  &quot;10. unstandardized, multivariate&quot;))) %&gt;%
  
  # plot
  ggplot(aes(x = rho, y = name)) +
  geom_vline(data = tibble(label = c(&quot;x with y&quot;, &quot;x with z&quot;, &quot;y with z&quot;),
                           rho   = r),
             aes(xintercept = rho), color = &quot;white&quot;) +
  geom_halfeyeh(.width = .95, size = 5/4) +
  scale_x_continuous(breaks = c(0, r)) +
  labs(x = expression(rho),
       y = NULL) +
  coord_cartesian(0:1) +
  theme(axis.ticks.y = element_blank(),
        axis.text.y  = element_text(hjust = 0)) +
  facet_wrap(~label, ncol = 3)</code></pre>
<p><img src="/post/2019-02-16-bayesian-correlations-let-s-talk-options_files/figure-html/unnamed-chunk-19-1.png" width="768" /></p>
<p>To my eye, a few patterns emerged. First, the point estimates were about the same across methods. Second, fixing the intercepts didn’t seem to effect things, much. But, third, it appears that fixing the sigmas in the multivariate models did narrow the posteriors a bit.</p>
<p>Fourth, and perhaps most importantly, notice how the posteriors for the multivariate models were more asymmetric when they approached 1. Hopefully this makes intuitive sense. Correlations are bound between -1 and 1. However, standardized regression coefficients are not so bound. Accordingly, notice how the posteriors from the univariate models stayed symmetric when approaching 1 and some of their right tails even crossed over 1. So while the univariate approach did a reasonable job capturing the correlation point estimates, their posteriors weren’t quite in a correlation metric. Alternately, the univariate approach did make it convenient to express the correlations with fitted regression lines in scatter plots.</p>
<p>Both univariate and multivariate approaches appear to have their strengths and weaknesses. Choose which methods seems most appropriate for your correlation needs.</p>
<p>Happy modeling.</p>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>## R version 3.6.2 (2019-12-12)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS High Sierra 10.13.6
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] tidybayes_2.0.1.9000 GGally_1.4.0         forcats_0.4.0       
##  [4] stringr_1.4.0        dplyr_0.8.4          purrr_0.3.3         
##  [7] readr_1.3.1          tidyr_1.0.2          tibble_2.1.3        
## [10] ggplot2_3.2.1        tidyverse_1.3.0      brms_2.12.0         
## [13] Rcpp_1.0.3           mvtnorm_1.0-12      
## 
## loaded via a namespace (and not attached):
##   [1] colorspace_1.4-1          ellipsis_0.3.0           
##   [3] ggridges_0.5.2            rsconnect_0.8.16         
##   [5] markdown_1.1              base64enc_0.1-3          
##   [7] fs_1.3.1                  rstudioapi_0.10          
##   [9] farver_2.0.3              rstan_2.19.2             
##  [11] svUnit_0.7-12             DT_0.11                  
##  [13] fansi_0.4.1               lubridate_1.7.4          
##  [15] xml2_1.2.2                codetools_0.2-16         
##  [17] bridgesampling_0.8-1      knitr_1.26               
##  [19] shinythemes_1.1.2         bayesplot_1.7.1          
##  [21] jsonlite_1.6.1            broom_0.5.3              
##  [23] dbplyr_1.4.2              shiny_1.4.0              
##  [25] compiler_3.6.2            httr_1.4.1               
##  [27] backports_1.1.5           assertthat_0.2.1         
##  [29] Matrix_1.2-18             fastmap_1.0.1            
##  [31] lazyeval_0.2.2            cli_2.0.1                
##  [33] later_1.0.0               htmltools_0.4.0          
##  [35] prettyunits_1.1.1         tools_3.6.2              
##  [37] igraph_1.2.4.2            coda_0.19-3              
##  [39] gtable_0.3.0              glue_1.3.1               
##  [41] reshape2_1.4.3            cellranger_1.1.0         
##  [43] vctrs_0.2.2               nlme_3.1-142             
##  [45] blogdown_0.17             crosstalk_1.0.0          
##  [47] xfun_0.12                 ps_1.3.0                 
##  [49] rvest_0.3.5               mime_0.8                 
##  [51] miniUI_0.1.1.1            lifecycle_0.1.0          
##  [53] gtools_3.8.1              zoo_1.8-7                
##  [55] scales_1.1.0              colourpicker_1.0         
##  [57] hms_0.5.3                 promises_1.1.0           
##  [59] Brobdingnag_1.2-6         parallel_3.6.2           
##  [61] inline_0.3.15             shinystan_2.5.0          
##  [63] RColorBrewer_1.1-2        yaml_2.2.1               
##  [65] gridExtra_2.3             loo_2.2.0                
##  [67] StanHeaders_2.19.0        reshape_0.8.8            
##  [69] stringi_1.4.6             dygraphs_1.1.1.6         
##  [71] pkgbuild_1.0.6            rlang_0.4.5              
##  [73] pkgconfig_2.0.3           matrixStats_0.55.0       
##  [75] evaluate_0.14             lattice_0.20-38          
##  [77] rstantools_2.0.0          htmlwidgets_1.5.1        
##  [79] labeling_0.3              processx_3.4.1           
##  [81] tidyselect_1.0.0          plyr_1.8.5               
##  [83] magrittr_1.5              bookdown_0.17            
##  [85] R6_2.4.1                  generics_0.0.2           
##  [87] DBI_1.1.0                 pillar_1.4.3             
##  [89] haven_2.2.0               withr_2.1.2              
##  [91] xts_0.12-0                abind_1.4-5              
##  [93] modelr_0.1.5              crayon_1.3.4             
##  [95] arrayhelpers_1.0-20160527 utf8_1.1.4               
##  [97] rmarkdown_2.0             grid_3.6.2               
##  [99] readxl_1.3.1              callr_3.4.1              
## [101] threejs_0.3.3             reprex_0.3.0             
## [103] digest_0.6.23             xtable_1.8-4             
## [105] httpuv_1.5.2              stats4_3.6.2             
## [107] munsell_0.5.0             shinyjs_1.1</code></pre>
</div>

    </div>

    


<div class="article-tags">
  
  <a class="badge badge-light" href="/tags/bayesian/">Bayesian</a>
  
  <a class="badge badge-light" href="/tags/brms/">brms</a>
  
  <a class="badge badge-light" href="/tags/r/">R</a>
  
  <a class="badge badge-light" href="/tags/tutorial/">tutorial</a>
  
</div>




    
    
    <div class="article-widget">
      <div class="hr-light"></div>
      <h3>Related</h3>
      <ul>
        
        <li><a href="/post/bayesian-robust-correlations-with-brms-and-why-you-should-love-student-s-t/">Bayesian robust correlations with brms (and why you should love Student’s $t$)</a></li>
        
        <li><a href="/post/robust-linear-regression-with-the-robust-student-s-t-distribution/">Robust Linear Regression with Student’s $t$-Distribution</a></li>
        
        <li><a href="/post/make-rotated-gaussians-kruschke-style/">Make rotated Gaussians, Kruschke style</a></li>
        
        <li><a href="/post/bayesian-meta-analysis/">Bayesian meta-analysis in brms</a></li>
        
        <li><a href="/post/how-bookdown/">bookdown, My Process</a></li>
        
      </ul>
    </div>
    

    

    


  </div>
</article>

<div class="container">
  <footer class="site-footer">
  
  <p class="powered-by">
    <a href="/privacy/">Privacy Policy</a>
  </p>
  

  <p class="powered-by">
    © 2018 &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

</div>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        CommonHTML: { linebreaks: { automatic: true } },
        tex2jax: { inlineMath: [ ['$', '$'], ['\\(','\\)'] ], displayMath: [ ['$$','$$'], ['\\[', '\\]'] ], processEscapes: false },
        TeX: { noUndefined: { attributes: { mathcolor: 'red', mathbackground: '#FFEEEE', mathsize: '90%' } } },
        messageStyle: 'none'
      });
    </script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha512-+NqPlbbtM1QqiK8ZAo4Yrj2c4lNQoGv8P79DPtKzj++l5jnN39rHA/xsqn8zE9l0uSoxaCdrOgFs6yjyfbBxSg==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha256-VsEqElsCHSGmnmHXGQzvoWjWwoznFSZc6hs7ARLRacQ=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    <script src="/js/hugo-academic.js"></script>
    

    
    

    
    
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "Search Results",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    <script src="/js/search.js"></script>
    

    
    

  </body>
</html>
