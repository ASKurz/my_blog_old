
@book{agrestiFoundationsLinearGeneralized2015,
  title = {Foundations of Linear and Generalized Linear Models},
  author = {Agresti, Alan},
  year = {2015},
  month = jan,
  publisher = {{John Wiley \& Sons}},
  url = {https://www.wiley.com/en-us/Foundations+of+Linear+and+Generalized+Linear+Models-p-9781118730034},
  abstract = {A valuable overview of the most important ideas and results in statistical modeling Written by a highly-experienced author, Foundations of Linear and Generalized Linear Models is a clear and comprehensive guide to the key concepts and results of linearstatistical models. The book presents a broad, in-depth overview of the most commonly usedstatistical models by discussing the theory underlying the models, R software applications,and examples with crafted models to elucidate key ideas and promote practical modelbuilding. The book begins by illustrating the fundamentals of linear models, such as how the model-fitting projects the data onto a model vector subspace and how orthogonal decompositions of the data yield information about the effects of explanatory variables. Subsequently, the book covers the most popular generalized linear models, which include binomial and multinomial logistic regression for categorical data, and Poisson and negative binomial loglinear models for count data. Focusing on the theoretical underpinnings of these models, Foundations ofLinear and Generalized Linear Models also features:  An introduction to quasi-likelihood methods that require weaker distributional assumptions, such as generalized estimating equation methods An overview of linear mixed models and generalized linear mixed models with random effects for clustered correlated data, Bayesian modeling, and extensions to handle problematic cases such as high dimensional problems Numerous examples that use R software for all text data analyses More than 400 exercises for readers to practice and extend the theory, methods, and data analysis A supplementary website with datasets for the examples and exercises  An invaluable textbook for upper-undergraduate and graduate-level students in statistics and biostatistics courses, Foundations of Linear and Generalized Linear Models is also an excellent reference for practicing statisticians and biostatisticians, as well as anyone who is interested in learning about the most important statistical models for analyzing data.},
  googlebooks = {dgIzBgAAQBAJ},
  isbn = {978-1-118-73005-8},
  keywords = {Mathematics / Probability \& Statistics / General,Mathematics / Probability \& Statistics / Stochastic Processes},
  language = {en}
}

@article{atkinsTutorialOnCount2013,
  title = {A Tutorial on Count Regression and Zero-Altered Count Models for Longitudinal Substance Use Data.},
  author = {Atkins, David C and Baldwin, Scott A and Zheng, Cheng and Gallop, Robert J and Neighbors, Clayton},
  year = {2013},
  volume = {27},
  pages = {166},
  publisher = {{American Psychological Association}},
  doi = {10.1037/a0029508},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3513584/pdf/nihms396181.pdf},
  journal = {Psychology of Addictive Behaviors},
  number = {1}
}

@book{brms2020RM,
  title = {{{brms}} Reference Manual, {{Version}} 2.12.0},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2020},
  url = {https://CRAN.R-project.org/package=brms/brms.pdf}
}

@article{burknerAdvancedBayesianMultilevel2018,
  title = {Advanced {{Bayesian}} Multilevel Modeling with the {{R}} Package Brms},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2018},
  volume = {10},
  pages = {395--411},
  doi = {10.32614/RJ-2018-017},
  journal = {The R Journal},
  number = {1}
}

@article{burknerBrmsPackageBayesian2017,
  title = {{{brms}}: {{An R}} Package for {{Bayesian}} Multilevel Models Using {{Stan}}},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2017},
  volume = {80},
  pages = {1--28},
  doi = {10.18637/jss.v080.i01},
  journal = {Journal of Statistical Software},
  number = {1}
}

@book{cohenStatisticalPowerAnalysis1988a,
  title = {Statistical Power Analysis for the Behavioral Sciences},
  author = {Cohen, Jacob},
  year = {1988},
  publisher = {{L. Erlbaum Associates}},
  address = {{Hillsdale, N.J.}},
  url = {https://www.worldcat.org/title/statistical-power-analysis-for-the-behavioral-sciences/oclc/17877467},
  abstract = {This is a nontechnical guide to power analysis in research planning that provides users of applied statistics with the tools they need for more effective analysis. The second edition includes: a chapter covering power analysis in set correlation and multivariate methods; a chapter considering effect size, psychometric reliability, and the efficacy of "qualifying" dependent variables and; expanded power and sample size tables for multiple regression/correlation.},
  isbn = {978-0-8058-0283-2},
  language = {English}
}

@article{gelmanPriorCanOften2017,
  title = {The Prior Can Often Only Be Understood in the Context of the Likelihood},
  author = {Gelman, Andrew and Simpson, Daniel and Betancourt, Michael},
  year = {2017},
  month = oct,
  volume = {19},
  pages = {555},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/e19100555},
  url = {https://www.mdpi.com/1099-4300/19/10/555},
  urldate = {2020-06-12},
  abstract = {A key sticking point of Bayesian analysis is the choice of prior distribution, and there is a vast literature on potential defaults including uniform priors, Jeffreys' priors, reference priors, maximum entropy priors, and weakly informative priors. These methods, however, often manifest a key conceptual tension in prior modeling: a model encoding true prior information should be chosen without reference to the model of the measurement process, but almost all common prior modeling techniques are implicitly motivated by a reference likelihood. In this paper we resolve this apparent paradox by placing the choice of prior into the context of the entire Bayesian analysis, from inference to prediction to model evaluation.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  file = {/Users/solomonkurz/Zotero/storage/GITEJRKC/Gelman et al. - 2017 - The Prior Can Often Only Be Understood in the Cont.pdf;/Users/solomonkurz/Zotero/storage/FD2UD59C/555.html},
  journal = {Entropy},
  keywords = {Bayesian inference,default priors,prior distribution},
  language = {en},
  number = {10}
}

@book{grolemundDataScience2017,
  title = {R for Data Science},
  author = {Grolemund, Garrett and Wickham, Hadley},
  year = {2017},
  publisher = {{O'Reilly}},
  url = {https://r4ds.had.co.nz}
}

@article{ingrahamThinkYouDrink2014,
  title = {Think You Drink a Lot? {{This}} Chart Will Tell You},
  author = {Ingraham, Christopher},
  year = {2014},
  url = {https://www.washingtonpost.com/news/wonk/wp/2014/09/25/think-you-drink-a-lot-this-chart-will-tell-you/?utm_term=.b81599bbbe25},
  journal = {Wonkblog. The Washington Post}
}

@article{josephCommentsBayesianSample1995,
  title = {Some Comments on {{Bayesian}} Sample Size Determination},
  author = {Joseph, Lawrence and Wolfson, David B. and Berger, Roxane Du},
  year = {1995},
  volume = {44},
  pages = {167--171},
  issn = {1467-9884},
  doi = {10.2307/2348442},
  url = {http://www.med.mcgill.ca/epidemiology/Joseph/publications/Methodological/ss_hpd.pdf},
  urldate = {2020-08-15},
  abstract = {Several criteria for Bayesian sample size determination have recently been proposed. Criteria based on highest posterior density (HPD) intervals from the exact posterior distribution in general lead to smaller sample sizes than those based on non-HPD intervals and/or normal approximations to the exact density. The economies are variable, however, and depend both on the prior inputs and the desired posterior accuracy and coverage probability. In our reply we review several properties of sample size methods and discuss the importance of these properties in the context of a binomial experiment. A general algorithm for Bayesian sample size determination that is useful for more complex sampling situations based on Monte Carlo simulations is briefly described.},
  copyright = {\textcopyright{} 1995 Royal Statistical Society},
  file = {/Users/solomonkurz/Zotero/storage/V3ILXR5R/2348442.html},
  journal = {Journal of the Royal Statistical Society: Series D (The Statistician)},
  language = {en},
  number = {2}
}

@article{josephSampleSizeCalculations1995,
  title = {Sample Size Calculations for Binomial Proportions via Highest Posterior Density Intervals},
  author = {Joseph, Lawrence and Wolfson, David B. and Berger, Roxane Du},
  year = {1995},
  volume = {44},
  pages = {143--154},
  issn = {1467-9884},
  doi = {10.2307/2348439},
  url = {https://www.medicine.mcgill.ca/epidemiology/Joseph/publications\%5CMethodological\%5Css_binom.pdf},
  urldate = {2020-08-15},
  abstract = {Three different Bayesian approaches to sample size calculations based on highest posterior density (HPD) intervals are discussed and illustrated in the context of a binomial experiment. The preposterior marginal distribution of the data is used to find the sample size needed to attain an expected HPD coverage probability for a given fixed interval length. Alternatively, one can find the sample size required to attain an expected HPD interval length for a fixed coverage. These two criteria can lead to different sample size requirements. In addition to averaging, a worst possible outcome scenario is also considered. The results presented here provide an exact solution to a problem recently addressed in the literature.},
  copyright = {\textcopyright{} 1995 Royal Statistical Society},
  file = {/Users/solomonkurz/Zotero/storage/QHE97GKD/2348439.html},
  journal = {Journal of the Royal Statistical Society: Series D (The Statistician)},
  keywords = {Bayesian design,Binomial proportions,Sample size calculations},
  language = {en},
  number = {2}
}

@book{kruschkeDoingBayesianData2015,
  title = {Doing {{Bayesian}} Data Analysis: {{A}} Tutorial with {{R}}, {{JAGS}}, and {{Stan}}},
  author = {Kruschke, John K.},
  year = {2015},
  publisher = {{Academic Press}},
  url = {https://sites.google.com/site/doingbayesiandataanalysis/}
}

@book{kurzDoingBayesianData2020,
  title = {Doing {{Bayesian}} Data Analysis in Brms and the Tidyverse},
  author = {Kurz, A. Solomon},
  year = {2020},
  month = may,
  edition = {version 0.2.0},
  url = {https://bookdown.org/content/3686/},
  urldate = {2020-05-22},
  abstract = {This project is an attempt to re-express the code in Kruschke's (2015) textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style.},
  file = {/Users/solomonkurz/Zotero/storage/UKHWZ73Z/3686.html}
}

@book{kurzStatisticalRethinkingBrms2020,
  title = {Statistical Rethinking with Brms, Ggplot2, and the Tidyverse},
  author = {Kurz, A. Solomon},
  year = {2020},
  month = mar,
  edition = {version 1.1.0},
  doi = {10.5281/zenodo.3693202},
  url = {https://bookdown.org/content/3890/},
  urldate = {2020-05-16},
  abstract = {This project is an attempt to re-express the code in McElreath's textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style.},
  file = {/Users/solomonkurz/Zotero/storage/MTCXZRHZ/3890.html}
}

@book{kurzStatisticalRethinkingSecondEd2020,
  title = {Statistical Rethinking with Brms, Ggplot2, and the Tidyverse: {{Second}} Edition},
  author = {Kurz, A. Solomon},
  year = {2020},
  month = jun,
  edition = {version 0.0.2},
  url = {https://bookdown.org/content/4857/},
  urldate = {2020-06-30},
  abstract = {This book is an attempt to re-express the code in the second edition of McElreath's textbook, 'Statistical rethinking.' His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style.}
}

@article{maxwellSampleSizePlanning2008,
  title = {Sample Size Planning for Statistical Power and Accuracy in Parameter Estimation},
  author = {Maxwell, Scott E. and Kelley, Ken and Rausch, Joseph R.},
  year = {2008},
  volume = {59},
  pages = {537--563},
  doi = {10.1146/annurev.psych.59.103006.093735},
  url = {https://www3.nd.edu/~kkelley/publications/articles/Maxwell_Kelley_Rausch_2008.pdf},
  urldate = {2020-08-14},
  abstract = {This review examines recent advances in sample size planning, not only from the perspective of an individual researcher, but also with regard to the goal of developing cumulative knowledge. Psychologists have traditionally thought of sample size planning in terms of power analysis. Although we review recent advances in power analysis, our main focus is the desirability of achieving accurate parameter estimates, either instead of or in addition to obtaining sufficient power. Accuracy in parameter estimation (AIPE) has taken on increasing importance in light of recent emphasis on effect size estimation and formation of confidence intervals. The review provides an overview of the logic behind sample size planning for AIPE and summarizes recent advances in implementing this approach in designs commonly used in psychological research.},
  file = {/Users/solomonkurz/Zotero/storage/A3Q2R3HH/Maxwell et al. - 2008 - Sample Size Planning for Statistical Power and Acc.pdf},
  journal = {Annual Review of Psychology},
  number = {1},
  pmid = {17937603}
}

@book{mcelreathStatisticalRethinkingBayesian2015,
  title = {Statistical Rethinking: {{A Bayesian}} Course with Examples in {{R}} and {{Stan}}},
  author = {McElreath, Richard},
  year = {2015},
  publisher = {{CRC press}},
  url = {https://xcelab.net/rm/statistical-rethinking/}
}

@book{mcelreathStatisticalRethinkingBayesian2020,
  title = {Statistical Rethinking: {{A Bayesian}} Course with Examples in {{R}} and {{Stan}}},
  shorttitle = {Statistical {{Rethinking}}},
  author = {McElreath, Richard},
  year = {2020},
  month = mar,
  edition = {Second edition},
  publisher = {{CRC Press}},
  url = {https://xcelab.net/rm/statistical-rethinking/},
  abstract = {Statistical Rethinking: A Bayesian Course with Examples in R and Stan builds your knowledge of and confidence in making inferences from data. Reflecting the need for scripting in today's model-based statistics, the book pushes you to perform step-by-step calculations that are usually automated. This unique computational approach ensures that you understand enough of the details to make reasonable choices and interpretations in your own modeling work.  The text presents causal inference and generalized linear multilevel models from a simple Bayesian perspective that builds on information theory and maximum entropy. The core material ranges from the basics of regression to advanced multilevel models. It also presents measurement error, missing data, and Gaussian process models for spatial and phylogenetic confounding.  The second edition emphasizes the directed acyclic graph (DAG) approach to causal inference, integrating DAGs into many examples. The new edition also contains new material on the design of prior distributions, splines, ordered categorical predictors, social relations models, cross-validation, importance sampling, instrumental variables, and Hamiltonian Monte Carlo. It ends with an entirely new chapter that goes beyond generalized linear modeling, showing how domain-specific scientific models can be built into statistical analyses.  Features   Integrates working code into the main text   Illustrates concepts through worked data analysis examples   Emphasizes understanding assumptions and how assumptions are reflected in code   Offers more detailed explanations of the mathematics in optional sections   Presents examples of using the dagitty R package to analyze causal graphs   Provides the rethinking R package on the author's website and on GitHub},
  isbn = {978-0-429-63914-2},
  keywords = {Mathematics / Probability \& Statistics / General},
  language = {en}
}

@article{moreyBayesFactorApproaches2011,
  title = {Bayes Factor Approaches for Testing Interval Null Hypotheses},
  author = {Morey, Richard D. and Rouder, Jeffrey N.},
  year = {2011},
  volume = {16},
  pages = {406--419},
  doi = {10.1037/a0024377},
  url = {https://d1wqtxts1xzle7.cloudfront.net/45416179/Bayes_Factor_Approaches_for_Testing_Inte20160506-23207-1t89l96.pdf?1462571611=\&response-content-disposition=inline\%3B+filename\%3DBayes_factor_approaches_for_testing_inte.pdf\&Expires=1597530412\&Signature=QAJQOISIvwxUlHd2uTfzgOMzf2TRcuWTcfwgki7JL4AIoYDziVCAfmDFOgUDi-h1mMEViTKFhOLTJF0-9u2IEyF2lR7-yhM67CYdKhqs8EEJOnhT9iK9MaaM2FBwZM8QoVtOXkOUaOXRHIt7C76UV5dbErTUx0r5Y1yym4a~-hDClb0696a6EB~dj0arYeDdylP7a3tfczmSxbIvrH8pOE4kQeHwsZXoANSh-eKXKYIYf6VD1yed~CSVPRkqlhMq6udOjg4INPZ33QBv3QQqYCk2esRC2DxxNmDF~rRVrIp0ebr6VMZkuMflVaj2~I2BFz7WS32Lb2hGFHT3jHskDA__\&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA},
  journal = {Psychological Methods},
  number = {4}
}

@article{niaaaNationalEpidemiologicSurvey2006,
  title = {National Epidemiologic Survey on Alcohol and Related Conditions},
  author = {{\{National Institute on Alcohol Abuse\}} and {Alcoholism}},
  year = {2006},
  publisher = {{National Institutes of Health Washington, DC}},
  url = {https://pubs.niaaa.nih.gov/publications/AA70/AA70.htm}
}

@book{pengProgrammingDataScience2019,
  title = {R Programming for Data Science},
  author = {Peng, Roger D.},
  year = {2019},
  url = {https://bookdown.org/rdpeng/rprogdatascience/}
}

@book{R-base,
  title = {R: {{A}} Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  year = {2020},
  publisher = {{R Foundation for Statistical Computing}},
  address = {{Vienna, Austria}},
  url = {https://www.R-project.org/}
}

@book{R-brms,
  title = {{{brms}}: {{Bayesian}} Regression Models Using '{{Stan}}'},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2020},
  url = {https://CRAN.R-project.org/package=brms}
}

@book{R-tidyverse,
  title = {{{tidyverse}}: {{Easily}} Install and Load the 'Tidyverse'},
  author = {Wickham, Hadley},
  year = {2019},
  url = {https://CRAN.R-project.org/package=tidyverse}
}

@article{rouderBayesianTestsAccepting2009,
  title = {Bayesian t Tests for Accepting and Rejecting the Null Hypothesis},
  author = {Rouder, Jeffrey N. and Speckman, Paul L. and Sun, Dongchu and Morey, Richard D. and Iverson, Geoffrey},
  year = {2009},
  month = apr,
  volume = {16},
  pages = {225--237},
  issn = {1531-5320},
  doi = {10.3758/PBR.16.2.225},
  url = {https://doi.org/10.3758/PBR.16.2.225},
  urldate = {2020-08-15},
  abstract = {Progress in science often comes from discovering invariances in relationships among variables; these invariances often correspond to null hypotheses. As is commonly known, it is not possible to state evidence for the null hypothesis in conventional significance testing. Here we highlight a Bayes factor alternative to the conventional t test that will allow researchers to express preference for either the null hypothesis or the alternative. The Bayes factor has a natural and straightforward interpretation, is based on reasonable assumptions, and has better properties than other methods of inference that have been advocated in the psychological literature. To facilitate use of the Bayes factor, we provide an easy-to-use, Web-based program that performs the necessary calculations.},
  file = {/Users/solomonkurz/Zotero/storage/2WAUSYVQ/Rouder et al. - 2009 - Bayesian t tests for accepting and rejecting the n.pdf},
  journal = {Psychonomic Bulletin \& Review},
  language = {en},
  number = {2}
}

@misc{standevelopmentteamRStanInterfaceStan2020,
  title = {{{RStan}}: The {{R}} Interface to {{Stan}}},
  author = {{Stan Development Team}},
  year = {2020},
  month = feb,
  url = {https://cran.r-project.org/web/packages/rstan/vignettes/rstan.html},
  urldate = {2020-05-22},
  file = {/Users/solomonkurz/Zotero/storage/UNLVDTJP/rstan.html}
}

@book{standevelopmentteamStanReferenceManual2020,
  title = {Stan Reference Manual, {{Version}} 2.23},
  author = {{Stan Development Team}},
  year = {2020},
  url = {https://mc-stan.org/docs/2_23/reference-manual/}
}

@book{standevelopmentteamStanUserGuide2020,
  title = {Stan User's Guide, {{Version}} 2.23},
  author = {{Stan Development Team}},
  year = {2020},
  url = {https://mc-stan.org/docs/2_23/stan-users-guide/index.html}
}

@article{wassersteinMovingWorld052019,
  title = {Moving to a {{World Beyond}} ``p {$<$} 0.05''},
  author = {Wasserstein, Ronald L. and Schirm, Allen L. and Lazar, Nicole A.},
  year = {2019},
  month = mar,
  volume = {73},
  pages = {1--19},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1080/00031305.2019.1583913},
  url = {https://doi.org/10.1080/00031305.2019.1583913},
  urldate = {2020-08-15},
  file = {/Users/solomonkurz/Zotero/storage/JSNMWIEI/Wasserstein et al. - 2019 - Moving to a World Beyond “p  0.05”.pdf;/Users/solomonkurz/Zotero/storage/GPI57NZ4/00031305.2019.html},
  journal = {The American Statistician},
  number = {sup1}
}

@book{wickhamTidyverseStyleGuide2020,
  title = {The Tidyverse Style Guide},
  author = {Wickham, Hadley},
  year = {2020},
  url = {https://style.tidyverse.org/}
}

@article{wickhamWelcomeTidyverse2019,
  title = {Welcome to the Tidyverse},
  author = {Wickham, Hadley and Averick, Mara and Bryan, Jennifer and Chang, Winston and McGowan, Lucy D'Agostino and Fran{\c c}ois, Romain and Grolemund, Garrett and Hayes, Alex and Henry, Lionel and Hester, Jim and Kuhn, Max and Pedersen, Thomas Lin and Miller, Evan and Bache, Stephan Milton and M{\"u}ller, Kirill and Ooms, Jeroen and Robinson, David and Seidel, Dana Paige and Spinu, Vitalie and Takahashi, Kohske and Vaughan, Davis and Wilke, Claus and Woo, Kara and Yutani, Hiroaki},
  year = {2019},
  volume = {4},
  pages = {1686},
  doi = {10.21105/joss.01686},
  journal = {Journal of Open Source Software},
  number = {43}
}


