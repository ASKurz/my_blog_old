<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bayesian on A. Solomon Kurz</title>
    <link>/tags/bayesian/</link>
    <description>Recent content in Bayesian on A. Solomon Kurz</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Sat, 23 Feb 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/bayesian/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Stein’s Paradox and What Partial Pooling Can Do For You</title>
      <link>/post/stein-s-paradox-and-what-partial-pooling-can-do-for-you/</link>
      <pubDate>Sat, 23 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/stein-s-paradox-and-what-partial-pooling-can-do-for-you/</guid>
      <description>tl;dr  Sometimes a mathematical result is strikingly contrary to generally held belief even though an obviously valid proof is given. Charles Stein of Stanford University discovered such a paradox in statistics in 1995. His result undermined a century and a half of work on estimation theory. (p. 119) The James-Stein estimator leads to better predictions than simple means. Though I don’t recommend you actually use the James-Stein estimator in applied research, understanding why it works might help clarify why it’s time social scientists default to multilevel models for applied statistics.</description>
    </item>
    
    <item>
      <title>Bayesian Correlations: Let’s Talk Options.</title>
      <link>/post/bayesian-correlations-let-s-talk-options/</link>
      <pubDate>Sat, 16 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/bayesian-correlations-let-s-talk-options/</guid>
      <description>tl;dr There’s more than one way to fit a Bayesian correlation in brms.
 Here’s the deal. In the last post, we considered how we might estimate correlations when our data contain influential outlier values. Our big insight was that if we use variants of Student’s \(t\)-distribution as the likelihood rather than the conventional normal distribution, our correlation estimates were less influenced by those outliers. And we mainly did that as Bayesians using the brms package.</description>
    </item>
    
    <item>
      <title>Bayesian robust correlations with brms (and why you should love Student’s $t$)</title>
      <link>/post/bayesian-robust-correlations-with-brms-and-why-you-should-love-student-s-t/</link>
      <pubDate>Sun, 10 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/bayesian-robust-correlations-with-brms-and-why-you-should-love-student-s-t/</guid>
      <description>In this post, we’ll show how Student’s \(t\)-distribution can produce better correlation estimates when your data have outliers. As is often the case, we’ll do so as Bayesians.
This post is a direct consequence of Adrian Baez-Ortega’s great blog, “Bayesian robust correlation with Stan in R (and why you should use Bayesian methods)”. Baez-Ortega worked out the approach and code for direct use with Stan computational environment. That solution is great because Stan is free, open source, and very flexible.</description>
    </item>
    
    <item>
      <title>Robust Linear Regression with Student’s $t$-Distribution</title>
      <link>/post/robust-linear-regression-with-the-robust-student-s-t-distribution/</link>
      <pubDate>Sat, 02 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/robust-linear-regression-with-the-robust-student-s-t-distribution/</guid>
      <description>[edited Feb 3, 2018]
The purpose of this post is to demonstrate the advantages of the Student’s \(t\)-distribution for regression with outliers, particularly within a Bayesian framework.
I make assumptions I’m presuming you are familiar with linear regression, familiar with the basic differences between frequentist and Bayesian approaches to fitting regression models, and have a sense that the issue of outlier values is a pickle worth contending with. All code in is R, with a heavy use of the tidyverse–which you might learn a lot about here, especially chapter 5– and Paul Bürkner’s brms package.</description>
    </item>
    
    <item>
      <title>Make rotated Gaussians, Kruschke style</title>
      <link>/post/make-rotated-gaussians-kruschke-style/</link>
      <pubDate>Thu, 20 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/make-rotated-gaussians-kruschke-style/</guid>
      <description>[edited Dec 23, 2018]
tl;dr You too can make sideways Gaussian density curves within the tidyverse. Here’s how.
 Here’s the deal: I like making pictures. Over the past several months, I’ve been slowly chipping away at John Kruschke’s Doing Bayesian data analysis, Second Edition: A tutorial with R, JAGS, and Stan. Kruschke has a unique plotting style. One of the quirks is once in a while he likes to express the results of his analyses in plots where he shows the data alongside density curves of the model-implied data-generating distributions.</description>
    </item>
    
    <item>
      <title>Bayesian meta-analysis in brms</title>
      <link>/post/bayesian-meta-analysis/</link>
      <pubDate>Sun, 14 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/bayesian-meta-analysis/</guid>
      <description>Preamble I released the first bookdown version of my Statistical Rethinking with brms, ggplot2, and the tidyverse project a couple weeks ago. I consider it the 0.9.0 version. I wanted a little time to step back from the project before giving it a final edit for the first major edition. I also wanted to give others a little time to take a look and suggest edits, which some thankfully have.</description>
    </item>
    
    <item>
      <title>bookdown, My Process</title>
      <link>/post/how-bookdown/</link>
      <pubDate>Thu, 04 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/how-bookdown/</guid>
      <description>tl;dr I just self-published a book-length version of my project Statistical Rethinking with brms, ggplot2, and the tidyverse. By using Yihui Xie’s bookdown package, I was able to do it for free. If you’ve never heard of it, bookdown enables R users to write books and other long-form articles with R Markdown. You can save your bookdown products in a variety of formats (e.g., PDF, HTML) and publish them in several ways, too.</description>
    </item>
    
  </channel>
</rss>