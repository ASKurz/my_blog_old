<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>A. Solomon Kurz on A. Solomon Kurz</title>
    <link>/</link>
    <description>Recent content in A. Solomon Kurz on A. Solomon Kurz</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Sat, 29 Sep 2018 00:00:00 -0500</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Would you like all your posteriors in one plot?</title>
      <link>/post/would-you-like-all-your-posteriors-in-one-plot/</link>
      <pubDate>Sat, 13 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/would-you-like-all-your-posteriors-in-one-plot/</guid>
      <description>&lt;p&gt;A colleague reached out to me earlier this week with a plotting question. They had fit a series of Bayesian models, all containing a common parameter of interest. They knew how to plot their focal parameter one model at a time, but were stumped on how to combine the plots across models into a seamless whole. It reminded me a bit of this gif&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/Bqn8Z7xdPCFy0/giphy.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;which I originally got from &lt;a href=&#34;https://twitter.com/JennyBryan&#34;&gt;Jenny Bryan&lt;/a&gt;’s great talk, &lt;a href=&#34;https://www.youtube.com/watch?v=4MfUCX_KpdE&#34;&gt;&lt;em&gt;Behind every great plot there’s a great deal of wrangling&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The goal of this post is to provide solutions. We’ll practice a few different ways you can combine the posterior samples from your Bayesian models into a single plot. As usual, we’ll be fitting our models with &lt;a href=&#34;https://github.com/paul-buerkner/brms&#34;&gt;&lt;strong&gt;brms&lt;/strong&gt;&lt;/a&gt;, wrangling with packages from the &lt;a href=&#34;https://www.tidyverse.org&#34;&gt;&lt;strong&gt;tidyverse&lt;/strong&gt;&lt;/a&gt;, and getting a little help from the &lt;a href=&#34;https://mjskay.github.io/tidybayes/index.html&#34;&gt;&lt;strong&gt;tidybayes&lt;/strong&gt; package&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;i-make-assumptions.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;I make assumptions.&lt;/h2&gt;
&lt;p&gt;For this post, I’m presuming you are familiar Bayesian regression using &lt;strong&gt;brms.&lt;/strong&gt; I’m also assuming you’ve coded using some of the foundational functions from the &lt;strong&gt;tidyverse.&lt;/strong&gt; If you’d like to firm up your foundations a bit, check out these resources.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;To learn about Bayesian regression, I recommend the introductory text books by either McElreath (&lt;a href=&#34;(%5Bhere%5D())&#34;&gt;here&lt;/a&gt;) or Kruschke (&lt;a href=&#34;http://www.indiana.edu/~kruschke/DoingBayesianDataAnalysis/&#34;&gt;here&lt;/a&gt;). Both authors host blogs (&lt;a href=&#34;http://doingbayesiandataanalysis.blogspot.com&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;http://elevanth.org/blog/&#34;&gt;here&lt;/a&gt;, respectively). If you go with McElreath, do check out his &lt;a href=&#34;https://www.youtube.com/channel/UCNJK6_DZvcMqNSzQdEkzvzA/playlists&#34;&gt;online lectures&lt;/a&gt; and &lt;a href=&#34;https://bookdown.org/connect/#/apps/1850/access&#34;&gt;my project&lt;/a&gt; translating his text to &lt;strong&gt;brms&lt;/strong&gt; and &lt;strong&gt;tidyverse&lt;/strong&gt; code. I’m working on a &lt;a href=&#34;https://github.com/ASKurz/Doing-Bayesian-Data-Analysis-in-brms-and-the-tidyverse&#34;&gt;similar project&lt;/a&gt; for Kruschke’s text, but it still has a ways to go before I release it in full.&lt;/li&gt;
&lt;li&gt;For even more &lt;strong&gt;brms&lt;/strong&gt;-related resources, you can find vignettes and documentation &lt;a href=&#34;https://cran.r-project.org/web/packages/brms/index.html&#34;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;For &lt;strong&gt;tidyverse&lt;/strong&gt; introductions, your best bets are &lt;a href=&#34;https://r4ds.had.co.nz&#34;&gt;&lt;em&gt;R4DS&lt;/em&gt;&lt;/a&gt; and &lt;a href=&#34;https://style.tidyverse.org&#34;&gt;&lt;em&gt;The tidyverse style guide&lt;/em&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;same-parameter-different-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Same parameter, different models&lt;/h2&gt;
&lt;p&gt;Let’s load our primary statistical packages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(brms)
library(tidybayes)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Simulate &lt;span class=&#34;math inline&#34;&gt;\(n = 150\)&lt;/span&gt; draws from the standard normal distribution.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- 150

set.seed(1)
d &amp;lt;-
  tibble(y = rnorm(n, mean = 0, sd = 1))

head(d)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 1
##        y
##    &amp;lt;dbl&amp;gt;
## 1 -0.626
## 2  0.184
## 3 -0.836
## 4  1.60 
## 5  0.330
## 6 -0.820&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here we’ll fit three intercept-only models for &lt;code&gt;y&lt;/code&gt;. Each will follow the form&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
y_i     &amp;amp; \sim \text{Normal} (\mu, \sigma) \\
\mu     &amp;amp; = \beta_0 \\
\beta_0 &amp;amp; \sim \text{Normal} (0, x) \\
\sigma  &amp;amp; \sim \text{Student-t}(3, 0, 10)
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; is the unconditional intercept (i.e., an intercept not conditioned on any predictors). We will be fitting three alternative models. All will have the same prior for &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\text{Student-t}(3, 0, 10)\)&lt;/span&gt;, which is the &lt;strong&gt;brms&lt;/strong&gt; default in this case. [If you’d like to check, use the &lt;code&gt;get_prior()&lt;/code&gt; function.] The only way the models will differ is by their prior on the intercept &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt;. By model, those priors will be&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;fit1&lt;/code&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\beta_0 \sim \text{Normal} (0, 10)\)&lt;/span&gt;,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fit2&lt;/code&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\beta_0 \sim \text{Normal} (0, 1)\)&lt;/span&gt;, and&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fit3&lt;/code&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\beta_0 \sim \text{Normal} (0, 0.1)\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So if you were wondering, the &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; in the &lt;span class=&#34;math inline&#34;&gt;\(\beta_0 \sim \text{Normal} (0, x)\)&lt;/span&gt; line, above, was a stand-in for the varying &lt;a href=&#34;https://en.wikipedia.org/wiki/Hyperparameter&#34;&gt;hyperparameter&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here we fit the models in bulk.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit1 &amp;lt;-
  brm(data = d,
      family = gaussian,
      y ~ 1,
      prior(normal(0, 10), class = Intercept),
      seed = 1)

fit2 &amp;lt;-
  update(fit1,
         prior = prior(normal(0, 1), class = Intercept),
         seed = 1)

fit3 &amp;lt;-
  update(fit1,
         prior = prior(normal(0, 0.1), class = Intercept),
         seed = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Normally we’d use &lt;code&gt;plot()&lt;/code&gt; to make sure the chains look good and then use something like &lt;code&gt;print()&lt;/code&gt; or &lt;code&gt;posterior_summary()&lt;/code&gt; to summarize the models’ results. I’ve checked and they’re all fine. For the sake of space, let’s press forward.&lt;/p&gt;
&lt;p&gt;If you were going to plot the results of an individual fit using something like the &lt;code&gt;tidybayes::geom_halfeyeh()&lt;/code&gt; function, the next step would be extracting the posterior draws. Here we’ll do so with the &lt;code&gt;brms::posterior_samples()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;post1 &amp;lt;- posterior_samples(fit1)
post2 &amp;lt;- posterior_samples(fit2)
post3 &amp;lt;- posterior_samples(fit3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Focusing on &lt;code&gt;fit1&lt;/code&gt;, here’s how we’d plot the results for the intercept &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# this part is unnecessary; it just adjusts some theme defaults to my liking
theme_set(theme_gray() +
            theme(axis.text.y  = element_text(hjust = 0),
                  axis.ticks.y = element_blank(),
                  panel.grid   = element_blank()))

# plot!
post1 %&amp;gt;% 
  ggplot(aes(x = b_Intercept, y = 0)) +
  geom_halfeyeh() +
  scale_y_continuous(NULL, breaks = NULL)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-07-13-would-you-like-all-your-posteriors-in-one-plot_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;But how might we get the posterior draws from all three fits into one plot?&lt;/em&gt; The answer is by somehow combining the posterior draws from each into one data frame. There are many ways to do this. Perhaps the simplest is with the &lt;code&gt;bind_rows()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posts &amp;lt;-
  bind_rows(
    post1,
    post2,
    post3
  ) %&amp;gt;% 
  mutate(prior = str_c(&amp;quot;normal(0, &amp;quot;, c(10, 1, 0.1), &amp;quot;)&amp;quot;) %&amp;gt;% rep(., each = 4000))

head(posts)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    b_Intercept     sigma      lp__         prior
## 1 -0.052176422 0.8568091 -204.1751 normal(0, 10)
## 2  0.124990457 0.8983495 -204.1663 normal(0, 10)
## 3 -0.006294612 0.9475288 -203.5528 normal(0, 10)
## 4  0.060904410 0.9410559 -203.5319 normal(0, 10)
## 5  0.177594575 0.9457762 -205.4991 normal(0, 10)
## 6  0.134879573 0.9267331 -204.3765 normal(0, 10)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;bind_rows()&lt;/code&gt; function worked well, here, because all three post objects had the same number of columns of the same names. So we just stacked them three high. That is, we went from three data objects of 4,000 rows and 3 columns to one data object with 12,000 rows and 3 columns. But with the &lt;code&gt;mutate()&lt;/code&gt; function we did add a fourth column, &lt;code&gt;prior&lt;/code&gt;, that indexed which model each row came from. Now our data are ready, we can plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posts %&amp;gt;% 
  ggplot(aes(x = b_Intercept, y = prior)) +
  geom_halfeyeh()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-07-13-would-you-like-all-your-posteriors-in-one-plot_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Our plot arrangement made it easy to compare the results of tightening the prior on &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt;; the narrower the prior, the narrower the posterior.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-if-my-posterior_samples-arent-of-the-same-dimensions-across-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What if my &lt;code&gt;posterior_samples()&lt;/code&gt; aren’t of the same dimensions across models?&lt;/h2&gt;
&lt;p&gt;For the next examples, we need new data. Here we’ll simulate three predictors–&lt;code&gt;x1&lt;/code&gt;, &lt;code&gt;x2&lt;/code&gt;, and &lt;code&gt;x3&lt;/code&gt;. We then simulate our criterion &lt;code&gt;y&lt;/code&gt; as a linear additive function of those predictors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1)
d &amp;lt;-
  tibble(x1 = rnorm(n, mean = 0, sd = 1),
         x2 = rnorm(n, mean = 0, sd = 1),
         x3 = rnorm(n, mean = 0, sd = 1)) %&amp;gt;% 
  mutate(y  = rnorm(n, mean = 0 + x1 * 0 + x2 * 0.2 + x3 * -0.4))

head(d)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 4
##       x1      x2     x3      y
##    &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 -0.626  0.450   0.894  0.694
## 2  0.184 -0.0186 -1.05  -0.189
## 3 -0.836 -0.318   1.97  -1.61 
## 4  1.60  -0.929  -0.384 -1.59 
## 5  0.330 -1.49    1.65  -2.41 
## 6 -0.820 -1.08    1.51  -0.764&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We are going to work with these data in two ways. For the first example, we’ll fit a series of univariable models following the same basic form, but each with a different predictor. For the second example, we’ll fit a series of multivariable models with various combinations of the predictors. Each requires its own approach.&lt;/p&gt;
&lt;div id=&#34;same-form-different-predictors.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Same form, different predictors.&lt;/h3&gt;
&lt;p&gt;This time we’re just using the &lt;strong&gt;brms&lt;/strong&gt; default priors. As such, the models all follow the form&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
y_i     &amp;amp; \sim \text{Normal} (\mu_i, \sigma) \\
\mu_i   &amp;amp; = \beta_0 + \beta_n x_n\\
\beta_0 &amp;amp; \sim \text{Student-t}(3, 0, 10) \\
\sigma  &amp;amp; \sim \text{Student-t}(3, 0, 10)
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;You may be wondering &lt;em&gt;What about the prior for&lt;/em&gt; &lt;span class=&#34;math inline&#34;&gt;\(\beta_n\)&lt;/span&gt;&lt;em&gt;?&lt;/em&gt; The &lt;strong&gt;brms&lt;/strong&gt; defaults for those are improper flat priors. We define &lt;span class=&#34;math inline&#34;&gt;\(\beta_n x_n\)&lt;/span&gt; for the next three models as&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;fit4&lt;/code&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\beta_1 x_1\)&lt;/span&gt;,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fit5&lt;/code&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\beta_2 x_2\)&lt;/span&gt;, and&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fit5&lt;/code&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\beta_3 x_3\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let’s fit the models.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit4 &amp;lt;-
  brm(data = d,
      family = gaussian,
      y ~ 1 + x1,
      seed = 1)

fit5 &amp;lt;-
  update(fit4,
         newdata = d,
         y ~ 1 + x2,
         seed = 1)

fit6 &amp;lt;-
  update(fit4,
         newdata = d,
         y ~ 1 + x3,
         seed = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Like before, save the posterior draws for each as separate data frames.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;post4 &amp;lt;- posterior_samples(fit4)
post5 &amp;lt;- posterior_samples(fit5)
post6 &amp;lt;- posterior_samples(fit6)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This time, our simple &lt;code&gt;bind_rows()&lt;/code&gt; trick won’t work well.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bind_rows(
  post4,
  post5,
  post6
) %&amp;gt;% 
  head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    b_Intercept         b_x1    sigma      lp__ b_x2 b_x3
## 1  0.167513067 -0.179568244 1.154730 -243.4799   NA   NA
## 2 -0.017092084 -0.281401589 1.145705 -243.1930   NA   NA
## 3 -0.036944855 -0.204756757 1.191577 -242.1853   NA   NA
## 4  0.041075341 -0.009902425 1.183252 -242.0840   NA   NA
## 5  0.032423912 -0.050100545 1.147125 -241.8424   NA   NA
## 6  0.003649314 -0.161764444 1.183537 -241.7794   NA   NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We don’t want separate columns for &lt;code&gt;b_x1&lt;/code&gt;, &lt;code&gt;b_x2&lt;/code&gt;, and &lt;code&gt;b_x3&lt;/code&gt;. We want them all stacked atop one another. One simple solution is a two-step wherein we (1) select the relevant columns from each and bind them together with &lt;code&gt;bind_cols()&lt;/code&gt; and then (2) stack them atop one another with the &lt;code&gt;gather()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posts &amp;lt;-
  bind_cols(
    post4 %&amp;gt;% select(b_x1),
    post5 %&amp;gt;% select(b_x2),
    post6 %&amp;gt;% select(b_x3)
  ) %&amp;gt;% 
  gather() %&amp;gt;% 
  mutate(predictor = str_remove(key, &amp;quot;b_&amp;quot;))

head(posts)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    key        value predictor
## 1 b_x1 -0.179568244        x1
## 2 b_x1 -0.281401589        x1
## 3 b_x1 -0.204756757        x1
## 4 b_x1 -0.009902425        x1
## 5 b_x1 -0.050100545        x1
## 6 b_x1 -0.161764444        x1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That &lt;code&gt;mutate()&lt;/code&gt; line at the end wasn’t necessary, but it will make the plot more attractive.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posts %&amp;gt;% 
  ggplot(aes(x = value, y = predictor)) +
  geom_halfeyeh()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-07-13-would-you-like-all-your-posteriors-in-one-plot_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;different-combinations-of-predictors-in-different-forms.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Different combinations of predictors in different forms.&lt;/h3&gt;
&lt;p&gt;Now we fit a series of multivariable models. The first three will have combinations of two of the predictors. The final model will have all three. For simplicity, we continue to use the &lt;strong&gt;brms&lt;/strong&gt; default priors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit7 &amp;lt;-
  brm(data = d,
      family = gaussian,
      y ~ 1 + x1 + x2,
      seed = 1)

fit8 &amp;lt;-
  update(fit7,
         newdata = d,
         y ~ 1 + x1 + x3,
         seed = 1)

fit9 &amp;lt;-
  update(fit7,
         newdata = d,
         y ~ 1 + x2 + x3,
         seed = 1)

fit10 &amp;lt;-
  update(fit7,
         newdata = d,
         y ~ 1 + x1 + x2 + x3,
         seed = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Individually extract the posterior draws.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;post7  &amp;lt;- posterior_samples(fit7)
post8  &amp;lt;- posterior_samples(fit8)
post9  &amp;lt;- posterior_samples(fit9)
post10 &amp;lt;- posterior_samples(fit10)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Take a look at what happens this time when we use the &lt;code&gt;bind_rows()&lt;/code&gt; approach.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posts &amp;lt;-
  bind_rows(
    post7,
    post8,
    post9,
    post10
  ) 

glimpse(posts)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 16,000
## Variables: 6
## $ b_Intercept &amp;lt;dbl&amp;gt; 0.09509318, 0.08186866, 0.02571336, -0.18844144, -0.06763395, 0.06137342, 0.0…
## $ b_x1        &amp;lt;dbl&amp;gt; -0.117031758, 0.004563560, -0.129202123, -0.125793634, -0.041442345, -0.02864…
## $ b_x2        &amp;lt;dbl&amp;gt; 0.19180539, 0.19254784, 0.31151419, 0.33083881, 0.08777655, 0.32273994, 0.158…
## $ sigma       &amp;lt;dbl&amp;gt; 1.118284, 1.122873, 1.159854, 1.108438, 1.041766, 1.214929, 1.220967, 1.28653…
## $ lp__        &amp;lt;dbl&amp;gt; -239.1799, -239.4599, -238.7769, -240.8443, -241.7296, -239.6411, -239.5687, …
## $ b_x3        &amp;lt;dbl&amp;gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We still have the various data frames stacked atop another, with the data from &lt;code&gt;post7&lt;/code&gt; in the first 4,000 rows. See how the values in the &lt;code&gt;b_x3&lt;/code&gt; column are all missing (i.e., filled with &lt;code&gt;NA&lt;/code&gt; values)? That’s because &lt;code&gt;fit7&lt;/code&gt; didn’t contain &lt;code&gt;x3&lt;/code&gt; as a predictor. Similarly, if we were to look at rows 4,001 through 8,000, we’d see column &lt;code&gt;b_x2&lt;/code&gt; would be the one filled with &lt;code&gt;NA&lt;/code&gt;s. This behavior is a good thing, here. After a little more wrangling, we’ll plot and it should be become clear why. Here’s the wrangling.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posts &amp;lt;-
  posts %&amp;gt;% 
  select(starts_with(&amp;quot;b_x&amp;quot;)) %&amp;gt;% 
  mutate(contains = rep(c(&amp;quot;&amp;lt;1, 1, 0&amp;gt;&amp;quot;, &amp;quot;&amp;lt;1, 0, 1&amp;gt;&amp;quot;, &amp;quot;&amp;lt;0, 1, 1&amp;gt;&amp;quot;, &amp;quot;&amp;lt;1, 1, 1&amp;gt;&amp;quot;), each = 4000)) %&amp;gt;% 
  gather(key, value, -contains) %&amp;gt;% 
  mutate(coefficient = str_remove(key, &amp;quot;b_x&amp;quot;) %&amp;gt;% str_c(&amp;quot;beta[&amp;quot;, ., &amp;quot;]&amp;quot;))

head(posts)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    contains  key       value coefficient
## 1 &amp;lt;1, 1, 0&amp;gt; b_x1 -0.11703176     beta[1]
## 2 &amp;lt;1, 1, 0&amp;gt; b_x1  0.00456356     beta[1]
## 3 &amp;lt;1, 1, 0&amp;gt; b_x1 -0.12920212     beta[1]
## 4 &amp;lt;1, 1, 0&amp;gt; b_x1 -0.12579363     beta[1]
## 5 &amp;lt;1, 1, 0&amp;gt; b_x1 -0.04144234     beta[1]
## 6 &amp;lt;1, 1, 0&amp;gt; b_x1 -0.02864308     beta[1]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With the &lt;code&gt;contains&lt;/code&gt; variable, we indexed which fit the draws came from. The 1s and 0s within the angle brackets indicate which of the three predictors were present within the model with the 1s indicating they were and the 0s indicating they were not. For example, &lt;code&gt;&amp;lt;1, 1, 0&amp;gt;&lt;/code&gt; in the first row indicated this was the model including &lt;code&gt;x1&lt;/code&gt; and &lt;code&gt;x2&lt;/code&gt;. Importantly, we also added a &lt;code&gt;coefficient&lt;/code&gt; index. This is just a variant of &lt;code&gt;key&lt;/code&gt; that’ll make the strip labels in our plot more attractive. Behold:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posts %&amp;gt;% 
  ggplot(aes(x = value, y = contains)) +
  geom_halfeyeh() +
  ylab(NULL) +
  facet_wrap(~coefficient, ncol = 1, labeller = label_parsed)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-07-13-would-you-like-all-your-posteriors-in-one-plot_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Hopefully now it’s clear why it was good to save those cells with the &lt;code&gt;NA&lt;/code&gt;s.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;bonus-you-can-streamline-your-workflow.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Bonus: You can streamline your workflow.&lt;/h2&gt;
&lt;p&gt;The workflows above are generally fine. But they’re a little inefficient. If you’d like to reduce the amount of code you’re writing and the number of objects you have floating around in your environment, you might consider a more streamlined workflow where you work with your fit objects in bulk. Here we’ll demonstrate a nested tibble approach with the first three fits.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posts &amp;lt;-
  tibble(name  = str_c(&amp;quot;fit&amp;quot;, 1:3),
         prior = str_c(&amp;quot;normal(0, &amp;quot;, c(10, 1, 0.1), &amp;quot;)&amp;quot;)) %&amp;gt;% 
  mutate(fit   = map(name, get)) %&amp;gt;% 
  mutate(post  = map(fit, posterior_samples))
  
head(posts)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 4
##   name  prior          fit       post                
##   &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;          &amp;lt;list&amp;gt;    &amp;lt;list&amp;gt;              
## 1 fit1  normal(0, 10)  &amp;lt;brmsfit&amp;gt; &amp;lt;df[,3] [4,000 × 3]&amp;gt;
## 2 fit2  normal(0, 1)   &amp;lt;brmsfit&amp;gt; &amp;lt;df[,3] [4,000 × 3]&amp;gt;
## 3 fit3  normal(0, 0.1) &amp;lt;brmsfit&amp;gt; &amp;lt;df[,3] [4,000 × 3]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We have a 3-row nested tibble. The first column, &lt;code&gt;name&lt;/code&gt; is just a character vector with the names of the fits. The next column isn’t necessary, but it nicely explicates the main difference in the models: the prior we used on the intercept. It’s in the &lt;code&gt;map()&lt;/code&gt; functions within the two &lt;code&gt;mutate()&lt;/code&gt;lines where all the magic happens. With the first, we used the &lt;code&gt;get()&lt;/code&gt; function to snatch up the &lt;strong&gt;brms&lt;/strong&gt; fit objects matching the names in the &lt;code&gt;name&lt;/code&gt; column. In the second, we used the &lt;code&gt;posterior_samples()&lt;/code&gt; function to extract the posterior draws from each of the fits saved in &lt;code&gt;fit&lt;/code&gt;. Do you see how each for in the &lt;code&gt;post&lt;/code&gt; column contains an entire &lt;span class=&#34;math inline&#34;&gt;\(4,000 \times 3\)&lt;/span&gt; data frame? That’s why we refer to this as a nested tibble. We have data frames compressed within data frames. If you’d like to access the data within the &lt;code&gt;post&lt;/code&gt; column, just &lt;code&gt;unnest()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posts %&amp;gt;% 
  unnest(post)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 12,000 x 5
##    name  prior         b_Intercept sigma  lp__
##    &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;               &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 fit1  normal(0, 10)    -0.0522  0.857 -204.
##  2 fit1  normal(0, 10)     0.125   0.898 -204.
##  3 fit1  normal(0, 10)    -0.00629 0.948 -204.
##  4 fit1  normal(0, 10)     0.0609  0.941 -204.
##  5 fit1  normal(0, 10)     0.178   0.946 -205.
##  6 fit1  normal(0, 10)     0.135   0.927 -204.
##  7 fit1  normal(0, 10)    -0.0777  0.874 -204.
##  8 fit1  normal(0, 10)     0.116   0.973 -205.
##  9 fit1  normal(0, 10)     0.134   0.852 -205.
## 10 fit1  normal(0, 10)     0.0197  0.929 -203.
## # … with 11,990 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After un-nesting, we can remake the plot from above.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posts %&amp;gt;% 
  unnest(post) %&amp;gt;% 

  ggplot(aes(x = b_Intercept, y = prior)) +
  geom_halfeyeh()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-07-13-would-you-like-all-your-posteriors-in-one-plot_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;To learn more about using the &lt;strong&gt;tidyverse&lt;/strong&gt; for iterating and saving the results in nested tibbles, check out &lt;a href=&#34;https://twitter.com/hadleywickham&#34;&gt;Hadley Wickham&lt;/a&gt;’s great talk, &lt;a href=&#34;https://www.youtube.com/watch?v=rz3_FDVt9eg&#34;&gt;&lt;em&gt;Managing many models&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;session-information&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Session information&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 3.6.0 (2019-04-26)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS High Sierra 10.13.6
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] tidybayes_1.1.0 brms_2.9.0      Rcpp_1.0.1      forcats_0.4.0   stringr_1.4.0   dplyr_0.8.1    
##  [7] purrr_0.3.2     readr_1.3.1     tidyr_0.8.3     tibble_2.1.3    ggplot2_3.2.0   tidyverse_1.2.1
## 
## loaded via a namespace (and not attached):
##   [1] colorspace_1.4-1          ggridges_0.5.1            rsconnect_0.8.13         
##   [4] ggstance_0.3.2            markdown_1.0              base64enc_0.1-3          
##   [7] rstudioapi_0.10           rstan_2.18.2              svUnit_0.7-12            
##  [10] DT_0.7                    fansi_0.4.0               mvtnorm_1.0-11           
##  [13] lubridate_1.7.4           xml2_1.2.0                bridgesampling_0.6-0     
##  [16] knitr_1.23                shinythemes_1.1.2         zeallot_0.1.0            
##  [19] bayesplot_1.7.0           jsonlite_1.6              broom_0.5.2              
##  [22] shiny_1.3.2               compiler_3.6.0            httr_1.4.0               
##  [25] backports_1.1.4           assertthat_0.2.1          Matrix_1.2-17            
##  [28] lazyeval_0.2.2            cli_1.1.0                 later_0.8.0              
##  [31] htmltools_0.3.6           prettyunits_1.0.2         tools_3.6.0              
##  [34] igraph_1.2.4.1            coda_0.19-2               gtable_0.3.0             
##  [37] glue_1.3.1                reshape2_1.4.3            cellranger_1.1.0         
##  [40] vctrs_0.1.0               nlme_3.1-139              blogdown_0.14            
##  [43] crosstalk_1.0.0           xfun_0.8                  ps_1.3.0                 
##  [46] rvest_0.3.4               mime_0.7                  miniUI_0.1.1.1           
##  [49] gtools_3.8.1              zoo_1.8-6                 scales_1.0.0             
##  [52] colourpicker_1.0          hms_0.4.2                 promises_1.0.1           
##  [55] Brobdingnag_1.2-6         parallel_3.6.0            inline_0.3.15            
##  [58] shinystan_2.5.0           yaml_2.2.0                gridExtra_2.3            
##  [61] loo_2.1.0                 StanHeaders_2.18.1-10     stringi_1.4.3            
##  [64] dygraphs_1.1.1.6          pkgbuild_1.0.3            rlang_0.4.0              
##  [67] pkgconfig_2.0.2           matrixStats_0.54.0        evaluate_0.14            
##  [70] lattice_0.20-38           labeling_0.3              rstantools_1.5.1         
##  [73] htmlwidgets_1.3           tidyselect_0.2.5          processx_3.3.1           
##  [76] plyr_1.8.4                magrittr_1.5              bookdown_0.12            
##  [79] R6_2.4.0                  generics_0.0.2            pillar_1.4.1             
##  [82] haven_2.1.0               withr_2.1.2               xts_0.11-2               
##  [85] abind_1.4-5               modelr_0.1.4              crayon_1.3.4             
##  [88] arrayhelpers_1.0-20160527 utf8_1.1.4                rmarkdown_1.13           
##  [91] grid_3.6.0                readxl_1.3.1              callr_3.2.0              
##  [94] threejs_0.3.1             digest_0.6.19             xtable_1.8-4             
##  [97] httpuv_1.5.1              stats4_3.6.0              munsell_0.5.0            
## [100] shinyjs_1.0&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Stein’s Paradox and What Partial Pooling Can Do For You</title>
      <link>/post/stein-s-paradox-and-what-partial-pooling-can-do-for-you/</link>
      <pubDate>Sat, 23 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/stein-s-paradox-and-what-partial-pooling-can-do-for-you/</guid>
      <description>&lt;div id=&#34;tldr&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;a href=&#34;https://www.urbandictionary.com/define.php?term=tl%3Bdr&#34;&gt;tl;dr&lt;/a&gt;&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Sometimes a mathematical result is strikingly contrary to generally held belief even though an obviously valid proof is given. &lt;a href=&#34;https://en.wikipedia.org/wiki/Charles_M._Stein&#34;&gt;Charles Stein&lt;/a&gt; of Stanford University discovered such a paradox in statistics in 1995. His result undermined a century and a half of work on estimation theory. (Efron &amp;amp; Morris, 1977, p. 119)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The James-Stein estimator leads to better predictions than simple means. Though I don’t recommend you actually use the James-Stein estimator in applied research, understanding why it works might help clarify why it’s time social scientists consider &lt;a href=&#34;http://elevanth.org/blog/2017/08/24/multilevel-regression-as-default/&#34;&gt;defaulting to multilevel models&lt;/a&gt; for their work-a-day projects.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-james-stein-can-help-us-understand-multilevel-models.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The James-Stein can help us understand multilevel models.&lt;/h2&gt;
&lt;p&gt;I recently noticed someone—I wish I could recall who—tweet about Efron and Morris’s classic, &lt;a href=&#34;http://statweb.stanford.edu/~ckirby/brad/other/Article1977.pdf&#34;&gt;&lt;em&gt;Stein’s Paradox in Statistics&lt;/em&gt;&lt;/a&gt;. At the time, I was vaguely aware of the paper but hadn’t taken the chance to read it. The tweet’s author mentioned how good a read it was. Now I’ve looked at it, I concur. I’m not a sports fan, but I really appreciated their primary example using batting averages from baseball players in 1970. It clarified why partial pooling leads to better estimates than taking simple averages.&lt;/p&gt;
&lt;p&gt;In this project, I’ll walk out Efron and Morris’s baseball example in R and then link it to contemporary Bayesian multilevel models.&lt;/p&gt;
&lt;div id=&#34;i-assume-things.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;I assume things.&lt;/h3&gt;
&lt;p&gt;For this project, I’m presuming you are familiar with logistic regression, vaguely familiar with the basic differences between frequentist and Bayesian approaches to fitting regression models, and have heard of multilevel models. All code in is &lt;a href=&#34;https://www.r-project.org/about.html&#34;&gt;R&lt;/a&gt;, with a heavy use of the &lt;a href=&#34;https://www.tidyverse.org&#34;&gt;tidyverse&lt;/a&gt;—which you might learn a lot about &lt;a href=&#34;http://r4ds.had.co.nz&#34;&gt;here&lt;/a&gt;, especially &lt;a href=&#34;http://r4ds.had.co.nz/transform.html&#34;&gt;chapter 5&lt;/a&gt;—, and the &lt;a href=&#34;https://github.com/paul-buerkner/brms&#34;&gt;brms package&lt;/a&gt; for Bayesian regression.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;behold-the-baseball-data.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Behold the &lt;code&gt;baseball&lt;/code&gt; data.&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Stein’s paradox concerns the use of observed averages to estimate unobservable quantities. Averaging is the second most basic process in statistics, the first being the simple act of counting. A baseball player who gets seven hits in 20 official times at bat is said to have a batting average of .350. In computing this statistic we are forming an estimate of the payer’s true batting ability in terms of his observed average rate of success. Asked how well the player will do in his next 100 times at bat, we would probably predict 35 more hits. In traditional statistical theory it can be proved that no other estimation rule is uniformly better than the observed average.&lt;/p&gt;
&lt;p&gt;The paradoxical element in Stein’s result is that it sometimes contradicts this elementary law of statistical theory. If we have three or more baseball players, and if we are interested in predicting future batting averages for each of them, then there is a procedure that is better than simply extrapolating from the three separate averages…&lt;/p&gt;
&lt;p&gt;As our primary data we shall consider the batting averages of 18 major-league players as they were recorded after their first 45 times at bat in the 1970 season. (p. 119)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Let’s enter the &lt;code&gt;baseball&lt;/code&gt; data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)

baseball &amp;lt;- 
  tibble(player = c(&amp;quot;Clemente&amp;quot;, &amp;quot;F Robinson&amp;quot;, &amp;quot;F Howard&amp;quot;, &amp;quot;Johnstone&amp;quot;, &amp;quot;Berry&amp;quot;, &amp;quot;Spencer&amp;quot;, &amp;quot;Kessinger&amp;quot;, &amp;quot;L Alvarado&amp;quot;, &amp;quot;Santo&amp;quot;, &amp;quot;Swoboda&amp;quot;, &amp;quot;Unser&amp;quot;, &amp;quot;Williams&amp;quot;, &amp;quot;Scott&amp;quot;, &amp;quot;Petrocelli&amp;quot;, &amp;quot;E Rodriguez&amp;quot;, &amp;quot;Campaneris&amp;quot;, &amp;quot;Munson&amp;quot;, &amp;quot;Alvis&amp;quot;),
         hits = c(18:15, 14, 14:12, 11, 11, rep(10, times = 5), 9:7),
         times_at_bat = 45,
         true_ba = c(.346, .298, .276, .222, .273, .27, .263, .21, .269, .23, .264, .256, .303, .264, .226, .286, .316, .2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s what they look like.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glimpse(baseball)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 18
## Variables: 4
## $ player       &amp;lt;chr&amp;gt; &amp;quot;Clemente&amp;quot;, &amp;quot;F Robinson&amp;quot;, &amp;quot;F Howard&amp;quot;, &amp;quot;Johnstone&amp;quot;, &amp;quot;Berry&amp;quot;, &amp;quot;Spencer&amp;quot;, &amp;quot;Kess…
## $ hits         &amp;lt;dbl&amp;gt; 18, 17, 16, 15, 14, 14, 13, 12, 11, 11, 10, 10, 10, 10, 10, 9, 8, 7
## $ times_at_bat &amp;lt;dbl&amp;gt; 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45
## $ true_ba      &amp;lt;dbl&amp;gt; 0.346, 0.298, 0.276, 0.222, 0.273, 0.270, 0.263, 0.210, 0.269, 0.230, 0.264,…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We have data from 18 players. The main columns are of the number of &lt;code&gt;hits&lt;/code&gt; for their first 45 &lt;code&gt;times_at_bat&lt;/code&gt;. I got the &lt;code&gt;player&lt;/code&gt;, &lt;code&gt;hits&lt;/code&gt;, and &lt;code&gt;times_at_bat&lt;/code&gt; values directly from the paper. However, Efron and Morris didn’t include the batting averages for the end of the season in the paper. Happily, I was able to find those values &lt;a href=&#34;http://statweb.stanford.edu/~ckirby/brad/LSI/chapter1.pdf&#34;&gt;online&lt;/a&gt;. They’re included in the &lt;code&gt;true_ba&lt;/code&gt; column.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;…These were all the players who happened to have batted exactly 45 times the day the data were tabulated. A batting average is defined, of course, simply as the number of hits divided by the number of times at bat; it is always a number between 0 and 1. (p. 119)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I like use a lot of plots to better understand what I’m doing. Before we start plotting, I should point out the color theme in this project comes from &lt;a href=&#34;https://teamcolorcodes.com/seattle-mariners-color-codes/&#34;&gt;here&lt;/a&gt;. [Haters gonna hate.]&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;navy_blue &amp;lt;- &amp;quot;#0C2C56&amp;quot;
nw_green  &amp;lt;- &amp;quot;#005C5C&amp;quot;  
silver    &amp;lt;- &amp;quot;#C4CED4&amp;quot;
theme_set(theme_grey() +
            theme(panel.grid = element_blank(),
                  panel.background = element_rect(fill = silver),
                  strip.background = element_rect(fill = silver)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We might use a histogram to get a sense of the &lt;code&gt;hits&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;baseball %&amp;gt;% 
  ggplot(aes(x = hits)) +
  geom_histogram(color = nw_green,
                 fill  = navy_blue,
                 size  = 1/10, binwidth = 1) +
  scale_x_continuous(&amp;quot;hits during the first 45 trials&amp;quot;,
                     breaks = 7:18)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-23-stein-s-paradox-and-what-partial-pooling-can-do-for-you_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And here is the distribution of the end-of-the-season batting averages, &lt;code&gt;true_ba&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidybayes)

baseball %&amp;gt;% 
  ggplot(aes(x = true_ba, y = 0)) +
  geom_halfeyeh(color = navy_blue,
                fill  = alpha(nw_green, 2/3),
                point_range = median_qi, .width = .5) +
  geom_rug(color = navy_blue,
           size = 1/3, alpha = 1/2) +
  ggtitle(NULL, subtitle = &amp;quot;The dot and horizontal line are the median and\ninterquartile range, respectively.&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-23-stein-s-paradox-and-what-partial-pooling-can-do-for-you_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;james-stein-will-help-us-achieve-our-goal.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;James-Stein will help us achieve our goal.&lt;/h3&gt;
&lt;p&gt;For each of the 18 players in the data, our goal is to the best job possible to use the data for their first 45 times at bat (i.e., &lt;code&gt;hits&lt;/code&gt; and &lt;code&gt;times_at_bat&lt;/code&gt;) to predict their batting averages at the end of the season (i.e., &lt;code&gt;true_ba&lt;/code&gt;). Before Charles Stein, the conventional reasoning was their initial batting averages (i.e., &lt;code&gt;hits / times_at_bat&lt;/code&gt;) are the best way to do this. It turns out that would be naïve. To see why, let&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;y&lt;/code&gt; (i.e., &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) = the batting average for the first 45 times at bat&lt;/li&gt;
&lt;li&gt;&lt;code&gt;y_bar&lt;/code&gt; (i.e., &lt;span class=&#34;math inline&#34;&gt;\(\overline y\)&lt;/span&gt;) = the grand mean for the first 45 times at bat&lt;/li&gt;
&lt;li&gt;&lt;code&gt;c&lt;/code&gt; (i.e., &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt;) = shrinking factor&lt;/li&gt;
&lt;li&gt;&lt;code&gt;z&lt;/code&gt; (i.e., &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt;) = James-Stein estimate&lt;/li&gt;
&lt;li&gt;&lt;code&gt;true_ba&lt;/code&gt; (i.e., &lt;code&gt;theta&lt;/code&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;) = the batting average at the end of the season&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;The first step in applying Stein’s method is to determine the average of the averages. Obviously this grand average, which we give the symbol &lt;span class=&#34;math inline&#34;&gt;\(\overline y\)&lt;/span&gt;, must also lie between 0 and 1. The essential process in Stein’s method is the “shrinking” of all the individual averages toward this grand average. If a player’s hitting record is better than the grand average, then it must be reduced; if he is not hitting as well as the grand average, then his hitting record must be increased. The resulting shrunken value for each player we designate &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt;. (p. 119)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As such, the James-Stein estimator is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[z = \overline y + c(y - \overline y)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;And in the paper, &lt;span class=&#34;math inline&#34;&gt;\(c = .212\)&lt;/span&gt;. Let’s get some of those values into the &lt;code&gt;baseball&lt;/code&gt; data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(
  baseball &amp;lt;-
  baseball %&amp;gt;% 
  mutate(y     = hits / times_at_bat) %&amp;gt;% 
  mutate(y_bar = mean(y),
         c     = .212) %&amp;gt;% 
  mutate(z     = y_bar + c * (y - y_bar),
         theta = true_ba)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 18 x 9
##    player       hits times_at_bat true_ba     y y_bar     c     z theta
##    &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 Clemente       18           45   0.346 0.4   0.265 0.212 0.294 0.346
##  2 F Robinson     17           45   0.298 0.378 0.265 0.212 0.289 0.298
##  3 F Howard       16           45   0.276 0.356 0.265 0.212 0.285 0.276
##  4 Johnstone      15           45   0.222 0.333 0.265 0.212 0.280 0.222
##  5 Berry          14           45   0.273 0.311 0.265 0.212 0.275 0.273
##  6 Spencer        14           45   0.27  0.311 0.265 0.212 0.275 0.27 
##  7 Kessinger      13           45   0.263 0.289 0.265 0.212 0.270 0.263
##  8 L Alvarado     12           45   0.21  0.267 0.265 0.212 0.266 0.21 
##  9 Santo          11           45   0.269 0.244 0.265 0.212 0.261 0.269
## 10 Swoboda        11           45   0.23  0.244 0.265 0.212 0.261 0.23 
## 11 Unser          10           45   0.264 0.222 0.265 0.212 0.256 0.264
## 12 Williams       10           45   0.256 0.222 0.265 0.212 0.256 0.256
## 13 Scott          10           45   0.303 0.222 0.265 0.212 0.256 0.303
## 14 Petrocelli     10           45   0.264 0.222 0.265 0.212 0.256 0.264
## 15 E Rodriguez    10           45   0.226 0.222 0.265 0.212 0.256 0.226
## 16 Campaneris      9           45   0.286 0.2   0.265 0.212 0.252 0.286
## 17 Munson          8           45   0.316 0.178 0.265 0.212 0.247 0.316
## 18 Alvis           7           45   0.2   0.156 0.265 0.212 0.242 0.2&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;Which set of values, &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt;, is the better indicator of batting ability for the 18 players in our example? In order to answer that question in a precise way one would have to know the “true batting ability” of each player. This true average we shall designate &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; (the Greek letter theta). Actually it is an unknowable quantity, an abstraction representing the probability that a player will get a hit on any given time at bat. Although &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; is unobservable, we have a good approximation to it: the subsequent performance of the batters. It is sufficient to consider just the remainder of the 1970 season, which includes about nine times as much data as the preliminary averages were based on. (p. 119)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now we have both &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt; in the data, let’s compare their distributions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;baseball %&amp;gt;% 
  select(y, z) %&amp;gt;% 
  gather() %&amp;gt;% 
  mutate(label = ifelse(key == &amp;quot;z&amp;quot;, 
                        &amp;quot;the James-Stein estimate&amp;quot;, 
                        &amp;quot;early-season batting average&amp;quot;)) %&amp;gt;% 
  
  ggplot(aes(x = value, y = label)) +
  geom_vline(color = &amp;quot;white&amp;quot;,
             xintercept = 0.2654321, linetype = 2) +
  geom_halfeyeh(color = navy_blue,
                fill  = alpha(nw_green, 2/3),
                point_range = median_qi, .width = .5, relative_scale = 4) +
  labs(x = &amp;quot;batting average&amp;quot;, y = NULL) +
  coord_cartesian(ylim = c(1.25, 5.25))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-23-stein-s-paradox-and-what-partial-pooling-can-do-for-you_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As implied in the formula, the James-Stein estimates are substantially shrunken towards the grand mean, &lt;code&gt;y_bar&lt;/code&gt;. To get a sense of which estimate is better, we can subtract the estimate from &lt;code&gt;theta&lt;/code&gt;, the end of the season batting average.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;baseball &amp;lt;-
  baseball %&amp;gt;% 
  mutate(y_error = theta - y,
         z_error = theta - z)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Since &lt;code&gt;y_error&lt;/code&gt; and &lt;code&gt;y_error&lt;/code&gt; are error distributions, we prefer values to be as close to zero as possible. Let’s take a look.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;baseball %&amp;gt;% 
  select(y_error:z_error) %&amp;gt;% 
  gather() %&amp;gt;% 
  
  ggplot(aes(x = value, y = key)) +
  geom_vline(xintercept = 0, linetype = 2,
             color = &amp;quot;white&amp;quot;) +
  geom_halfeyeh(color = navy_blue,
                fill  = alpha(nw_green, 2/3),
                point_range = median_qi, .width = .5, relative_scale = 2.5) +
  labs(x = NULL, y = NULL) +
  coord_cartesian(ylim = c(1.25, 4))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-23-stein-s-paradox-and-what-partial-pooling-can-do-for-you_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The James-Stein errors (i.e., &lt;code&gt;z_error&lt;/code&gt;) are much more concentrated toward zero. In the paper, we read: “One method of evaluating the two estimates is by simply counting their successes and failures. For 16 of the 18 players the James-Stein estimator &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt; is closer than the observed average &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; to the ‘true,’ or seasonal, average &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;” (pp. 119–121). We can compute that with a little &lt;code&gt;ifelse()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;baseball %&amp;gt;% 
  transmute(closer_to_theta = ifelse(abs(y_error) - abs(z_error) == 0, &amp;quot;equal&amp;quot;,
                                     ifelse(abs(y_error) - abs(z_error) &amp;gt; 0, &amp;quot;z&amp;quot;, &amp;quot;y&amp;quot;))) %&amp;gt;% 
  group_by(closer_to_theta) %&amp;gt;% 
  count()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 2
## # Groups:   closer_to_theta [2]
##   closer_to_theta     n
##   &amp;lt;chr&amp;gt;           &amp;lt;int&amp;gt;
## 1 y                   2
## 2 z                  16&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;A more quantitative way of comparing the two techniques is through the total squared error of estimation… The observed averages &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; have a total squared error of .077, whereas the squared error of the James-Stein estimators is only .022. By this comparison, then, Stein’s method is 3.5 times as accurate. (p. 121)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;baseball %&amp;gt;% 
  select(y_error:z_error) %&amp;gt;% 
  gather() %&amp;gt;% 
  group_by(key) %&amp;gt;% 
  summarise(total_squared_error = sum(value * value))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 2
##   key     total_squared_error
##   &amp;lt;chr&amp;gt;                 &amp;lt;dbl&amp;gt;
## 1 y_error              0.0755
## 2 z_error              0.0214&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can get the 3.5 value with simple division.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;0.07548795 / 0.02137602&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3.531431&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So it does indeed turn out that shrinking each player’s initial estimate toward the grand mean of those initial estimates does a better job of predicting their end-of-the-season batting averages than using their individual batting averages. To get a sense of what this looks like, let’s make our own version of the figure on page 121.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;baseball %&amp;gt;% 
  select(y, z, theta, player) %&amp;gt;% 
  gather(key, value, -player) %&amp;gt;% 
  mutate(time = ifelse(key == &amp;quot;theta&amp;quot;, &amp;quot;theta&amp;quot;, &amp;quot;estimate&amp;quot;)) %&amp;gt;% 
  bind_rows(
    baseball %&amp;gt;% 
      select(player, theta) %&amp;gt;% 
      rename(value = theta) %&amp;gt;% 
      mutate(key  = &amp;quot;theta&amp;quot;, 
             time = &amp;quot;theta&amp;quot;)
  ) %&amp;gt;% 
  mutate(facet = rep(c(&amp;quot;estimate = y&amp;quot;, &amp;quot;estimate = z&amp;quot;), each = n() / 4) %&amp;gt;% rep(., times = 2)) %&amp;gt;% 
  
  ggplot(aes(x = time, y = value, group = player)) +
  geom_hline(yintercept = 0.2654321, linetype = 2,
             color = &amp;quot;white&amp;quot;) +
  geom_line(alpha = 1/2,
            color = nw_green) +
  geom_point(alpha = 1/2,
             color = navy_blue) +
  labs(x = NULL,
       y = &amp;quot;batting average&amp;quot;) +
  theme(axis.ticks.x = element_blank()) +
  facet_wrap(~facet)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-23-stein-s-paradox-and-what-partial-pooling-can-do-for-you_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The James-Stein estimator works because of its shrinkage. The shrinkage factor is &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt;. In the first parts of the paper, Efron and Morris just told us &lt;span class=&#34;math inline&#34;&gt;\(c = .212\)&lt;/span&gt;. A little later in the paper, they gave the actual formula for &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt;. If you let &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; be the number of means (i.e., the number of clusters), then:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[c = 1 - \frac{(k - 3)\sigma^2}{\sum (y - \overline y)^2}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The difficulty of that formula is we don’t know the value for &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;. It’s not the simple variance of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; (i.e., &lt;code&gt;var(y)&lt;/code&gt;). An &lt;a href=&#34;https://stats.stackexchange.com/questions/5727/james-stein-estimator-how-did-efron-and-morris-calculate-sigma2-in-shrinkag&#34;&gt;answer to this stackexchange question&lt;/a&gt; appears to have uncovered the method Efron and Morris used in the paper. I’ll reproduce it in detail:&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/post/2019-02-23-stein-s-paradox-and-what-partial-pooling-can-do-for-you_files/answer.PNG&#34; style=&#34;width:100.0%&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;Following along, we can compute &lt;code&gt;sigma_squared&lt;/code&gt; like so:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(sigma_squared &amp;lt;- mean(baseball$y) * (1 - mean(baseball$y)) / 45)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.004332842&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can reproduce the &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; value from the paper.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;baseball %&amp;gt;% 
  select(player, y:c) %&amp;gt;% 
  mutate(squared_deviation = (y - y_bar)^2) %&amp;gt;%
  summarise(c_by_hand = 1 - ((n() - 3) * sigma_squared / sum(squared_deviation)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 1
##   c_by_hand
##       &amp;lt;dbl&amp;gt;
## 1     0.212&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;lets-go-bayesian.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Let’s go Bayesian.&lt;/h2&gt;
&lt;p&gt;This has been fun. But I don’t recommend you actually use the James-Stein estimator in your research.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The James-Stein estimator is not the only one that is known to be better than the sample averages…&lt;/p&gt;
&lt;p&gt;The search for new estimators continues. Recent efforts [in the 1970s, that is] have been concentrated on achieving results like those obtained with Stein’s method for problems involving distributions other than the normal distribution. Several lines of work, including Stein’s and Robbins’ and more formal &lt;em&gt;Bayesian methods&lt;/em&gt; seem to be converging on a powerful general theory of parameter estimation. (p. 127, &lt;em&gt;emphasis&lt;/em&gt; added)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The James-Stein estimator is not Bayesian, but it is a precursor to the kind of analyses we now do with Bayesian multilevel models, which pool cluster-level means toward a grand mean. To get a sense of this, let’s fit a couple models. First, let’s load the brms package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(brms)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I typically work with the linear regression paradigm. If we were to analyze the &lt;code&gt;baseball&lt;/code&gt; data, we’d use an aggregated binomial mode, which is a particular kind of logistic regression. You can learn more about it &lt;a href=&#34;https://www.youtube.com/watch?v=DyrUkqK9Tj4&amp;amp;t=1581s&amp;amp;frags=pl%2Cwn&#34;&gt;here&lt;/a&gt; or &lt;a href=&#34;https://github.com/ASKurz/Statistical_Rethinking_with_brms_ggplot2_and_the_tidyverse/blob/master/10.md&#34;&gt;here&lt;/a&gt;. If we wanted a model that corresponded to the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; estimates, above, we’d use &lt;code&gt;hits&lt;/code&gt; as the criterion and allow each player to get his own &lt;em&gt;separate&lt;/em&gt; estimate. Since we’re working within the Bayesian paradigm, we also need to assign priors. In this case, we’ll use a weakly-regularizing &lt;span class=&#34;math inline&#34;&gt;\(\text{Normal} (0, 1.5)\)&lt;/span&gt; on the intercepts. See &lt;a href=&#34;https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations&#34;&gt;this wiki&lt;/a&gt; for more on weakly-regularizing priors.&lt;/p&gt;
&lt;p&gt;Here’s the code to fit the model in brms.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit_y &amp;lt;-
  brm(data = baseball, family = binomial,
      hits | trials(45) ~ 0 + player,
      prior(normal(0, 1.5), class = b),
      seed = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you were curious, that model followed the statistical formula&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{eqnarray}
\text{hits}_i &amp;amp; \sim &amp;amp; \text{Binomial} (n = 45, p_i) \\
\text{logit}(p_i) &amp;amp; = &amp;amp; \alpha_\text{player} \\
\alpha_\text{player} &amp;amp; \sim &amp;amp; \text{Normal} (0, 1.5)
\end{eqnarray}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(p_i\)&lt;/span&gt; is the probability of player &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\alpha_\text{player}\)&lt;/span&gt; is a vector of &lt;span class=&#34;math inline&#34;&gt;\(\text{player}\)&lt;/span&gt;-specific intercepts from within the logistic regression model, and each of those intercepts are given a &lt;span class=&#34;math inline&#34;&gt;\(\text{Normal} (0, 1.5)\)&lt;/span&gt; prior on the log-odds scale. (If this is all new and confusing, don’t worry. I’ll recommended some resources at the end of this post.)&lt;/p&gt;
&lt;p&gt;For our analogue to the James-Stein estimate &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt;, we’ll fit the multilevel version of that last model. While each player still gets his own estimate, those estimates are now partially-pooled toward the grand mean.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit_z &amp;lt;-
  brm(data = baseball, family = binomial,
      hits | trials(45) ~ 1 + (1 | player),
      prior = c(prior(normal(0, 1.5), class = Intercept),
                prior(normal(0, 1.5), class = sd)),
      seed = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And that model followed the statistical formula&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{eqnarray}
\text{hits}_i &amp;amp; \sim &amp;amp; \text{Binomial} (n = 45, p_i) \\
\text{logit}(p_i) &amp;amp; = &amp;amp; \alpha + \alpha_\text{player} \\
\alpha &amp;amp; \sim &amp;amp; \text{Normal} (0, 1.5) \\ 
\alpha_\text{player} &amp;amp; \sim &amp;amp; \text{Normal} (0, \sigma_\text{player}) \\
\sigma_\text{player} &amp;amp; \sim &amp;amp; \text{HalfNormal} (0, 1.5)
\end{eqnarray}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; is the grand mean among the &lt;span class=&#34;math inline&#34;&gt;\(\text{player}\)&lt;/span&gt;-specific intercepts, &lt;span class=&#34;math inline&#34;&gt;\(\alpha_\text{player}\)&lt;/span&gt; is the vector of &lt;span class=&#34;math inline&#34;&gt;\(\text{player}\)&lt;/span&gt;-specific deviations from the grand mean, which are Normally distributed with a mean of zero and a standard deviation of &lt;span class=&#34;math inline&#34;&gt;\(\sigma_\text{player}\)&lt;/span&gt;, which is estimated from the data.&lt;/p&gt;
&lt;p&gt;Here are the model summaries.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit_y$fit&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Inference for Stan model: 1d2456d7f7a08ebf8ef5fda01ce9b808.
## 4 chains, each with iter=2000; warmup=1000; thin=1; 
## post-warmup draws per chain=1000, total post-warmup draws=4000.
## 
##                      mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat
## b_playerAlvis       -1.63    0.00 0.39  -2.44  -1.89  -1.62  -1.35  -0.89  7862    1
## b_playerBerry       -0.78    0.00 0.31  -1.41  -0.98  -0.77  -0.56  -0.19  8886    1
## b_playerCampaneris  -1.34    0.00 0.35  -2.05  -1.57  -1.33  -1.10  -0.69  7628    1
## b_playerClemente    -0.39    0.00 0.30  -0.99  -0.59  -0.39  -0.19   0.18 10134    1
## b_playerERodriguez  -1.21    0.00 0.35  -1.93  -1.45  -1.20  -0.97  -0.55 10145    1
## b_playerFHoward     -0.59    0.00 0.31  -1.22  -0.79  -0.58  -0.38   0.03 10787    1
## b_playerFRobinson   -0.49    0.00 0.30  -1.08  -0.69  -0.49  -0.28   0.10 10544    1
## b_playerJohnstone   -0.69    0.00 0.31  -1.32  -0.88  -0.68  -0.48  -0.09  9763    1
## b_playerKessinger   -0.88    0.00 0.33  -1.55  -1.10  -0.88  -0.67  -0.28  9094    1
## b_playerLAlvarado   -0.98    0.00 0.32  -1.63  -1.20  -0.97  -0.76  -0.37 10622    1
## b_playerMunson      -1.48    0.00 0.38  -2.27  -1.72  -1.46  -1.21  -0.77 11067    1
## b_playerPetrocelli  -1.21    0.00 0.33  -1.89  -1.43  -1.20  -0.99  -0.59  9253    1
## b_playerSanto       -1.10    0.00 0.33  -1.78  -1.32  -1.09  -0.87  -0.46  9619    1
## b_playerScott       -1.22    0.00 0.36  -1.94  -1.45  -1.20  -0.98  -0.54 10948    1
## b_playerSpencer     -0.78    0.00 0.33  -1.45  -0.99  -0.77  -0.55  -0.14  8511    1
## b_playerSwoboda     -1.10    0.00 0.35  -1.81  -1.33  -1.10  -0.87  -0.42 10665    1
## b_playerUnser       -1.21    0.00 0.35  -1.92  -1.44  -1.21  -0.97  -0.54 11893    1
## b_playerWilliams    -1.22    0.00 0.35  -1.96  -1.45  -1.20  -0.97  -0.56  8597    1
## lp__               -73.45    0.08 2.93 -79.97 -75.21 -73.15 -71.34 -68.48  1444    1
## 
## Samples were drawn using NUTS(diag_e) at Sat Feb 23 17:19:53 2019.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit_z$fit&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Inference for Stan model: 33295e60ce033f843c74128ac973bc03.
## 4 chains, each with iter=2000; warmup=1000; thin=1; 
## post-warmup draws per chain=1000, total post-warmup draws=4000.
## 
##                                   mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat
## b_Intercept                      -1.02    0.00 0.09  -1.21  -1.08  -1.02  -0.96  -0.84  3116    1
## sd_player__Intercept              0.17    0.00 0.11   0.01   0.08   0.16   0.24   0.42  1643    1
## r_player[Alvis,Intercept]        -0.13    0.00 0.20  -0.62  -0.22  -0.07   0.00   0.17  2411    1
## r_player[Berry,Intercept]         0.05    0.00 0.17  -0.26  -0.03   0.02   0.13   0.44  4251    1
## r_player[Campaneris,Intercept]   -0.08    0.00 0.17  -0.51  -0.16  -0.04   0.02   0.21  3621    1
## r_player[Clemente,Intercept]      0.14    0.00 0.20  -0.13   0.00   0.09   0.25   0.63  2902    1
## r_player[E.Rodriguez,Intercept]  -0.05    0.00 0.16  -0.43  -0.12  -0.02   0.04   0.27  4722    1
## r_player[F.Howard,Intercept]      0.09    0.00 0.18  -0.20  -0.01   0.05   0.19   0.54  3081    1
## r_player[F.Robinson,Intercept]    0.12    0.00 0.19  -0.17   0.00   0.07   0.22   0.58  2766    1
## r_player[Johnstone,Intercept]     0.07    0.00 0.17  -0.22  -0.02   0.04   0.15   0.47  4122    1
## r_player[Kessinger,Intercept]     0.03    0.00 0.16  -0.29  -0.05   0.01   0.09   0.40  4051    1
## r_player[L.Alvarado,Intercept]    0.00    0.00 0.17  -0.37  -0.08   0.00   0.08   0.36  4060    1
## r_player[Munson,Intercept]       -0.10    0.00 0.19  -0.59  -0.18  -0.05   0.01   0.19  3625    1
## r_player[Petrocelli,Intercept]   -0.05    0.00 0.17  -0.46  -0.14  -0.02   0.04   0.25  4014    1
## r_player[Santo,Intercept]        -0.02    0.00 0.16  -0.40  -0.09  -0.01   0.05   0.30  4388    1
## r_player[Scott,Intercept]        -0.05    0.00 0.17  -0.45  -0.13  -0.02   0.04   0.26  3650    1
## r_player[Spencer,Intercept]       0.05    0.00 0.17  -0.27  -0.04   0.02   0.13   0.43  3611    1
## r_player[Swoboda,Intercept]      -0.03    0.00 0.16  -0.38  -0.10  -0.01   0.05   0.28  4562    1
## r_player[Unser,Intercept]        -0.05    0.00 0.16  -0.44  -0.13  -0.02   0.04   0.25  3412    1
## r_player[Williams,Intercept]     -0.05    0.00 0.17  -0.44  -0.13  -0.02   0.04   0.26  4306    1
## lp__                            -73.87    0.13 4.11 -82.53 -76.49 -73.67 -71.00 -66.54  1053    1
## 
## Samples were drawn using NUTS(diag_e) at Sat Feb 23 17:20:43 2019.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you’re new to aggregated binomial or logistic regression, those estimates might be confusing. For technical reasons—see &lt;a href=&#34;https://www.youtube.com/watch?v=DyrUkqK9Tj4&amp;amp;t=1430s&amp;amp;frags=pl%2Cwn&#34;&gt;here&lt;/a&gt;—, they’re in a log-odds metric. But we can use the &lt;code&gt;brms::inv_logit_scaled()&lt;/code&gt; function to convert them back to a probability metric. &lt;em&gt;Why would we want a probability metric?&lt;/em&gt;, you might ask. As it turns out, batting average is in a probability metric, too. So you might also think of the &lt;code&gt;inv_logit_scaled()&lt;/code&gt; function as turning the model results into a batting-average metric. For example, if we wanted to get the estimated batting average for E. Rodriguez baed on the &lt;code&gt;y_fit&lt;/code&gt; model (i.e., the model corresponding to the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; estimator), we might do something like this.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fixef(fit_y)[&amp;quot;playerERodriguez&amp;quot;, 1] %&amp;gt;% 
  inv_logit_scaled()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.2293629&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To double check the model returned a sensible estimate, here’s the corresponding &lt;code&gt;y&lt;/code&gt; value from the &lt;code&gt;baseball&lt;/code&gt; data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;baseball %&amp;gt;% 
  filter(player == &amp;quot;E Rodriguez&amp;quot;) %&amp;gt;% 
  select(y)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 1
##       y
##   &amp;lt;dbl&amp;gt;
## 1 0.222&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It’s a little off, but in the right ballpark. Here is the corresponding estimate from the multilevel model, &lt;code&gt;fit_z&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coef(fit_z)$player[&amp;quot;E Rodriguez&amp;quot;, 1, ] %&amp;gt;% inv_logit_scaled()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.2558496&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And indeed that’s pretty close to the &lt;code&gt;z&lt;/code&gt; value from the &lt;code&gt;baseball&lt;/code&gt; data, too.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;baseball %&amp;gt;% 
  filter(player == &amp;quot;E Rodriguez&amp;quot;) %&amp;gt;% 
  select(z)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 1
##       z
##   &amp;lt;dbl&amp;gt;
## 1 0.256&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So now we have these too competing ways to model the data of the first 45 times at bat, let’s see how well their estimates predict the &lt;code&gt;true_ba&lt;/code&gt; values. We’ll do so with a couple plots. This first one is of the single-level model which did not pool the batting averages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# get the `fitted()` draws and wrangle a bit
f_y &amp;lt;-
  baseball %&amp;gt;% 
  distinct(player) %&amp;gt;% 
  add_fitted_draws(fit_y, dpar = &amp;quot;mu&amp;quot;) %&amp;gt;% 
  left_join(baseball %&amp;gt;% 
              select(player, true_ba))
  
# save the plot
p1 &amp;lt;-
  f_y %&amp;gt;% 
  ggplot(aes(x = mu, y = reorder(player, true_ba))) +
  geom_vline(xintercept = mean(baseball$true_ba), color = &amp;quot;white&amp;quot;) +
  stat_intervalh(.width = .95, alpha = 1/3, color = nw_green) +
  stat_intervalh(.width = .50, alpha = 1/3, color = nw_green) +
  geom_point(data = baseball,
             aes(x = true_ba),
             size = 2, alpha = 3/4,
             color = navy_blue) +
  labs(x = &amp;quot;batting average&amp;quot;, 
       y = NULL,
       subtitle = &amp;quot;fit_y, the no pooling model&amp;quot;) +
  coord_cartesian(xlim = c(0, .6)) +
  theme(axis.text.y   = element_text(hjust = 0),
        axis.ticks.y  = element_blank(),
        plot.subtitle = element_text(hjust = .5))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note our use of some handy convenience functions (i.e., &lt;code&gt;add_fitted_draws()&lt;/code&gt; and &lt;code&gt;stat_intervalh()&lt;/code&gt;) from the &lt;a href=&#34;https://github.com/mjskay/tidybayes&#34;&gt;tidybayes package&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This second plot is almost the same as the previous one, but this time based on the partial-pooling multilevel model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f_z &amp;lt;-
  baseball %&amp;gt;% 
  distinct(player) %&amp;gt;% 
  add_fitted_draws(fit_z, dpar = &amp;quot;mu&amp;quot;) %&amp;gt;% 
  left_join(baseball %&amp;gt;% 
              select(player, true_ba))

p2 &amp;lt;-
  f_z %&amp;gt;% 
  ggplot(aes(x = mu, y = reorder(player, true_ba))) +
  geom_vline(xintercept = mean(baseball$true_ba), color = &amp;quot;white&amp;quot;) +
  stat_intervalh(.width = .95, alpha = 1/3, color = nw_green) +
  stat_intervalh(.width = .50, alpha = 1/3, color = nw_green) +
  geom_point(data = baseball,
             aes(x = true_ba),
             size = 2, alpha = 3/4,
             color = navy_blue) +
  labs(x = &amp;quot;batting average&amp;quot;, 
       y = NULL,
       subtitle = &amp;quot;fit_z, the multilevel pooling model&amp;quot;) +
  coord_cartesian(xlim = c(0, .6)) +
  theme(axis.text.y   = element_text(hjust = 0),
        axis.ticks.y  = element_blank(),
        plot.subtitle = element_text(hjust = .5))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here we join them together.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(gridExtra)

grid.arrange(p1, p2, ncol = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-23-stein-s-paradox-and-what-partial-pooling-can-do-for-you_files/figure-html/unnamed-chunk-24-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In both panels, the end-of-the-season batting averages (i.e., &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;) are the blue dots. The model-implied estimates are depicted by 95% and 50% interval bands (i.e., the lighter and darker green horizontal lines, respectively). The white line in the background marks off the mean of &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;. Although neither model was perfect, the multilevel model, our analogue to the James-Stein estimates, yielded predictions that appear both more valid and more precise.&lt;/p&gt;
&lt;p&gt;We might also compare the models by their prediction errors. Here we’ll subtract the end-of-the-season batting averages from the model estimates. But unlike with &lt;code&gt;y&lt;/code&gt; and &lt;code&gt;z&lt;/code&gt; estimates, above, our &lt;code&gt;fit_y&lt;/code&gt; and &lt;code&gt;fit_z&lt;/code&gt; models yielded entire posterior distributions. Therefore, we’ll express our prediction errors in terms of error distributions, rather than single values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# save the `fit_y` plot
p3 &amp;lt;-
  f_y %&amp;gt;% 
  # the error distribution is just the model-implied values minus 
  # the true end-of-season values
  mutate(error = mu - true_ba)  %&amp;gt;% 

  ggplot(aes(x = error, y = reorder(player, true_ba))) +
  geom_vline(xintercept = c(0, -.2, .2), size = c(1/2, 1/4, 1/4), 
             linetype = c(1, 3, 3), color = &amp;quot;white&amp;quot;) +
  geom_halfeyeh(point_interval = mean_qi, .width = .95,
                color = navy_blue, fill = alpha(nw_green, 2/3)) +
  coord_cartesian(xlim = c(-.35, .35)) +
  labs(x = &amp;quot;error&amp;quot;, 
       y = NULL,
       subtitle = &amp;quot;fit_y, the no pooling model&amp;quot;) +
  theme(axis.text.y   = element_text(hjust = 0),
        axis.ticks.y  = element_blank(),
        plot.subtitle = element_text(hjust = .5))

# save the `fit_z` plot
p4 &amp;lt;-
  f_z %&amp;gt;%   
  mutate(error = mu - true_ba)  %&amp;gt;% 
  
  ggplot(aes(x = error, y = reorder(player, true_ba))) +
  geom_vline(xintercept = c(0, -.2, .2), size = c(1/2, 1/4, 1/4), 
             linetype = c(1, 3, 3), color = &amp;quot;white&amp;quot;) +
  geom_halfeyeh(point_interval = mean_qi, .width = .95,
                color = navy_blue, fill = alpha(nw_green, 2/3)) +
  coord_cartesian(xlim = c(-.35, .35)) +
  labs(x = &amp;quot;error&amp;quot;, 
       y = NULL,
       subtitle = &amp;quot;fit_z, the multilevel pooling model&amp;quot;) +
  theme(axis.text.y   = element_text(hjust = 0),
        axis.ticks.y  = element_blank(),
        plot.subtitle = element_text(hjust = .5))

# now combine the two and behold
grid.arrange(p3, p4, ncol = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-23-stein-s-paradox-and-what-partial-pooling-can-do-for-you_files/figure-html/unnamed-chunk-25-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For consistency, I’ve ordered the players along the y-axis the same as above. In both panels, we see the prediction error distribution for each player in green and then summarize those distributions in terms of their means and percentile-based 95% intervals. Since these are error distributions, we prefer them to be as close to zero as possible. Although neither model made perfect predictions, the overall errors in the multilevel model were clearly smaller. Much like with the James-Stein estimator, the partial pooling of the multilevel model made for better end-of-the-season estimates.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The paradoxical [consequence of Bayesian multilevel models] is that [they can contradict] this elementary law of statistical theory. If we have [two] or more baseball players, and if we are interested in predicting future batting averages for each of them, then [the Bayesian multilevel model can be better] than simply extrapolating from [the] separate averages. (p. 119)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is another example of how the &lt;a href=&#34;https://en.wikipedia.org/wiki/KISS_principle&#34;&gt;KISS principle&lt;/a&gt; isn’t always the best bet with data analysis.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;next-steps&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Next steps&lt;/h2&gt;
&lt;p&gt;If you’re new to logistic regression, multilevel models or Bayesian statistics, I recommend any of the following texts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://xcelab.net/rm/statistical-rethinking/&#34;&gt;&lt;em&gt;Statistical Rethinking&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://sites.google.com/site/doingbayesiandataanalysis/&#34;&gt;&lt;em&gt;Doing Bayesian Data Analysis&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.stat.columbia.edu/~gelman/arm/&#34;&gt;&lt;em&gt;Data Analysis Using Regression and Multilevel/Hierarchical Models&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And if you choose &lt;em&gt;Statistical Rethinking&lt;/em&gt;, do check out &lt;a href=&#34;https://www.youtube.com/channel/UCNJK6_DZvcMqNSzQdEkzvzA/playlists&#34;&gt;these great lectures&lt;/a&gt; on the text or &lt;a href=&#34;https://bookdown.org/connect/#/apps/1850/access&#34;&gt;my project translating the code in the text to brms and the tidyverse&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Also, don’t miss the provocative preprint by Davis-Stober, Dana and Rouder, &lt;a href=&#34;https://osf.io/2ukxj/&#34;&gt;&lt;em&gt;When are sample means meaningful? The role of modern estimation in psychological science&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;reference&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Reference&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://statweb.stanford.edu/~ckirby/brad/other/Article1977.pdf&#34;&gt;Efron, B., &amp;amp; Morris, C. (1977). Stein’s paradox in statistics. &lt;em&gt;Scientific American, 236&lt;/em&gt;, 119–127, doi: 10.1038/scientificamerican0577-119&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;session-info&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Session info&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 3.5.1 (2018-07-02)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS High Sierra 10.13.6
## 
## Matrix products: default
## BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] gridExtra_2.3   brms_2.7.0      Rcpp_1.0.0      bindrcpp_0.2.2  tidybayes_1.0.3 forcats_0.3.0  
##  [7] stringr_1.3.1   dplyr_0.7.6     purrr_0.2.5     readr_1.1.1     tidyr_0.8.1     tibble_2.0.1   
## [13] ggplot2_3.1.0   tidyverse_1.2.1
## 
## loaded via a namespace (and not attached):
##   [1] colorspace_1.3-2          ggridges_0.5.0            rsconnect_0.8.8          
##   [4] rprojroot_1.3-2           ggstance_0.3              markdown_0.8             
##   [7] base64enc_0.1-3           rstudioapi_0.7            rstan_2.18.2             
##  [10] svUnit_0.7-12             DT_0.4                    fansi_0.4.0              
##  [13] mvtnorm_1.0-8             lubridate_1.7.4           xml2_1.2.0               
##  [16] bridgesampling_0.4-0      knitr_1.20                shinythemes_1.1.1        
##  [19] bayesplot_1.6.0           jsonlite_1.5              broom_0.5.1              
##  [22] shiny_1.1.0               compiler_3.5.1            httr_1.3.1               
##  [25] backports_1.1.2           assertthat_0.2.0          Matrix_1.2-14            
##  [28] lazyeval_0.2.1            cli_1.0.1                 later_0.7.3              
##  [31] prettyunits_1.0.2         htmltools_0.3.6           tools_3.5.1              
##  [34] igraph_1.2.1              coda_0.19-2               gtable_0.2.0             
##  [37] glue_1.3.0                reshape2_1.4.3            cellranger_1.1.0         
##  [40] nlme_3.1-137              blogdown_0.8              crosstalk_1.0.0          
##  [43] xfun_0.3                  ps_1.2.1                  rvest_0.3.2              
##  [46] mime_0.5                  miniUI_0.1.1.1            gtools_3.8.1             
##  [49] MASS_7.3-50               zoo_1.8-2                 scales_1.0.0             
##  [52] colourpicker_1.0          hms_0.4.2                 promises_1.0.1           
##  [55] Brobdingnag_1.2-5         parallel_3.5.1            inline_0.3.15            
##  [58] shinystan_2.5.0           yaml_2.1.19               StanHeaders_2.18.0-1     
##  [61] loo_2.0.0                 stringi_1.2.3             dygraphs_1.1.1.5         
##  [64] pkgbuild_1.0.2            rlang_0.3.1               pkgconfig_2.0.2          
##  [67] matrixStats_0.54.0        evaluate_0.10.1           lattice_0.20-35          
##  [70] bindr_0.1.1               rstantools_1.5.0          htmlwidgets_1.2          
##  [73] labeling_0.3              processx_3.2.1            tidyselect_0.2.4         
##  [76] plyr_1.8.4                magrittr_1.5              bookdown_0.7             
##  [79] R6_2.3.0                  generics_0.0.2            pillar_1.3.1             
##  [82] haven_1.1.2               withr_2.1.2               xts_0.10-2               
##  [85] abind_1.4-5               modelr_0.1.2              crayon_1.3.4             
##  [88] arrayhelpers_1.0-20160527 utf8_1.1.4                rmarkdown_1.10           
##  [91] grid_3.5.1                readxl_1.1.0              callr_3.1.0              
##  [94] threejs_0.3.1             digest_0.6.18             xtable_1.8-2             
##  [97] httpuv_1.4.4.2            stats4_3.5.1              munsell_0.5.0            
## [100] viridisLite_0.3.0         shinyjs_1.0&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Bayesian Correlations: Let’s Talk Options.</title>
      <link>/post/bayesian-correlations-let-s-talk-options/</link>
      <pubDate>Sat, 16 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/bayesian-correlations-let-s-talk-options/</guid>
      <description>&lt;div id=&#34;tldr&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;tl;dr&lt;/h2&gt;
&lt;p&gt;There’s more than one way to fit a Bayesian correlation in brms.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;heres-the-deal.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Here’s the deal.&lt;/h2&gt;
&lt;p&gt;In the last post, we considered how we might estimate correlations when our data contain influential outlier values. Our big insight was that if we use variants of Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution as the likelihood rather than the conventional normal distribution, our correlation estimates were less influenced by those outliers. And we mainly did that as Bayesians using the &lt;a href=&#34;https://github.com/paul-buerkner/brms&#34;&gt;brms package&lt;/a&gt;. Click &lt;a href=&#34;https://solomonkurz.netlify.com/post/bayesian-robust-correlations-with-brms-and-why-you-should-love-student-s-t/&#34;&gt;here&lt;/a&gt; for a refresher.&lt;/p&gt;
&lt;p&gt;Since the brms package is designed to fit regression models, &lt;a href=&#34;https://twitter.com/tjmahr/status/1094808459239981056&#34;&gt;it can be surprising&lt;/a&gt; when you discover it’s handy for correlations, too. In short, you can fit them using a few tricks based on the &lt;a href=&#34;https://cran.r-project.org/web/packages/brms/vignettes/brms_multivariate.html&#34;&gt;multivariate syntax&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Shortly after uploading the post, it occurred to me we had more options and it might be useful to walk through them a bit.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;i-assume-things.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;I assume things.&lt;/h2&gt;
&lt;p&gt;For this post, I’m presuming you are vaguely familiar with linear regression–both univariate and multivariate–, have a little background with Bayesian statistics, and have used Paul Bürkner’s brms packge. As you might imagine, all code in is &lt;a href=&#34;https://www.r-bloggers.com/why-use-r-five-reasons/&#34;&gt;R&lt;/a&gt;, with a heavy use of the &lt;a href=&#34;http://style.tidyverse.org&#34;&gt;tidyverse&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;we-need-data.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;We need data.&lt;/h2&gt;
&lt;p&gt;First, we’ll load our main packages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(mvtnorm)
library(brms)
library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’ll use the &lt;a href=&#34;https://cran.r-project.org/web/packages/mvtnorm/index.html&#34;&gt;mvtnorm package&lt;/a&gt; to simulate three positively correlated variables.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m &amp;lt;- c(10, 15, 20)  # the means
s &amp;lt;- c(10, 20, 30)  # the sigmas
r &amp;lt;- c(.9, .6, .3)  # the correlations

# here&amp;#39;s the variance/covariance matrix
v &amp;lt;- 
  matrix(c((s[1] * s[1]),        (s[2] * s[1] * r[1]), (s[3] * s[1] * r[2]),
           (s[2] * s[1] * r[1]), (s[2] * s[2]),        (s[3] * s[2] * r[3]),
           (s[3] * s[1] * r[2]), (s[3] * s[2] * r[3]), (s[3] * s[3])),
         nrow = 3, ncol = 3)

# after setting our seed, we&amp;#39;re ready to simulate with `rmvnorm()`
set.seed(1)
d &amp;lt;- 
  rmvnorm(n = 50, mean = m, sigma = v) %&amp;gt;% 
  as_tibble() %&amp;gt;% 
  set_names(&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;, &amp;quot;z&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Our data look like so.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(GGally)
theme_set(theme_gray() +
            theme(panel.grid = element_blank()))

d %&amp;gt;% 
  ggpairs()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-16-bayesian-correlations-let-s-talk-options_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Do note the Pearson’s correlation coefficients in the upper triangle.&lt;/p&gt;
&lt;p&gt;In order to exploit all the methods we’ll cover in this post, we need to standardize our data. Here we do so by hand using the typical formula&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[z_{x_i} = \frac{x_i - \overline x}{s_x}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\overline x\)&lt;/span&gt; is the observed mean and &lt;span class=&#34;math inline&#34;&gt;\(s_x\)&lt;/span&gt; is the observed standard deviation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;d &amp;lt;-
  d %&amp;gt;% 
  mutate(x_s = (x - mean(x)) / sd(x),
         y_s = (y - mean(y)) / sd(y),
         z_s = (z - mean(z)) / sd(z))

head(d)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 6
##        x     y      z    x_s      y_s    z_s
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1   3.90  11.5  -6.90 -0.723 -0.308   -0.928
## 2  17.7   29.5   4.01  0.758  0.653   -0.512
## 3  20.4   33.8  41.5   1.05   0.886    0.917
## 4  20.3   42.1  34.8   1.04   1.33     0.663
## 5  -3.64 -26.8  43.5  -1.53  -2.36     0.994
## 6  13.9   17.3  47.6   0.347  0.00255  1.15&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are at least two broad ways to get correlations out of standardized data in brms. One way uses the typical univariate syntax. The other way is an extension of the multivariate &lt;code&gt;cbind()&lt;/code&gt; approach. Let’s start univariate.&lt;/p&gt;
&lt;p&gt;And for a point of clarification, we’re presuming the Gaussian likelihood for all the examples in this post.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;univariate&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Univariate&lt;/h2&gt;
&lt;p&gt;If you fit a simple univariate model with standardized data and a single predictor, the coefficient for the slope will be in a correlation-like metric. Happily, since the data are all standardized, it’s easy to use &lt;a href=&#34;https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations&#34;&gt;regularizing priors&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f1 &amp;lt;- 
  brm(data = d, 
      family = gaussian,
      y_s ~ 1 + x_s,
      prior = c(prior(normal(0, 1), class = Intercept),
                prior(normal(0, 1), class = b),
                prior(normal(0, 1), class = sigma)),
      chains = 4, cores = 4, 
      seed = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Take a look at the model summary.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(f1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: y_s ~ 1 + x_s 
##    Data: d (Number of observations: 50) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept     0.00      0.06    -0.12     0.12       3602 1.00
## x_s           0.91      0.06     0.78     1.03       3324 1.00
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sigma     0.42      0.04     0.35     0.52       3492 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The ‘Population-Level Effects’ has the summary information for our intercept and slope. Notice how our &lt;code&gt;x_s&lt;/code&gt; slope is the same as the Pearson’s correlation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor(d$x, d$y)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.9119708&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Since this approach only yields one correlation at a time, we have to fit two more models to get the other two correlations. To do so with haste, we can use the &lt;code&gt;update()&lt;/code&gt; syntax.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f2 &amp;lt;-
  update(f1,
         newdata = d,
         formula = z_s ~ 1 + x_s)

f3 &amp;lt;-
  update(f2,
         newdata = d,
         formula = z_s ~ 1 + y_s)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With the &lt;code&gt;fixef()&lt;/code&gt; function, we can easily isolate the &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; estimates.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fixef(f2)[2, ]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Estimate Est.Error      Q2.5     Q97.5 
## 0.5857431 0.1200180 0.3491512 0.8181209&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fixef(f3)[2, ]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Estimate  Est.Error       Q2.5      Q97.5 
## 0.31295659 0.13847579 0.03713735 0.58539395&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There’s another thing I’d like to point out. Plotting the model results will help make the point.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# define the predictor values you&amp;#39;d like the fitted values for
nd &amp;lt;- tibble(x_s = seq(from = -3, to = 3, length.out = d %&amp;gt;% nrow()))

# wrangle
fitted(f1,
       newdata = nd) %&amp;gt;% 
  as_tibble() %&amp;gt;% 
  bind_cols(nd) %&amp;gt;% 
  
  # plot
  ggplot(aes(x_s)) +
  geom_vline(xintercept = 0, color = &amp;quot;white&amp;quot;) +
  geom_hline(yintercept = 0, color = &amp;quot;white&amp;quot;) +
  geom_point(data = d,
             aes(y = y_s)) +
  geom_smooth(aes(y = Estimate, ymin = Q2.5, ymax = Q97.5),
              stat = &amp;quot;identity&amp;quot;,
              alpha = 1/4, size = 1/2) +
  coord_cartesian(xlim = range(d$x_s),
                  ylim = range(d$y_s))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-16-bayesian-correlations-let-s-talk-options_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;336&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The blue line is the posterior mean and the surrounding gray ribbon depicts the 95% posterior interval. Notice how the data and their respective fitted lines pass through [0, 0]? This is a consequence of modeling standardized data. We should always expect the intercept of a model like this to be 0. Here are the intercept summaries for all three models.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fixef(f1)[&amp;quot;Intercept&amp;quot;, ] %&amp;gt;% round(3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Estimate Est.Error      Q2.5     Q97.5 
##     0.001     0.061    -0.120     0.119&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fixef(f2)[&amp;quot;Intercept&amp;quot;, ] %&amp;gt;% round(3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Estimate Est.Error      Q2.5     Q97.5 
##    -0.001     0.117    -0.227     0.223&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fixef(f3)[&amp;quot;Intercept&amp;quot;, ] %&amp;gt;% round(3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Estimate Est.Error      Q2.5     Q97.5 
##    -0.003     0.140    -0.282     0.267&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Within simulation error, they’re all centered on zero. So instead of estimating the intercept, why not just bake that into the models? Here we refit the models by fixing the intercept for each to zero.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f4 &amp;lt;-
  update(f1,
         formula = y_s ~ 0 + x_s)

f5 &amp;lt;-
  update(f4,
         newdata = d,
         formula = z_s ~ 0 + x_s)

f6 &amp;lt;-
  update(f4,
         newdata = d,
         formula = z_s ~ 0 + y_s)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look at the summary for the first.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(f4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: y_s ~ x_s - 1 
##    Data: d (Number of observations: 50) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##     Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## x_s     0.91      0.06     0.79     1.03       2562 1.00
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sigma     0.42      0.04     0.35     0.52       2440 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Even though it may have seemed like we substantially changed the models by fixing the intercepts to 0, the summaries are essentially the same as when we estimated the intercepts. Here we’ll confirm the summaries with a plot, like above.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# wrangle
fitted(f4,
       newdata = nd) %&amp;gt;% 
  as_tibble() %&amp;gt;% 
  bind_cols(nd) %&amp;gt;% 
  
  # plot
  ggplot(aes(x_s)) +
  geom_vline(xintercept = 0, color = &amp;quot;white&amp;quot;) +
  geom_hline(yintercept = 0, color = &amp;quot;white&amp;quot;) +
  geom_point(data = d,
             aes(y = y_s)) +
  geom_smooth(aes(y = Estimate, ymin = Q2.5, ymax = Q97.5),
              stat = &amp;quot;identity&amp;quot;,
              alpha = 1/4, size = 1/2) +
  coord_cartesian(xlim = range(d$x_s),
                  ylim = range(d$y_s))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-16-bayesian-correlations-let-s-talk-options_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;336&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The difference is subtle. By fixing the intercepts at 0, we estimated the slopes (i.e., the correlations) with increased precision as demonstrated by the slightly smaller posterior standard deviations (i.e., the values in the ‘Est.Error’ columns).&lt;/p&gt;
&lt;p&gt;Here are the correlation summaries for those last three models.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fixef(f4) %&amp;gt;% round(3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     Estimate Est.Error  Q2.5 Q97.5
## x_s    0.907     0.062 0.786 1.029&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fixef(f5) %&amp;gt;% round(3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     Estimate Est.Error  Q2.5 Q97.5
## x_s    0.584     0.122 0.352 0.823&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fixef(f6) %&amp;gt;% round(3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     Estimate Est.Error  Q2.5 Q97.5
## y_s    0.316     0.137 0.052 0.583&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But anyway, you get the idea. If you want to estimate a correlation in brms using simple univariate syntax, just (a) standardize the data and (b) fit a univariate model with or without an intercept. The slop will be in a correlation-like metric.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lets-go-multivariate.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Let’s go multivariate.&lt;/h2&gt;
&lt;p&gt;If you don’t recall the steps to fit correlations in brms with the multivariate syntax, here they are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;List the variables you’d like correlations for within &lt;code&gt;cbind()&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Place the &lt;code&gt;cbind()&lt;/code&gt; function within the left side of the model formula.&lt;/li&gt;
&lt;li&gt;On the right side of the model formula, indicate you only want intercepts (i.e., &lt;code&gt;~ 1&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f7 &amp;lt;- 
  brm(data = d, 
      family = gaussian,
      cbind(x_s, y_s, z_s) ~ 1,
      prior = c(prior(normal(0, 1), class = Intercept),
                prior(normal(1, 1), class = sigma, resp = xs),
                prior(normal(1, 1), class = sigma, resp = ys),
                prior(normal(1, 1), class = sigma, resp = zs),
                prior(lkj(2), class = rescor)),
      chains = 4, cores = 4, 
      seed = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Behold the summary.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(f7)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: MV(gaussian, gaussian, gaussian) 
##   Links: mu = identity; sigma = identity
##          mu = identity; sigma = identity
##          mu = identity; sigma = identity 
## Formula: x_s ~ 1 
##          y_s ~ 1 
##          z_s ~ 1 
##    Data: d (Number of observations: 50) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##              Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## xs_Intercept    -0.01      0.13    -0.27     0.24       2318 1.00
## ys_Intercept    -0.01      0.13    -0.28     0.25       2500 1.00
## zs_Intercept    -0.00      0.14    -0.28     0.28       3068 1.00
## 
## Family Specific Parameters: 
##          Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sigma_xs     0.99      0.10     0.82     1.19       2222 1.00
## sigma_ys     1.00      0.10     0.83     1.23       2158 1.00
## sigma_zs     1.02      0.10     0.84     1.25       3043 1.00
## 
## Residual Correlations: 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## rescor(xs,ys)     0.90      0.03     0.83     0.94       2344 1.00
## rescor(xs,zs)     0.55      0.09     0.35     0.71       3114 1.00
## rescor(ys,zs)     0.25      0.12     0.01     0.48       2908 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Look at the ‘Residual Correlations:’ section at the bottom of the output. Since there are no predictors in the model, the residual correlations are just correlations. Now notice how the intercepts in this model are also hovering around 0, just like in our univariate models. Yep, we can fix those, too.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f8 &amp;lt;- 
  brm(data = d, 
      family = gaussian,
      cbind(x_s, y_s, z_s) ~ 0,
      prior = c(prior(normal(1, 1), class = sigma, resp = xs),
                prior(normal(1, 1), class = sigma, resp = ys),
                prior(normal(1, 1), class = sigma, resp = zs),
                prior(lkj(2), class = rescor)),
      chains = 4, cores = 4, 
      seed = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Without the intercepts, the rest of the model is the same within simulation variance.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(f8)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: MV(gaussian, gaussian, gaussian) 
##   Links: mu = identity; sigma = identity
##          mu = identity; sigma = identity
##          mu = identity; sigma = identity 
## Formula: x_s ~ 0 
##          y_s ~ 0 
##          z_s ~ 0 
##    Data: d (Number of observations: 50) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Family Specific Parameters: 
##          Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sigma_xs     0.98      0.09     0.81     1.19       1768 1.00
## sigma_ys     0.99      0.10     0.82     1.20       1775 1.00
## sigma_zs     1.02      0.10     0.84     1.24       2642 1.00
## 
## Residual Correlations: 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## rescor(xs,ys)     0.90      0.03     0.83     0.94       2491 1.00
## rescor(xs,zs)     0.55      0.10     0.35     0.71       2661 1.00
## rescor(ys,zs)     0.26      0.13     0.01     0.50       2615 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you wanna get silly, we can prune even further. Did you notice how the estimates for &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; are all hovering around 1? Since we have no predictors, &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; is just an estimate of the population standard deviation. And since we’re working with standardized data, the population standard deviation has to be 1. Any other estimate would be nonsensical. So why not fix it to 1?&lt;/p&gt;
&lt;p&gt;With brms, we can fix those &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;s to 1 with a trick of the nonlinear &lt;a href=&#34;https://cran.r-project.org/web/packages/brms/vignettes/brms_distreg.html&#34;&gt;distributional modeling syntax&lt;/a&gt;. Recall when you model &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;, the brms default is to actually model its log. As is turns out, the log of 1 is zero.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;log(1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s how to make use of that within &lt;code&gt;brm()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f9 &amp;lt;-
  brm(data = d, 
      family = gaussian,
      bf(cbind(x_s, y_s, z_s) ~ 0,
         sigma ~ 0),
      prior = c(prior(lkj(2), class = rescor)),
      chains = 4, cores = 4, 
      seed = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Other than the &lt;code&gt;sigma ~ 0&lt;/code&gt; syntax, the main thing to notice is we’ve wrapped the entire model &lt;code&gt;formula&lt;/code&gt; into the &lt;code&gt;bf()&lt;/code&gt; function. Here are the results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(f9)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: MV(gaussian, gaussian, gaussian) 
##   Links: mu = identity; sigma = log
##          mu = identity; sigma = log
##          mu = identity; sigma = log 
## Formula: x_s ~ 0 
##          sigma ~ 0
##          y_s ~ 0 
##          sigma ~ 0
##          z_s ~ 0 
##          sigma ~ 0
##    Data: d (Number of observations: 50) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Residual Correlations: 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## rescor(xs,ys)     0.91      0.02     0.87     0.93       2640 1.00
## rescor(xs,zs)     0.57      0.07     0.42     0.69       3109 1.00
## rescor(ys,zs)     0.29      0.09     0.11     0.47       3098 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The correlations are the only things left in the model.&lt;/p&gt;
&lt;p&gt;Just to be clear, the multivariate approach does not require standardized data. To demonstrate, here we refit &lt;code&gt;f7&lt;/code&gt;, but with the unstandardized variables. And, since we’re no longer in the standardized metric, we’ll be less certain with our priors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f10 &amp;lt;- 
  brm(data = d, 
      family = gaussian,
      cbind(x, y, z) ~ 1,
      prior = c(prior(normal(0, 10), class = Intercept),
                prior(student_t(3, 0, 10), class = sigma, resp = x),
                prior(student_t(3, 0, 10), class = sigma, resp = y),
                prior(student_t(3, 0, 10), class = sigma, resp = z),
                prior(lkj(2), class = rescor)),
      chains = 4, cores = 4, 
      seed = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;See, the ‘rescor()’ results are about the same as with &lt;code&gt;f7&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(f10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: MV(gaussian, gaussian, gaussian) 
##   Links: mu = identity; sigma = identity
##          mu = identity; sigma = identity
##          mu = identity; sigma = identity 
## Formula: x ~ 1 
##          y ~ 1 
##          z ~ 1 
##    Data: d (Number of observations: 50) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##             Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## x_Intercept     9.64      1.20     7.29    12.00       1821 1.00
## y_Intercept    15.57      2.47    10.69    20.34       2032 1.00
## z_Intercept    14.85      3.38     8.00    21.42       2760 1.00
## 
## Family Specific Parameters: 
##         Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sigma_x     8.99      0.87     7.50    10.91       2005 1.00
## sigma_y    18.24      1.81    15.18    22.05       1981 1.00
## sigma_z    26.09      2.62    21.58    31.77       3011 1.00
## 
## Residual Correlations: 
##             Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## rescor(x,y)     0.89      0.03     0.83     0.94       2301 1.00
## rescor(x,z)     0.54      0.09     0.34     0.70       3046 1.00
## rescor(y,z)     0.24      0.12    -0.00     0.47       2830 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;its-time-to-compare-methods.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;It’s time to compare methods.&lt;/h2&gt;
&lt;p&gt;To recap, we’ve compared several ways to fit correlations in brms. Some of the methods were with univariate syntax, others were with the multivariate syntax. Some of the models had all free parameters, others included fixed intercepts and sigmas. Whereas all the univariate models required standardized data, the multivariate approach can work with unstandardized data, too.&lt;/p&gt;
&lt;p&gt;Now it might be of help to compare the results from each of the methods to get a sense of which ones you might prefer. Before we do so, we’ll define a couple custom functions to streamline the data wrangling.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;get_rho &amp;lt;- function(fit) {
  posterior_samples(fit) %&amp;gt;% 
    select(starts_with(&amp;quot;b_&amp;quot;), -contains(&amp;quot;Intercept&amp;quot;)) %&amp;gt;% 
    set_names(&amp;quot;rho&amp;quot;) 
}

get_rescor &amp;lt;- function(fit) {
  posterior_samples(fit) %&amp;gt;% 
    select(starts_with(&amp;quot;rescor&amp;quot;)) %&amp;gt;% 
    set_names(&amp;quot;x with y&amp;quot;, &amp;quot;x with z&amp;quot;, &amp;quot;y with z&amp;quot;) %&amp;gt;% 
    gather(label, rho) %&amp;gt;% 
    select(rho, label)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let’s put those functions to work and plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidybayes)

# collect the posteriors from the univariate models
tibble(name = str_c(&amp;quot;f&amp;quot;, 1:6)) %&amp;gt;% 
  mutate(fit = map(name, get)) %&amp;gt;% 
  mutate(rho = map(fit, get_rho)) %&amp;gt;% 
  unnest(rho) %&amp;gt;% 
  mutate(predictor = rep(c(&amp;quot;x&amp;quot;, &amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;), each = 4000) %&amp;gt;% rep(., times = 2),
         criterion = rep(c(&amp;quot;y&amp;quot;, &amp;quot;z&amp;quot;, &amp;quot;z&amp;quot;), each = 4000) %&amp;gt;% rep(., times = 2)) %&amp;gt;% 
  mutate(label = str_c(predictor, &amp;quot; with &amp;quot;, criterion)) %&amp;gt;% 
  select(-c(predictor:criterion)) %&amp;gt;% 
  # add in the posteriors from the multivariate models
  bind_rows(
    tibble(name = str_c(&amp;quot;f&amp;quot;, 7:10)) %&amp;gt;% 
      mutate(fit = map(name, get)) %&amp;gt;% 
      mutate(post = map(fit, get_rescor)) %&amp;gt;% 
      unnest(post)
  ) %&amp;gt;% 
  # wrangle a bit just to make the y axis easier to understand
  mutate(name = factor(name, 
                       levels = c(str_c(&amp;quot;f&amp;quot;, 1:10)),
                       labels = c(&amp;quot;1. standardized, univariate&amp;quot;,
                                  &amp;quot;2. standardized, univariate&amp;quot;,
                                  &amp;quot;3. standardized, univariate&amp;quot;,
                                  &amp;quot;4. standardized, univariate, fixed intercepts&amp;quot;,
                                  &amp;quot;5. standardized, univariate, fixed intercepts&amp;quot;,
                                  &amp;quot;6. standardized, univariate, fixed intercepts&amp;quot;,
                                  &amp;quot;7. standardized, multivariate, fixed intercepts&amp;quot;,
                                  &amp;quot;8. standardized, multivariate, fixed intercepts&amp;quot;,
                                  &amp;quot;9. standardized, multivariate, fixed intercepts/sigmas&amp;quot;,
                                  &amp;quot;10. unstandardized, multivariate&amp;quot;))) %&amp;gt;%
  
  # plot
  ggplot(aes(x = rho, y = name)) +
  geom_vline(data = tibble(label = c(&amp;quot;x with y&amp;quot;, &amp;quot;x with z&amp;quot;, &amp;quot;y with z&amp;quot;),
                           rho   = r),
             aes(xintercept = rho), color = &amp;quot;white&amp;quot;) +
  geom_halfeyeh(.width = .95, size = 5/4) +
  scale_x_continuous(breaks = c(0, r)) +
  labs(x = expression(rho),
       y = NULL) +
  coord_cartesian(0:1) +
  theme(axis.ticks.y = element_blank(),
        axis.text.y  = element_text(hjust = 0)) +
  facet_wrap(~label, ncol = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-16-bayesian-correlations-let-s-talk-options_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;To my eye, a few patterns emerged. First, the point estimates were about the same across methods. Second, fixing the intercepts didn’t seem to effect things, much. But, third, it appears that fixing the sigmas in the multivariate models did narrow the posteriors a bit.&lt;/p&gt;
&lt;p&gt;Fourth, and perhaps most importantly, notice how the posteriors for the multivariate models were more asymmetric when they approached 1. Hopefully this makes intuitive sense. Correlations are bound between -1 and 1. However, standardized regression coefficients are not so bound. Accordingly, notice how the posteriors from the univariate models stayed symmetric when approaching 1 and some of their right tails even crossed over 1. So while the univariate approach did a reasonable job capturing the correlation point estimates, their posteriors weren’t quite in a correlation metric. Alternately, the univariate approach did make it convenient to express the correlations with fitted regression lines in scatter plots.&lt;/p&gt;
&lt;p&gt;Both univariate and multivariate approaches appear to have their strengths and weaknesses. Choose which methods seems most appropriate for your correlation needs.&lt;/p&gt;
&lt;p&gt;Happy modeling.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 3.5.1 (2018-07-02)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS High Sierra 10.13.6
## 
## Matrix products: default
## BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] tidybayes_1.0.3 bindrcpp_0.2.2  GGally_1.4.0    forcats_0.3.0  
##  [5] stringr_1.3.1   dplyr_0.7.6     purrr_0.2.5     readr_1.1.1    
##  [9] tidyr_0.8.1     tibble_2.0.1    tidyverse_1.2.1 brms_2.7.0     
## [13] ggplot2_3.1.0   Rcpp_1.0.0      mvtnorm_1.0-8  
## 
## loaded via a namespace (and not attached):
##   [1] colorspace_1.3-2          ggridges_0.5.0           
##   [3] rsconnect_0.8.8           rprojroot_1.3-2          
##   [5] ggstance_0.3              markdown_0.8             
##   [7] base64enc_0.1-3           rstudioapi_0.7           
##   [9] rstan_2.18.2              svUnit_0.7-12            
##  [11] DT_0.4                    fansi_0.4.0              
##  [13] lubridate_1.7.4           xml2_1.2.0               
##  [15] bridgesampling_0.4-0      codetools_0.2-15         
##  [17] knitr_1.20                shinythemes_1.1.1        
##  [19] bayesplot_1.6.0           jsonlite_1.5             
##  [21] broom_0.5.1               shiny_1.1.0              
##  [23] compiler_3.5.1            httr_1.3.1               
##  [25] backports_1.1.2           assertthat_0.2.0         
##  [27] Matrix_1.2-14             lazyeval_0.2.1           
##  [29] cli_1.0.1                 later_0.7.3              
##  [31] htmltools_0.3.6           prettyunits_1.0.2        
##  [33] tools_3.5.1               igraph_1.2.1             
##  [35] coda_0.19-2               gtable_0.2.0             
##  [37] glue_1.3.0                reshape2_1.4.3           
##  [39] cellranger_1.1.0          nlme_3.1-137             
##  [41] blogdown_0.8              crosstalk_1.0.0          
##  [43] xfun_0.3                  ps_1.2.1                 
##  [45] rvest_0.3.2               mime_0.5                 
##  [47] miniUI_0.1.1.1            gtools_3.8.1             
##  [49] MASS_7.3-50               zoo_1.8-2                
##  [51] scales_1.0.0              colourpicker_1.0         
##  [53] hms_0.4.2                 promises_1.0.1           
##  [55] Brobdingnag_1.2-5         parallel_3.5.1           
##  [57] inline_0.3.15             shinystan_2.5.0          
##  [59] RColorBrewer_1.1-2        yaml_2.1.19              
##  [61] gridExtra_2.3             loo_2.0.0                
##  [63] StanHeaders_2.18.0-1      reshape_0.8.7            
##  [65] stringi_1.2.3             dygraphs_1.1.1.5         
##  [67] pkgbuild_1.0.2            rlang_0.3.1              
##  [69] pkgconfig_2.0.2           matrixStats_0.54.0       
##  [71] evaluate_0.10.1           lattice_0.20-35          
##  [73] bindr_0.1.1               rstantools_1.5.0         
##  [75] htmlwidgets_1.2           labeling_0.3             
##  [77] processx_3.2.1            tidyselect_0.2.4         
##  [79] plyr_1.8.4                magrittr_1.5             
##  [81] bookdown_0.7              R6_2.3.0                 
##  [83] generics_0.0.2            pillar_1.3.1             
##  [85] haven_1.1.2               withr_2.1.2              
##  [87] xts_0.10-2                abind_1.4-5              
##  [89] modelr_0.1.2              crayon_1.3.4             
##  [91] arrayhelpers_1.0-20160527 utf8_1.1.4               
##  [93] rmarkdown_1.10            grid_3.5.1               
##  [95] readxl_1.1.0              callr_3.1.0              
##  [97] threejs_0.3.1             digest_0.6.18            
##  [99] xtable_1.8-2              httpuv_1.4.4.2           
## [101] stats4_3.5.1              munsell_0.5.0            
## [103] shinyjs_1.0&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Bayesian robust correlations with brms (and why you should love Student’s $t$)</title>
      <link>/post/bayesian-robust-correlations-with-brms-and-why-you-should-love-student-s-t/</link>
      <pubDate>Sun, 10 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/bayesian-robust-correlations-with-brms-and-why-you-should-love-student-s-t/</guid>
      <description>&lt;p&gt;[edited June 18, 2019]&lt;/p&gt;
&lt;p&gt;In this post, we’ll show how Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution can produce better correlation estimates when your data have outliers. As is often the case, we’ll do so as Bayesians.&lt;/p&gt;
&lt;p&gt;This post is a direct consequence of Adrian Baez-Ortega’s great blog, “&lt;a href=&#34;https://baezortega.github.io/2018/05/28/robust-correlation/&#34;&gt;Bayesian robust correlation with Stan in R (and why you should use Bayesian methods)&lt;/a&gt;”. Baez-Ortega worked out the approach and code for direct use with &lt;a href=&#34;http://mc-stan.org&#34;&gt;Stan&lt;/a&gt; computational environment. That solution is great because Stan is free, open source, and very flexible. However, Stan’s interface might be prohibitively technical for non-statistician users. Happily, the &lt;a href=&#34;https://github.com/paul-buerkner/brms&#34;&gt;brms&lt;/a&gt; package allows users to access the computational power of Stan through a simpler interface. In this post, we show how to extend Baez-Ortega’s method to brms. To pay respects where they’re due, the synthetic data, priors, and other model settings are largely the same as those Baez-Ortega used in his blog.&lt;/p&gt;
&lt;div id=&#34;i-make-assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;I make assumptions&lt;/h2&gt;
&lt;p&gt;For this post, I’m presuming you are vaguely familiar with linear regression, know about the basic differences between frequentist and Bayesian approaches to fitting models, and have a sense that the issue of outlier values is a pickle worth contending with. All code in is &lt;a href=&#34;https://www.r-bloggers.com/why-use-r-five-reasons/&#34;&gt;R&lt;/a&gt;, with a heavy use of the &lt;a href=&#34;http://style.tidyverse.org&#34;&gt;tidyverse&lt;/a&gt;–which you might learn a lot about &lt;a href=&#34;http://r4ds.had.co.nzhttp://r4ds.had.co.nz&#34;&gt;here, especially chapter 5&lt;/a&gt;–, and, of course, Bürkner’s &lt;a href=&#34;https://github.com/paul-buerkner/brms&#34;&gt;brms&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you’d like a warmup, consider checking out my related post, &lt;a href=&#34;https://solomonkurz.netlify.com/post/robust-linear-regression-with-the-robust-student-s-t-distribution/&#34;&gt;Robust Linear Regression with Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-Distribution&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;whats-the-deal&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What’s the deal?&lt;/h2&gt;
&lt;p&gt;Pearson’s correlations are designed to quantify the linear relationship between two normally distributed variables. The normal distribution and its multivariate generalization, the multivariate normal distribution, are sensitive to outliers. When you have well-behaved synthetic data, this isn’t an issue. But if you work real-world data, this can be a problem. One can have data for which the vast majority of cases are well-characterized by a nice liner relationship, but have a few odd cases for which that relationship does not hold. And if those odd cases happen to be overly influential–sometimes called leverage points–the resulting Pearson’s correlation coefficient might look off.&lt;/p&gt;
&lt;p&gt;Recall that the normal distribution is a special case of Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution with the &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; parameter (i.e., &lt;em&gt;nu&lt;/em&gt;, degree of freedom) set to infinity. As it turns out, when &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; is small, Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution is more robust to multivariate outliers. It’s less influenced by them. I’m not going to cover why in any detail. For that you’ve got &lt;a href=&#34;https://baezortega.github.io/2018/05/28/robust-correlation/&#34;&gt;Baez-Ortega’s blog&lt;/a&gt;, an even earlier blog from &lt;a href=&#34;http://www.sumsar.net/blog/2013/08/bayesian-estimation-of-correlation/&#34;&gt;Rasmus Bååth&lt;/a&gt;, and textbook treatments on the topic by &lt;a href=&#34;http://www.stat.columbia.edu/~gelman/arm/&#34;&gt;Gelman &amp;amp; Hill (2007, chapter 6)&lt;/a&gt; and &lt;a href=&#34;https://sites.google.com/site/doingbayesiandataanalysis/&#34;&gt;Kruschke (2014, chapter 16)&lt;/a&gt;. Here we’ll get a quick sense of how vulnerable Pearson’s correlations–with their reliance on the Gaussian–are to outliers, we’ll demonstrate how fitting correlations within the Bayesian paradigm using the conventional Gaussian likelihood is similarly vulnerable to distortion, and then see how Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution can save the day. And importantly, we’ll do the bulk of this with the brms package.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;we-need-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;We need data&lt;/h2&gt;
&lt;p&gt;To start off, we’ll make a multivariate normal simulated data set using the same steps Baez-Ortega’s used.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(mvtnorm)
library(tidyverse)

sigma &amp;lt;- c(20, 40)  # the variances
rho   &amp;lt;- -.95       # the desired correlation

# here&amp;#39;s the variance/covariance matrix
cov.mat &amp;lt;- 
  matrix(c(sigma[1] ^ 2,
           sigma[1] * sigma[2] * rho,
           sigma[1] * sigma[2] * rho,
           sigma[2] ^ 2),
         nrow = 2, byrow = T)

# after setting our seed, we&amp;#39;re ready to simulate with `rmvnorm()`
set.seed(210191)
x.clean &amp;lt;- 
  rmvnorm(n = 40, sigma = cov.mat) %&amp;gt;% 
  as_tibble() %&amp;gt;% 
  rename(x = V1,
         y = V2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here we make our second data set, &lt;code&gt;x.noisy&lt;/code&gt;, which is identical to our well-behaved &lt;code&gt;x.clean&lt;/code&gt; data, but with the first three cases transformed to outlier values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x.noisy &amp;lt;- x.clean

x.noisy[1:3,] &amp;lt;-
  matrix(c(-40, -60,
           20, 100,
           40, 40),
         nrow = 3, byrow = T)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we’ll add an &lt;code&gt;outlier&lt;/code&gt; index to the data sets, which will help us with plotting.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x.clean &amp;lt;-
  x.clean %&amp;gt;% 
  mutate(outlier = factor(0))

x.noisy &amp;lt;- 
  x.noisy %&amp;gt;% 
  mutate(outlier = c(rep(1, 3), rep(0, 37)) %&amp;gt;% as.factor(.))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The plot below shows what the &lt;code&gt;x.clean&lt;/code&gt; data look like. I’m a fan of &lt;a href=&#34;http://fivethirtyeight.com&#34;&gt;FiveThirtyEight&lt;/a&gt;, so we’ll use a few convenience functions from the handy &lt;a href=&#34;https://github.com/jrnold/ggthemes&#34;&gt;ggthemes package&lt;/a&gt; to give our plots a FiveThirtyEight-like feel.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggthemes)

x.clean %&amp;gt;% 
  ggplot(aes(x = x, y = y, color = outlier, fill = outlier)) +
  geom_point() +
  stat_ellipse(geom = &amp;quot;polygon&amp;quot;, alpha = .15, size = .15, level = .5) +
  stat_ellipse(geom = &amp;quot;polygon&amp;quot;, alpha = .15, size = .15, level = .95) +
  scale_color_fivethirtyeight() +
  scale_fill_fivethirtyeight() +
  coord_cartesian(xlim = -50:50,
                  ylim = -100:100) +
  theme_fivethirtyeight() +
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-09-bayesian-robust-correlations-with-brms-and-why-you-should-love-student-s-t_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;312&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And here are the &lt;code&gt;x.noisy&lt;/code&gt; data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x.noisy %&amp;gt;% 
  ggplot(aes(x = x, y = y, color = outlier, fill = outlier)) +
  geom_point() +
  stat_ellipse(geom = &amp;quot;polygon&amp;quot;, alpha = .15, size = .15, level = .5) +
  stat_ellipse(geom = &amp;quot;polygon&amp;quot;, alpha = .15, size = .15, level = .95) +
  scale_color_fivethirtyeight() +
  scale_fill_fivethirtyeight() +
  coord_cartesian(xlim = -50:50,
                  ylim = -100:100) +
  theme_fivethirtyeight() +
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-09-bayesian-robust-correlations-with-brms-and-why-you-should-love-student-s-t_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;312&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The three outliers are in red. Even in their presence, the old interocular trauma test suggests there is a pronounced overall trend in the data. I would like a correlation procedure that’s capable of capturing that overall trend. Let’s examine some candidates.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-does-old-pearson-hold-up&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;How does old Pearson hold up?&lt;/h2&gt;
&lt;p&gt;A quick way to get a Pearson’s correlation coefficient in R is with the &lt;code&gt;cor()&lt;/code&gt; function, which does a nice job recovering the correlation we simulated the &lt;code&gt;x.clean&lt;/code&gt; data with:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor(x.clean$x, x.clean$y)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] -0.959702&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, things fall apart if you use &lt;code&gt;cor()&lt;/code&gt; on the &lt;code&gt;x.noisy&lt;/code&gt; data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor(x.noisy$x, x.noisy$y)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] -0.6365649&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So even though most of the &lt;code&gt;x.noisy&lt;/code&gt; data continue to show a clear strong relation, three outlier values reduced the Pearson’s correlation a third of the way toward zero. Let’s see what happens when we go Bayesian.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bayesian-correlations-in-brms&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Bayesian correlations in brms&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://twitter.com/paulbuerkner&#34;&gt;Bürkner&lt;/a&gt;’s brms is a general purpose interface for fitting all manner of Bayesian regression models with &lt;a href=&#34;https://mc-stan.org&#34;&gt;Stan&lt;/a&gt; as the engine under the hood. It has popular &lt;a href=&#34;https://cran.r-project.org/web/packages/lme4/index.html&#34;&gt;lme4&lt;/a&gt;-like syntax and offers a variety of convenience functions for post processing. Let’s load it up.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(brms)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;Rcpp&amp;#39; was built under R version 3.5.2&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;first-with-the-gaussian-likelihood.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;First with the Gaussian likelihood.&lt;/h3&gt;
&lt;p&gt;I’m not going to spend a lot of time walking through the syntax in the main brms function, &lt;code&gt;brm()&lt;/code&gt;. You can learn all about that &lt;a href=&#34;https://github.com/paul-buerkner/brms&#34;&gt;here&lt;/a&gt; or with my project &lt;a href=&#34;https://github.com/ASKurz/Statistical_Rethinking_with_brms_ggplot2_and_the_tidyverse#statistical-rethinking-with-brms-ggplot2-and-the-tidyverse&#34;&gt;&lt;em&gt;Statistical Rethinking with brms, ggplot2, and the tidyverse&lt;/em&gt;&lt;/a&gt;. But our particular use of &lt;code&gt;brm()&lt;/code&gt; requires we make a few fine points.&lt;/p&gt;
&lt;p&gt;One doesn’t always think about bivariate correlations within the regression paradigm. But they work just fine. Within brms, you would typically specify the conventional Gaussian likelihood (i.e., &lt;code&gt;family = gaussian&lt;/code&gt;), use the &lt;code&gt;mvbind()&lt;/code&gt; syntax to set up a &lt;a href=&#34;https://cran.r-project.org/web/packages/brms/vignettes/brms_multivariate.html&#34;&gt;multivariate model&lt;/a&gt;, and fit that model without predictors. For each variable specified in &lt;code&gt;cbind()&lt;/code&gt;, you’ll estimate an intercept (i.e., mean, &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) and sigma (i.e., &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;, often called a residual variance). Since there are no predictors in the model, the residual variance is just the variance and the brms default for multivariate models is to allow the residual variances to covary. But since variances are parameterized in the standard deviation metric in brms, the residual variances and their covariance are &lt;em&gt;SD&lt;/em&gt;s and their correlation, respectively.&lt;/p&gt;
&lt;p&gt;Here’s what it looks like in practice.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f0 &amp;lt;- 
  brm(data = x.clean, 
      family = gaussian,
      mvbind(x, y) ~ 1,
      prior = c(prior(normal(0, 100), class = Intercept),
                prior(normal(0, 100), class = sigma, resp = x),
                prior(normal(0, 100), class = sigma, resp = y),
                prior(lkj(1), class = rescor)),
      iter = 2000, warmup = 500, chains = 4, cores = 4, 
      seed = 210191)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In a typical Bayesian workflow, you’d examine the quality of the chains with trace plots. The easy way to do that in brms is with &lt;code&gt;plot()&lt;/code&gt;. E.g., to get the trace plots for our first model, you’d code &lt;code&gt;plot(f0)&lt;/code&gt;. Happily, the trace plots look fine for all models in this post. For the sake of space, I’ll leave their inspection as exercises for interested readers.&lt;/p&gt;
&lt;p&gt;Our priors and such mirror those in Baez-Ortega’s blog. Here are the results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(f0)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: MV(gaussian, gaussian) 
##   Links: mu = identity; sigma = identity
##          mu = identity; sigma = identity 
## Formula: x ~ 1 
##          y ~ 1 
##    Data: x.clean (Number of observations: 40) 
## Samples: 4 chains, each with iter = 2000; warmup = 500; thin = 1;
##          total post-warmup samples = 6000
## 
## Population-Level Effects: 
##             Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## x_Intercept    -2.83      3.33    -9.33     3.69       2995 1.00
## y_Intercept     3.55      6.65    -9.45    16.60       2972 1.00
## 
## Family Specific Parameters: 
##         Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sigma_x    21.47      2.47    17.29    26.99       2453 1.00
## sigma_y    42.93      4.86    34.55    53.51       2418 1.00
## 
## Residual Correlations: 
##             Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## rescor(x,y)    -0.95      0.02    -0.98    -0.92       2636 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Way down there in the last line in the ‘Family Specific Parameters’ section we have &lt;code&gt;rescor(x,y)&lt;/code&gt;, which is our correlation. And indeed, our Gaussian intercept-only multivariate model did a great job recovering the correlation we used to simulate the &lt;code&gt;x.clean&lt;/code&gt; data with. Look at what happens when we try this approach with &lt;code&gt;x.noisy&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f1 &amp;lt;-
  update(f0,
         newdata = x.noisy,
         iter = 2000, warmup = 500, chains = 4, cores = 4, seed = 210191)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(f1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: MV(gaussian, gaussian) 
##   Links: mu = identity; sigma = identity
##          mu = identity; sigma = identity 
## Formula: x ~ 1 
##          y ~ 1 
##    Data: x.noisy (Number of observations: 40) 
## Samples: 4 chains, each with iter = 2000; warmup = 500; thin = 1;
##          total post-warmup samples = 6000
## 
## Population-Level Effects: 
##             Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## x_Intercept    -2.95      3.75   -10.39     4.57       4477 1.00
## y_Intercept     6.52      7.45    -8.31    20.98       4692 1.00
## 
## Family Specific Parameters: 
##         Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sigma_x    23.65      2.76    18.97    29.83       4312 1.00
## sigma_y    47.20      5.42    37.94    59.03       4332 1.00
## 
## Residual Correlations: 
##             Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## rescor(x,y)    -0.61      0.10    -0.78    -0.39       4480 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And the correlation estimate is -.61. As it turns out, &lt;code&gt;data = x.noisy&lt;/code&gt; + &lt;code&gt;family = gaussian&lt;/code&gt; in &lt;code&gt;brm()&lt;/code&gt; failed us just like Pearson’s correlation failed us. Time to leave failure behind.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;now-with-students-t-distribution.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Now with Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution.&lt;/h3&gt;
&lt;p&gt;Before we jump into using &lt;code&gt;family = student&lt;/code&gt;, we should talk a bit about &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt;. This is our new parameter which is silently fixed to infinity when we use the Gaussian likelihood. The &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; parameter is bound at zero but, as discussed in Baez-Ortega’s blog, is somewhat nonsensical for values below 1. As it turns out, &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; is constrained to be equal to or greater than 1 in brms. So nothing for us to worry about, there. The &lt;a href=&#34;https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations&#34;&gt;Stan team currently recommends the gamma(2, 0.1) prior for &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt;&lt;/a&gt;, which is also the current brms default. This is what that distribution looks like.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tibble(x = seq(from = 1, to = 120, by = .5)) %&amp;gt;% 
  ggplot(aes(x = x, fill = factor(0))) +
  geom_ribbon(aes(ymin = 0, 
                  ymax = dgamma(x, 2, 0.1))) +
  scale_y_continuous(NULL, breaks = NULL) +
  scale_fill_fivethirtyeight() +
  coord_cartesian(xlim = 0:100) +
  ggtitle(&amp;quot;gamma(2, 0.1)&amp;quot;) +
  theme_fivethirtyeight() +
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-09-bayesian-robust-correlations-with-brms-and-why-you-should-love-student-s-t_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So gamma(2, 0.1) should gently push the &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; posterior toward low values, but it’s slowly-sloping right tail will allow higher values to emerge.&lt;/p&gt;
&lt;p&gt;Following the Stan team’s recommendation, the brms default and Baez-Ortega’s blog, here’s our robust Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; model for the &lt;code&gt;x.noisy&lt;/code&gt; data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f2 &amp;lt;- 
  brm(data = x.noisy, 
      family = student,
      mvbind(x, y) ~ 1,
      prior = c(prior(gamma(2, .1), class = nu),
                prior(normal(0, 100), class = Intercept),
                prior(normal(0, 100), class = sigma, resp = x),
                prior(normal(0, 100), class = sigma, resp = y),
                prior(lkj(1), class = rescor)),
      iter = 2000, warmup = 500, chains = 4, cores = 4, 
      seed = 210191)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(f2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: MV(student, student) 
##   Links: mu = identity; sigma = identity; nu = identity
##          mu = identity; sigma = identity; nu = identity 
## Formula: x ~ 1 
##          y ~ 1 
##    Data: x.noisy (Number of observations: 40) 
## Samples: 4 chains, each with iter = 2000; warmup = 500; thin = 1;
##          total post-warmup samples = 6000
## 
## Population-Level Effects: 
##             Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## x_Intercept    -2.11      3.61    -9.22     4.96       2936 1.00
## y_Intercept     1.93      7.12   -11.74    16.03       2949 1.00
## 
## Family Specific Parameters: 
##         Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sigma_x    18.26      2.92    13.06    24.48       3188 1.00
## sigma_y    36.31      5.79    26.08    48.60       3206 1.00
## nu          2.65      1.00     1.36     5.13       3905 1.00
## 
## Residual Correlations: 
##             Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## rescor(x,y)    -0.93      0.03    -0.97    -0.84       3484 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Whoa, look at that correlation, &lt;code&gt;rescore(x,y)&lt;/code&gt;! It’s right about what we’d hope for. Sure, it’s not a perfect -.95, but that’s way better than -.61.&lt;/p&gt;
&lt;p&gt;While we’re at it, we may as well see what happens when we fit a Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; model when we have perfectly multivariate normal data. Here it is with the &lt;code&gt;x.clean&lt;/code&gt; data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f3 &amp;lt;- 
  update(f2,
         newdata = x.clean, 
         iter = 2000, warmup = 500, chains = 4, cores = 4, seed = 210191)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(f3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: MV(student, student) 
##   Links: mu = identity; sigma = identity; nu = identity
##          mu = identity; sigma = identity; nu = identity 
## Formula: x ~ 1 
##          y ~ 1 
##    Data: x.clean (Number of observations: 40) 
## Samples: 4 chains, each with iter = 2000; warmup = 500; thin = 1;
##          total post-warmup samples = 6000
## 
## Population-Level Effects: 
##             Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## x_Intercept    -2.37      3.50    -9.20     4.39       2909 1.00
## y_Intercept     2.71      6.98   -10.90    16.48       3032 1.00
## 
## Family Specific Parameters: 
##         Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sigma_x    20.79      2.60    16.28    26.60       2388 1.00
## sigma_y    41.34      5.17    32.33    52.62       2417 1.00
## nu         22.42     13.78     5.70    57.53       4384 1.00
## 
## Residual Correlations: 
##             Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## rescor(x,y)    -0.96      0.01    -0.98    -0.92       3045 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So when you don’t need Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;, it yields the right answer anyways. That’s a nice feature.&lt;/p&gt;
&lt;p&gt;We should probably compare the posteriors of the correlations across the four models. First we’ll collect the posterior samples into a tibble.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posts &amp;lt;-
  tibble(model = str_c(&amp;quot;f&amp;quot;, 0:3)) %&amp;gt;% 
  mutate(fit  = map(model, get)) %&amp;gt;% 
  mutate(post = map(fit, posterior_samples)) %&amp;gt;% 
  unnest(post)

head(posts)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 8
##   model b_x_Intercept b_y_Intercept sigma_x sigma_y rescor__x__y  lp__
##   &amp;lt;chr&amp;gt;         &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 f0             1.31        -5.60     18.2    37.8       -0.947 -353.
## 2 f0            -7.41        10.6      25.2    50.5       -0.941 -357.
## 3 f0            -4.51         5.65     23.3    49.4       -0.975 -354.
## 4 f0            -2.65        -0.597    18.3    37.3       -0.929 -354.
## 5 f0            -2.76        -1.50     18.4    37.5       -0.923 -355.
## 6 f0            -9.84        15.2      26.3    45.1       -0.953 -358.
## # … with 1 more variable: nu &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With the posterior draws in hand, we just need to wrangle a bit before showing the correlation posteriors in a coefficient plot. To make things easier, we’ll do so with a couple convenience functions from the &lt;a href=&#34;https://github.com/mjskay/tidybayes&#34;&gt;tidybayes&lt;/a&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidybayes)

# wrangle
posts %&amp;gt;% 
  group_by(model) %&amp;gt;% 
  median_qi(rescor__x__y, .width = c(.5, .95)) %&amp;gt;% 
  mutate(key = recode(model, 
                      f0 = &amp;quot;Gaussian likelihood with clean data&amp;quot;,
                      f1 = &amp;quot;Gaussian likelihood with noisy data&amp;quot;,
                      f2 = &amp;quot;Student likelihood with noisy data&amp;quot;,
                      f3 = &amp;quot;Student likelihood with clean data&amp;quot;),
         clean = ifelse(model %in% c(&amp;quot;f0&amp;quot;, &amp;quot;f3&amp;quot;), &amp;quot;0&amp;quot;, &amp;quot;1&amp;quot;)) %&amp;gt;%
  
  # plot
  ggplot(aes(x = rescor__x__y, y = key, color = clean)) +
  geom_pointintervalh() +
  scale_color_fivethirtyeight() +
  coord_cartesian(xlim = -1:0) +
  labs(subtitle = expression(paste(&amp;quot;The posterior for &amp;quot;, rho, &amp;quot; depends on the likelihood. Why not go robust and use Student&amp;#39;s &amp;quot;, italic(t), &amp;quot;?&amp;quot;))) +
  theme_fivethirtyeight() +
  theme(axis.text.y     = element_text(hjust = 0),
        legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-09-bayesian-robust-correlations-with-brms-and-why-you-should-love-student-s-t_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;From our &lt;code&gt;tidybayes::median_qi()&lt;/code&gt; code, the dots are the posterior medians, the thick inner lines the 50% intervals, and the thinner outer lines the 95% intervals. The posteriors for the &lt;code&gt;x.noisy&lt;/code&gt; data are in red and those for the &lt;code&gt;x.clean&lt;/code&gt; data are in blue. If the data are clean multivariate normal Gaussian or if they’re dirty but fit with robust Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;, everything is pretty much alright. But whoa, if you fit a correlation with a combination of &lt;code&gt;family = gaussian&lt;/code&gt; and noisy outlier-laden data, man that’s just a mess.&lt;/p&gt;
&lt;p&gt;Don’t let a few overly-influential outliers make a mess of your analyses. Try the robust Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 3.5.1 (2018-07-02)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS High Sierra 10.13.6
## 
## Matrix products: default
## BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] tidybayes_1.0.4 bindrcpp_0.2.2  brms_2.8.8      Rcpp_1.0.1     
##  [5] ggthemes_4.0.1  forcats_0.3.0   stringr_1.4.0   dplyr_0.8.0.1  
##  [9] purrr_0.2.5     readr_1.1.1     tidyr_0.8.1     tibble_2.1.1   
## [13] ggplot2_3.1.1   tidyverse_1.2.1 mvtnorm_1.0-10 
## 
## loaded via a namespace (and not attached):
##   [1] readxl_1.1.0              backports_1.1.4          
##   [3] Hmisc_4.1-1               plyr_1.8.4               
##   [5] igraph_1.2.1              lazyeval_0.2.2           
##   [7] splines_3.5.1             svUnit_0.7-12            
##   [9] crosstalk_1.0.0           rstantools_1.5.1         
##  [11] inline_0.3.15             digest_0.6.18            
##  [13] htmltools_0.3.6           rsconnect_0.8.8          
##  [15] fansi_0.4.0               gdata_2.18.0             
##  [17] magrittr_1.5              checkmate_1.8.5          
##  [19] cluster_2.0.7-1           modelr_0.1.2             
##  [21] matrixStats_0.54.0        xts_0.10-2               
##  [23] prettyunits_1.0.2         colorspace_1.3-2         
##  [25] rvest_0.3.2               pan_1.6                  
##  [27] haven_1.1.2               xfun_0.3                 
##  [29] callr_3.1.0               crayon_1.3.4             
##  [31] jsonlite_1.5              lme4_1.1-17              
##  [33] bindr_0.1.1               survival_2.42-3          
##  [35] zoo_1.8-2                 glue_1.3.1.9000          
##  [37] gtable_0.3.0              pkgbuild_1.0.2           
##  [39] weights_1.0               rstan_2.18.2             
##  [41] jomo_2.6-2                abind_1.4-5              
##  [43] scales_1.0.0              miniUI_0.1.1.1           
##  [45] xtable_1.8-2              htmlTable_1.12           
##  [47] ggstance_0.3              foreign_0.8-70           
##  [49] Formula_1.2-3             stats4_3.5.1             
##  [51] StanHeaders_2.18.0-1      DT_0.4                   
##  [53] htmlwidgets_1.2           httr_1.3.1               
##  [55] threejs_0.3.1             arrayhelpers_1.0-20160527
##  [57] RColorBrewer_1.1-2        acepack_1.4.1            
##  [59] mice_3.1.0                pkgconfig_2.0.2          
##  [61] loo_2.1.0                 nnet_7.3-12              
##  [63] utf8_1.1.4                tidyselect_0.2.5         
##  [65] labeling_0.3              rlang_0.3.4              
##  [67] reshape2_1.4.3            later_0.7.3              
##  [69] munsell_0.5.0             cellranger_1.1.0         
##  [71] tools_3.5.1               cli_1.0.1                
##  [73] generics_0.0.2            broom_0.5.1              
##  [75] ggridges_0.5.0            evaluate_0.10.1          
##  [77] yaml_2.1.19               processx_3.2.1           
##  [79] knitr_1.20                mitml_0.3-6              
##  [81] nlme_3.1-137              mime_0.5                 
##  [83] xml2_1.2.0                compiler_3.5.1           
##  [85] bayesplot_1.7.0           shinythemes_1.1.1        
##  [87] rstudioapi_0.7            stringi_1.4.3            
##  [89] ps_1.2.1                  blogdown_0.8             
##  [91] Brobdingnag_1.2-6         lattice_0.20-35          
##  [93] Matrix_1.2-14             nloptr_1.0.4             
##  [95] markdown_0.8              shinyjs_1.0              
##  [97] pillar_1.3.1              bridgesampling_0.6-0     
##  [99] data.table_1.11.4         httpuv_1.4.4.2           
## [101] R6_2.3.0                  latticeExtra_0.6-28      
## [103] bookdown_0.9              promises_1.0.1           
## [105] gridExtra_2.3             codetools_0.2-15         
## [107] colourpicker_1.0          MASS_7.3-50              
## [109] gtools_3.8.1              assertthat_0.2.0         
## [111] rprojroot_1.3-2           withr_2.1.2              
## [113] shinystan_2.5.0           parallel_3.5.1           
## [115] hms_0.4.2                 grid_3.5.1               
## [117] rpart_4.1-13              coda_0.19-2              
## [119] minqa_1.2.4               rmarkdown_1.10           
## [121] shiny_1.1.0               lubridate_1.7.4          
## [123] base64enc_0.1-3           dygraphs_1.1.1.5&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>&#34;How to Survive a Plague&#34;: Part 1/$n$ of a premature book report</title>
      <link>/post/how-to-survive-a-plague-part-1-n-of-a-premature-book-report/</link>
      <pubDate>Sat, 02 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/how-to-survive-a-plague-part-1-n-of-a-premature-book-report/</guid>
      <description>&lt;p&gt;I’ve been reading &lt;a href=&#34;https://twitter.com/bydavidfrance?lang=en&#34;&gt;David France&lt;/a&gt;’s &lt;a href=&#34;https://surviveaplague.com&#34;&gt;&lt;em&gt;How to Survive a Plague: The Inside Story of How Citizens and Science Tamed AIDS&lt;/em&gt;&lt;/a&gt;. It’s a masterwork. And it’s devastating. Two months in and I haven’t cracked 100 pages. &lt;em&gt;HSP&lt;/em&gt; is the kind of book I can only take 10—20 pages at a time. But like anything soulful and hard and true, it’s worth it.&lt;/p&gt;
&lt;p&gt;For example, what do you know about the first baby on record to have died of AIDS?&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In San Francisco [November 1982], Dr. Arthur Ammann was feeling frustrated as he studied the results of a bone marrow test he had ordered on a very sick toddler. As an expert in pediatric immunology who traveled regularly throughout Africa, Ammann thought he’d either seen or read about every immune disorder that cold plague a child… But this little boy baffled him. He was born prematurely on March 3, 1981, with pronounced &lt;a href=&#34;https://www.mayoclinic.org/diseases-conditions/infant-jaundice/symptoms-causes/syc-20373865&#34;&gt;jaundice&lt;/a&gt;, a problem caused by toxins accumulating in the blood. This was not extraordinary, and the standard course of treatment was followed: every ounce of his contaminated blood was replaced with donated supplies. The process was repeated five times over a four-day period, followed by additional infusions of blood products like packed red blood cells and platelets. (p. 71)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Just that alone—fuck.&lt;/p&gt;
&lt;p&gt;After the initial bout of treatment, it looked like he was getting better. Dr. Ammann sent him home with his parents.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;But at four months of age his health began to dive. He suffered an &lt;a href=&#34;https://emedicine.medscape.com/article/958739-overvie&#34;&gt;enlarged spleen&lt;/a&gt; and &lt;a href=&#34;https://www.stlouischildrens.org/conditions-treatments/liver-disease&#34;&gt;liver&lt;/a&gt;. Jaundice returned, followed by &lt;a href=&#34;https://www.stanfordchildrens.org/en/topic/default?id=hepatitis-in-children-90-P02517&#34;&gt;hepatitis&lt;/a&gt; of no known origin, then &lt;a href=&#34;https://www.aafp.org/afp/2016/0215/p270.html&#34;&gt;anemia&lt;/a&gt; and diarrhea. Now the little boy was twenty months old and in intensive care. (p. 71)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;By mid-1982, gay men, Haitians, and intravenous drug users were known to be at risk for AIDS. But it wasn’t yet clear why.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Ammann suspected an infection in the child’s bone marrow, which would be highly unusual. Test results were even more surprising than he’d imagined. The child’s culture was positive for &lt;a href=&#34;https://rarediseases.info.nih.gov/diseases/7123/mycobacterium-avium-complex-infections&#34;&gt;&lt;em&gt;Mycobacterium avium-intracellulare&lt;/em&gt;&lt;/a&gt;, the dreaded cause of &lt;a href=&#34;http://www.aidsinfonet.org/fact_sheets/view/519pml.htm&#34;&gt;wasting syndrome&lt;/a&gt; in adults with AIDS. Recently there had been a number of reports of babies who seemed to inherit the disease at birth from their sick mothers, but that was not the case here. Ammann wrote in his case notes that both parents of his patient were “heterosexual non-Haitians and do not have a history of intravenous drug abuse.” He submitted both [parents] to extensive testing, and found no signs of immune deficiency.&lt;/p&gt;
&lt;p&gt;All he could think was: The blood supply is contaminated. (p. 71, &lt;em&gt;emphasis&lt;/em&gt; in the original)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As is turned out, gay men were particularly generous blood donors at that time.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Gay men, he learned, were extremely avid blood donors. In fact, in recent months an unnoticed and massive blood drive had been under way in LA’s gay neighborhoods in response to the mounting GRID [i.e., gay-related immune deficiency, as AIDS was known by in the early days] crisis, there. Week after week long lines of men rolled up their sleeves to donate blood, dutifully offering up pint after pint of harm they never dreamed of. (p. 59)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This was the precursor to a 30-year ban on gay men donating blood—which was &lt;a href=&#34;https://www.cnn.com/2015/12/21/health/fda-gay-men-blood-donation-changes/index.html&#34;&gt;overturned in 2015 based on advances in the relevant scientific literature&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;“Pulling the boy’s hospital records, he saw that blood donations from twenty-one separate people had been transfused into the child. Their identities were masked” (p. 71). After some efforts, Ammann and his team determined the relevant donor.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A man in his late forties… He had donated blood in early 1981. His health had remained unremarkable until that October, when he complained of fatigue, swollen lymph glands, and clouded vision in one eye—classic AIDS symptoms. Doctors diagnosed PCP [i.e., &lt;a href=&#34;https://www.webmd.com/hiv-aids/guide/aids-hiv-opportunistic-infections-pneumocystis-pcp-pneumonia#1&#34;&gt;&lt;em&gt;pneumocystis carinii&lt;/em&gt;&lt;/a&gt; pneumonia, an inflammation and fluid buildup in the lungs most of us conquer in early childhood] in December, and he was dead nine months later.&lt;/p&gt;
&lt;p&gt;This was the first irrefutable evidence of transmission through the blood supply. (p. 72)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Shortly after, Ammann and notified the medical community via the CDC’s widely-read &lt;a href=&#34;https://www.cdc.gov/mmwr/index.html&#34;&gt;&lt;em&gt;Morbidity and Mortality Weekly Report&lt;/em&gt;&lt;/a&gt; platform. His publication choice was crucial. Had he tried to get published at a more prestigious outlet, such as the &lt;em&gt;New England Journal of Medicine&lt;/em&gt;, the peer-review process could have held up the message for months or more. Ammann needed to get the message out to practitioners as soon as possible. The publication lag for the &lt;em&gt;MMWR&lt;/em&gt; was trivial. &lt;a href=&#34;https://www.cdc.gov/mmwr/preview/mmwrhtml/00001203.htm&#34;&gt;Here’s the report&lt;/a&gt;. In an editorial note at the end of the report, we read&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Of the 788 definite AIDS cases among adults reported thus far to CDC, 42 (5.3%) belong to no known risk group (i.e., they are not known to be homosexually active men, intravenous drug abusers, Haitians, or hemophiliacs). Two cases received blood products within 2 years of the onset of their illnesses and are currently under investigation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Seven hundred and seventy-eight.&lt;/p&gt;
&lt;p&gt;According to the World Health Organization, about &lt;a href=&#34;https://www.who.int/gho/hiv/en/&#34;&gt;37 million people were living with AIDS in 2017&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Shortly after Ammann’s piece was published,&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;a scrum of journalists burst through the CDC’s door for the first time, including correspondents from countless television networks and affiliates. The attention was long overdue. But with images of bouncing toddlers, the reporters warned America that the gay disease was now killing children. It unleashed a &lt;a href=&#34;https://www.nytimes.com/1986/11/23/us/violence-against-homosexuals-rising-groups-seeking-wider-protection-say.html&#34;&gt;torrent of anti-gay violence&lt;/a&gt; the likes of which the community had never seen before. (p. 73)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;If you find this topic sad and compelling and worth the heartbreak, there’s more to come.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Robust Linear Regression with Student’s $t$-Distribution</title>
      <link>/post/robust-linear-regression-with-the-robust-student-s-t-distribution/</link>
      <pubDate>Sat, 02 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/robust-linear-regression-with-the-robust-student-s-t-distribution/</guid>
      <description>&lt;p&gt;[edited Feb 3, 2019]&lt;/p&gt;
&lt;p&gt;The purpose of this post is to demonstrate the advantages of the Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution for regression with outliers, particularly within a &lt;a href=&#34;https://www.youtube.com/channel/UCNJK6_DZvcMqNSzQdEkzvzA/playlists&#34;&gt;Bayesian framework&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;i-make-assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;I make assumptions&lt;/h2&gt;
&lt;p&gt;I’m presuming you are familiar with linear regression, familiar with the basic differences between frequentist and Bayesian approaches to fitting regression models, and have a sense that the issue of outlier values is a pickle worth contending with. All code in is &lt;a href=&#34;https://www.r-bloggers.com/why-use-r-five-reasons/&#34;&gt;R&lt;/a&gt;, with a heavy use of the &lt;a href=&#34;http://style.tidyverse.org&#34;&gt;tidyverse&lt;/a&gt;–which you might learn a lot about &lt;a href=&#34;http://r4ds.had.co.nzhttp://r4ds.had.co.nz&#34;&gt;here, especially chapter 5&lt;/a&gt;– and &lt;a href=&#34;https://twitter.com/paulbuerkner&#34;&gt;Paul Bürkner&lt;/a&gt;’s &lt;a href=&#34;https://github.com/paul-buerkner/brms&#34;&gt;brms&lt;/a&gt; package.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-problem&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The problem&lt;/h2&gt;
&lt;p&gt;Simple regression models typically use the Gaussian likelihood. Say you have some criterion variable &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;, which you can reasonably describe with a mean &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and standard deviation &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;. Further, you’d like to describe &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; with a predictor &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. Using the Gaussian likelihood, we can describe the model as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{eqnarray}
y_i &amp;amp; \sim &amp;amp; \text{Normal}(\mu_i, \sigma) \\
\mu_i &amp;amp; = &amp;amp; \beta_0 + \beta_1 x_i
\end{eqnarray}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;With this formulation, we use &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; to model the mean of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. The &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; parameter is the intercept of the regression model and &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; is its slope with respect to &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. After accounting for &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;’s relation with &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;, the leftover variability in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; is described by &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;, often called error or residual variance. The reason we describe the model in terms of &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; is because those are the two parameters by which we define the Normal distribution, the Gaussian likelihood.&lt;/p&gt;
&lt;p&gt;The Gaussian is a sensible default choice for many data types. You might say it works unreasonably well. Unfortunately, the normal (i.e., Gaussian) distribution is sensitive to outliers.&lt;/p&gt;
&lt;p&gt;The normal distribution is a special case of Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution with the &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; parameter (i.e., the degree of freedom) set to infinity. However, when &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; is small, Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution is more robust to multivariate outliers. See &lt;a href=&#34;http://www.stat.columbia.edu/~gelman/arm/&#34;&gt;Gelman &amp;amp; Hill (2007, chapter 6)&lt;/a&gt; or &lt;a href=&#34;https://sites.google.com/site/doingbayesiandataanalysis/&#34;&gt;Kruschke (2014, chapter 16)&lt;/a&gt; for textbook treatments on the topic.&lt;/p&gt;
&lt;p&gt;In this post, we demonstrate how vulnerable the Gaussian likelihood is to outliers and then compare it to different ways of using Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-likelihood for the same data.&lt;/p&gt;
&lt;p&gt;First, we’ll get a sense of the distributions with a plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)

tibble(x = seq(from = -6, to = 6, by = .01)) %&amp;gt;% 
  expand(x, nu = c(1, 2.5, 5, 10, Inf)) %&amp;gt;% 
  mutate(density = dt(x = x, df = nu),
         nu      = factor(nu, levels = c(&amp;quot;Inf&amp;quot;, &amp;quot;10&amp;quot;, &amp;quot;5&amp;quot;, &amp;quot;2.5&amp;quot;, &amp;quot;1&amp;quot;))) %&amp;gt;% 
  
  ggplot(aes(x = x, y = density, group = nu, color = nu)) +
  geom_line() +
  scale_color_viridis_d(expression(nu),
                        direction = 1, option = &amp;quot;C&amp;quot;, end = .85) +
  scale_y_continuous(NULL, breaks = NULL) +
  coord_cartesian(xlim = -5:5) +
  xlab(NULL) +
  theme(panel.grid = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-02-robust-linear-regression-with-the-robust-student-s-t-distribution_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;528&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So the difference is that a Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution with a low &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; will have notably heavier tails than the conventional Gaussian distribution. It’s easiest to see the difference when &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; approaches 1. Even then, the difference can be subtle when looking at a plot. Another way is to compare how probable relatively extreme values are in a Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution relative to the Gaussian. For the sake of demonstration, here we’ll compare Gauss with Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; with a &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; of 5. In the plot above, they are clearly different, but not shockingly so. However, that difference is very notable in the tails.&lt;/p&gt;
&lt;p&gt;Let’s look more closely with a table. Below, we compare the probability of a given z-score or lower within the Gaussian and a &lt;span class=&#34;math inline&#34;&gt;\(\nu = 5\)&lt;/span&gt; Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;. In the rightmost column, we compare the probabilities in a ratio.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Here we pic our nu
nu &amp;lt;- 5

tibble(z_score               = 0:-5,
       p_Gauss               = pnorm(z_score, mean = 0, sd = 1),
       p_Student_t           = pt(z_score, df = nu),
       `Student/Gauss ratio` = p_Student_t/p_Gauss) %&amp;gt;%
  mutate_if(is.double, round, digits = 5) %&amp;gt;% 
  knitr::kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;z_score&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p_Gauss&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p_Student_t&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Student/Gauss ratio&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.50000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.50000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.00000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;-1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.15866&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.18161&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.14468&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;-2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.02275&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.05097&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.24042&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;-3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00135&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.01505&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11.14871&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;-4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00003&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00516&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;162.97775&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;-5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00205&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7159.76534&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Note how low z-scores are more probable in this Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; than in the Gaussian. This is most apparent in the &lt;code&gt;Student/Gauss ratio&lt;/code&gt; column on the right. A consequence of this is that extreme scores are less influential to your solutions when you use a small-&lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution in place of the Gaussian. That is, the small-&lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; is more robust than the Gaussian to unusual and otherwise influential observations.&lt;/p&gt;
&lt;p&gt;In order to demonstrate, let’s simulate our own. We’ll start by creating multivariate normal data.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lets-create-our-initial-tibble-of-well-behaved-data-d&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Let’s create our initial &lt;a href=&#34;https://cran.r-project.org/web/packages/tibble/vignettes/tibble.html&#34;&gt;tibble&lt;/a&gt; of well-behaved data, &lt;code&gt;d&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;First, we’ll need to define our variance/covariance matrix.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s &amp;lt;- matrix(c(1, .6, 
              .6, 1), 
             nrow = 2, ncol = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By the two &lt;code&gt;.6&lt;/code&gt;s on the off-diagonal positions, we indicated we’d like our two variables to have a correlation of .6.&lt;/p&gt;
&lt;p&gt;Second, our variables also need means, which we’ll define with a mean vector.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m &amp;lt;- c(0, 0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With means of &lt;code&gt;0&lt;/code&gt; and variances of &lt;code&gt;1&lt;/code&gt;, our data are in a standardized metric.&lt;/p&gt;
&lt;p&gt;Third, we’ll use the &lt;code&gt;mvrnorm()&lt;/code&gt; function from the &lt;a href=&#34;https://cran.r-project.org/web/packages/MASS/index.html&#34;&gt;MASS package&lt;/a&gt; to simulate our data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(3)

d &amp;lt;- MASS::mvrnorm(n = 100, mu = m, Sigma = s) %&amp;gt;%
  as_tibble() %&amp;gt;%
  rename(y = V1, x = V2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first few rows look like so:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(d)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 2
##         y      x
##     &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 -1.14   -0.584
## 2 -0.0805 -0.443
## 3 -0.239   0.702
## 4 -1.30   -0.761
## 5 -0.280   0.630
## 6 -0.245   0.299&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As an aside, check out &lt;a href=&#34;https://www.r-bloggers.com/creating-sample-datasets-exercises/&#34;&gt;this nice r-bloggers post&lt;/a&gt; for more information on simulating data with this method.&lt;/p&gt;
&lt;p&gt;Anyway, this line reorders our data by &lt;code&gt;x&lt;/code&gt;, placing the smallest values on top.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;d &amp;lt;-
  d %&amp;gt;%
  arrange(x)

head(d)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 2
##        y     x
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 -2.21  -1.84
## 2 -1.27  -1.71
## 3 -0.168 -1.60
## 4 -0.292 -1.46
## 5 -0.785 -1.40
## 6 -0.157 -1.37&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;lets-create-our-outlier-tibble-o&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Let’s create our outlier tibble, &lt;code&gt;o&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;Here we’ll make two outlying and unduly influential values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;o &amp;lt;- d
o[c(1:2), 1] &amp;lt;- c(5, 4)

head(o)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 2
##        y     x
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1  5     -1.84
## 2  4     -1.71
## 3 -0.168 -1.60
## 4 -0.292 -1.46
## 5 -0.785 -1.40
## 6 -0.157 -1.37&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With the code, above, we replaced the first two values of our first variable, &lt;code&gt;y&lt;/code&gt;. They both started out quite negative. Now they are positive values of a large magnitude within the standardized metric.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;frequentist-ols-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Frequentist &lt;a href=&#34;https://en.wikipedia.org/wiki/Ordinary_least_squares&#34;&gt;OLS&lt;/a&gt; models&lt;/h2&gt;
&lt;p&gt;To get a quick sense of what we’ve done, we’ll first fit two models with OLS regression via the &lt;code&gt;lm()&lt;/code&gt; function. The first model, &lt;code&gt;ols0&lt;/code&gt;, is of the multivariate normal data, &lt;code&gt;d&lt;/code&gt;. The second model, &lt;code&gt;ols1&lt;/code&gt;, is on the otherwise identical data with the two odd and influential values, &lt;code&gt;o&lt;/code&gt;. Here is our model code.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ols0 &amp;lt;- lm(data = d, y ~ 1 + x)
ols1 &amp;lt;- lm(data = o, y ~ 1 + x)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’ll use the &lt;a href=&#34;https://cran.r-project.org/web/packages/broom/index.html&#34;&gt;broom package&lt;/a&gt; to assist with model summaries and other things.&lt;/p&gt;
&lt;p&gt;Here are the parameter estimates for the first model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(broom)

tidy(ols0) %&amp;gt;% mutate_if(is.double, round, digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 5
##   term        estimate std.error statistic p.value
##   &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
## 1 (Intercept)    -0.01      0.09     -0.08    0.94
## 2 x               0.45      0.1       4.55    0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And now the parameters for the second model, the one based on the &lt;code&gt;o&lt;/code&gt; outlier data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tidy(ols1) %&amp;gt;% mutate_if(is.double, round, digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 5
##   term        estimate std.error statistic p.value
##   &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
## 1 (Intercept)     0.12      0.11      1.12    0.26
## 2 x               0.15      0.13      1.21    0.23&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Just two odd and influential values dramatically changed the model parameters, particularly the slope. Let’s plot the data and the models to get a visual sense of what happened.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# The well-behaived data
p1 &amp;lt;-
  ggplot(data = d, aes(x = x, y = y)) +
  stat_smooth(method = &amp;quot;lm&amp;quot;, color = &amp;quot;grey92&amp;quot;, fill = &amp;quot;grey67&amp;quot;, alpha = 1, fullrange = T) +
  geom_point(size = 1, alpha = 3/4) +
  scale_x_continuous(limits = c(-4, 4)) +
  coord_cartesian(xlim = -3:3, 
                  ylim = -3:5) +
  labs(title = &amp;quot;No Outliers&amp;quot;) +
  theme(panel.grid = element_blank())

# The data with two outliers
p2 &amp;lt;-
  ggplot(data = o, aes(x = x, y = y, color = y &amp;gt; 3)) +
  stat_smooth(method = &amp;quot;lm&amp;quot;, color = &amp;quot;grey92&amp;quot;, fill = &amp;quot;grey67&amp;quot;, alpha = 1, fullrange = T) +
  geom_point(size = 1, alpha = 3/4) +
  scale_color_viridis_d(option = &amp;quot;A&amp;quot;, end = 4/7) +
  scale_x_continuous(limits = c(-4, 4)) +
  coord_cartesian(xlim = -3:3, 
                  ylim = -3:5) +
  labs(title = &amp;quot;Two Outliers&amp;quot;) +
  theme(panel.grid = element_blank(),
        legend.position = &amp;quot;none&amp;quot;)

library(gridExtra)

grid.arrange(p1, p2, ncol = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-02-robust-linear-regression-with-the-robust-student-s-t-distribution_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;648&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The two outliers were quite influential on the slope. It went from a nice clear diagonal to almost horizontal. You’ll also note how the 95% intervals (i.e., the bowtie shapes) were a bit wider when based on the &lt;code&gt;o&lt;/code&gt; data.&lt;/p&gt;
&lt;p&gt;One of the popular ways to quantify outlier status is with Mahalanobis’ distance. However, the Mahalanobis distance is primarilly valid for multivariate normal data. Though the data in this example are indeed multivariate normal–or at least they were before we injected two outlying values into them–I am going to resist relying on Mahalanobis’ distance. There are other more general approaches that will be of greater use when you need to explore other variants of the generalized linear model. The &lt;code&gt;broom::augment()&lt;/code&gt; function will give us access to one.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;aug0 &amp;lt;- augment(ols0)
aug1 &amp;lt;- augment(ols1)

glimpse(aug1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 100
## Variables: 9
## $ y          &amp;lt;dbl&amp;gt; 5.00000000, 4.00000000, -0.16783167, -0.29164105, -0.…
## $ x          &amp;lt;dbl&amp;gt; -1.8439208, -1.7071418, -1.5996509, -1.4601550, -1.39…
## $ .fitted    &amp;lt;dbl&amp;gt; -0.155937416, -0.135213012, -0.118926273, -0.09779020…
## $ .se.fit    &amp;lt;dbl&amp;gt; 0.2581834, 0.2427649, 0.2308204, 0.2155907, 0.2086463…
## $ .resid     &amp;lt;dbl&amp;gt; 5.15593742, 4.13521301, -0.04890540, -0.19385084, -0.…
## $ .hat       &amp;lt;dbl&amp;gt; 0.05521164, 0.04881414, 0.04412882, 0.03849763, 0.036…
## $ .sigma     &amp;lt;dbl&amp;gt; 0.964211, 1.017075, 1.104423, 1.104253, 1.102081, 1.1…
## $ .cooksd    &amp;lt;dbl&amp;gt; 6.809587e-01, 3.820802e-01, 4.783890e-05, 6.480561e-0…
## $ .std.resid &amp;lt;dbl&amp;gt; 4.82755612, 3.85879897, -0.04552439, -0.17992001, -0.…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here we can compare the observations with Cook’s distance, &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt; (i.e., &lt;code&gt;.cooksd&lt;/code&gt;). Cook’s &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt; is a measure of the influence of a given observation on the model. To compute &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt;, the model is fit once for each &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; case, after first dropping that case. Then the difference in the model with all observations and the model with all observations but the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;th observation, as defined by the Euclidian distance between the estimators. &lt;a href=&#34;http://www.springer.com/us/book/9783642343322#aboutBook&#34;&gt;Fahrmeir et al (2013, p. 166)&lt;/a&gt; suggest that within the OLS framework “as a rule of thumb, observations with &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt; &amp;gt; 0.5 are worthy of attention, and observations with &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt; &amp;gt; 1 should always be examined.” Here we plot &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt; against our observation index, &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;, for both models.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;aug0 %&amp;gt;%  # The well-behaived data
  mutate(i = 1:n()) %&amp;gt;%
  bind_rows(  # The data with two outliers
    aug1 %&amp;gt;%
      mutate(i = 1:n())
    ) %&amp;gt;%
  mutate(fit = rep(c(&amp;quot;fit b0&amp;quot;, &amp;quot;fit b1&amp;quot;), each = n()/2)) %&amp;gt;%
  ggplot(aes(x = i, y = .cooksd)) +
  geom_hline(yintercept = .5, color = &amp;quot;white&amp;quot;) +
  geom_point(alpha = .5) +
  geom_text(data = tibble(i = 46, 
                          .cooksd = .53,
                          fit = &amp;quot;fit b0&amp;quot;),
            label = &amp;quot;Fahrmeir et al said we might worry around here&amp;quot;,
            color = &amp;quot;grey50&amp;quot;) +
  coord_cartesian(ylim = c(0, .7)) +
  theme(panel.grid = element_blank(),
        axis.title.x = element_text(face = &amp;quot;italic&amp;quot;, family = &amp;quot;Times&amp;quot;)) +
    facet_wrap(~fit)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-02-robust-linear-regression-with-the-robust-student-s-t-distribution_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For the model of the well-behaved data, &lt;code&gt;ols0&lt;/code&gt;, we have &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt; values all hovering near zero. However, the plot for &lt;code&gt;ols1&lt;/code&gt; shows one &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt; value well above the 0.5 level and another not quite that high but deviant relative to the rest. Our two outlier values look quite influential for the results of &lt;code&gt;ols1&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;switch-to-a-bayesian-framework&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Switch to a Bayesian framework&lt;/h2&gt;
&lt;p&gt;In this project, we’ll use the &lt;a href=&#34;https://cran.r-project.org/web/packages/brms/index.html&#34;&gt;brms package&lt;/a&gt; to fit our Bayesian regression models. You can learn a lot about brms &lt;a href=&#34;https://cran.r-project.org/web/packages/brms/vignettes/brms_overview.pdf&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://github.com/paul-buerkner/brms&#34;&gt;here&lt;/a&gt;. Bayesian models, of course, require us to use priors. To keep things simple, we’ll use &lt;a href=&#34;https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations&#34;&gt;weakly-regularizing priors&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(brms)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;stick-with-gauss.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Stick with Gauss.&lt;/h3&gt;
&lt;p&gt;For our first two Bayesian models, &lt;code&gt;b0&lt;/code&gt; and &lt;code&gt;b1&lt;/code&gt;, we’ll use the conventional Gaussian likelihood (i.e., &lt;code&gt;family = gaussian&lt;/code&gt; in the &lt;code&gt;brm()&lt;/code&gt; function). Like with &lt;code&gt;ols0&lt;/code&gt;, above, the first model is based on the nice &lt;code&gt;d&lt;/code&gt; data. The second, &lt;code&gt;b1&lt;/code&gt;, is based on the more-difficult &lt;code&gt;o&lt;/code&gt; data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b0 &amp;lt;- 
  brm(data = d, family = gaussian,
      y ~ 1 + x,
      prior = c(prior(normal(0, 10), class = Intercept),
                prior(normal(0, 10), class = b),
                prior(cauchy(0, 1),  class = sigma)),
      seed = 1)
b1 &amp;lt;- 
  update(b0, 
         newdata = o)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here are the model summaries.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tidy(b0) %&amp;gt;% slice(1:3) %&amp;gt;% mutate_if(is.double, round, digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          term estimate std.error lower upper
## 1 b_Intercept    -0.01      0.09 -0.15  0.13
## 2         b_x     0.44      0.10  0.29  0.61
## 3       sigma     0.87      0.07  0.77  0.98&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tidy(b1) %&amp;gt;% slice(1:3) %&amp;gt;% mutate_if(is.double, round, digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          term estimate std.error lower upper
## 1 b_Intercept     0.12      0.11 -0.05  0.30
## 2         b_x     0.15      0.13 -0.05  0.36
## 3       sigma     1.10      0.08  0.99  1.24&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These should look familiar. They’re very much like the results from the OLS models. Hopefully this isn’t surprising. Our priors were quite weak, so there’s no reason to suspect the results would differ much.&lt;/p&gt;
&lt;div id=&#34;the-loo-and-other-goodies-help-with-diagnostics.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;The LOO and other goodies help with diagnostics.&lt;/h4&gt;
&lt;p&gt;With the &lt;code&gt;loo()&lt;/code&gt; function, we’ll extract loo objects, which contain some handy output.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;loo_b0 &amp;lt;- loo(b0)
loo_b1 &amp;lt;- loo(b1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Found 1 observations with a pareto_k &amp;gt; 0.7 in model &amp;#39;b1&amp;#39;. It is
## recommended to set &amp;#39;reloo = TRUE&amp;#39; in order to calculate the ELPD without
## the assumption that these observations are negligible. This will refit
## the model 1 times to compute the ELPDs for the problematic observations
## directly.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’ll use &lt;code&gt;str()&lt;/code&gt; to get a sense of what’s all in there, using &lt;code&gt;loo_b1&lt;/code&gt; as an example.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(loo_b1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 11
##  $ estimates  : num [1:3, 1:2] -155.63 6.64 311.26 15.54 3.91 ...
##   ..- attr(*, &amp;quot;dimnames&amp;quot;)=List of 2
##   .. ..$ : chr [1:3] &amp;quot;elpd_loo&amp;quot; &amp;quot;p_loo&amp;quot; &amp;quot;looic&amp;quot;
##   .. ..$ : chr [1:2] &amp;quot;Estimate&amp;quot; &amp;quot;SE&amp;quot;
##  $ pointwise  : num [1:100, 1:4] -14.29 -9.09 -1.04 -1.05 -1.24 ...
##   ..- attr(*, &amp;quot;dimnames&amp;quot;)=List of 2
##   .. ..$ : NULL
##   .. ..$ : chr [1:4] &amp;quot;elpd_loo&amp;quot; &amp;quot;mcse_elpd_loo&amp;quot; &amp;quot;p_loo&amp;quot; &amp;quot;looic&amp;quot;
##  $ diagnostics:List of 2
##   ..$ pareto_k: num [1:100] 0.8286 0.5899 -0.0669 -0.1036 -0.1012 ...
##   ..$ n_eff   : num [1:100] 40.5 348 3976.3 3973.3 3927.6 ...
##  $ psis_object: NULL
##  $ elpd_loo   : num -156
##  $ p_loo      : num 6.64
##  $ looic      : num 311
##  $ se_elpd_loo: num 15.5
##  $ se_p_loo   : num 3.91
##  $ se_looic   : num 31.1
##  $ model_name : chr &amp;quot;b1&amp;quot;
##  - attr(*, &amp;quot;dims&amp;quot;)= int [1:2] 4000 100
##  - attr(*, &amp;quot;class&amp;quot;)= chr [1:3] &amp;quot;ic&amp;quot; &amp;quot;psis_loo&amp;quot; &amp;quot;loo&amp;quot;
##  - attr(*, &amp;quot;yhash&amp;quot;)= chr &amp;quot;5cdc17bb2cb41f3e3f0a617f418fff3fbb8e1ebf&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For a detailed explanation of all those elements, see the &lt;a href=&#34;https://cran.r-project.org/web/packages/loo/loo.pdf&#34;&gt;reference manual&lt;/a&gt;. For our purposes, we’ll focus on the &lt;code&gt;pareto_k&lt;/code&gt;. Here’s a glimpse of what it contains for the &lt;code&gt;b1&lt;/code&gt; model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;loo_b1$diagnostics$pareto_k %&amp;gt;% as_tibble()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Calling `as_tibble()` on a vector is discouraged, because the behavior is likely to change in the future. Use `enframe(name = NULL)` instead.
## This warning is displayed once per session.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 100 x 1
##      value
##      &amp;lt;dbl&amp;gt;
##  1  0.829 
##  2  0.590 
##  3 -0.0669
##  4 -0.104 
##  5 -0.101 
##  6 -0.0321
##  7  0.0498
##  8 -0.114 
##  9  0.179 
## 10 -0.0736
## # … with 90 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’ve got us a numeric vector of as many values as our data had observations–100 in this case. The &lt;code&gt;pareto_k&lt;/code&gt; values can be used to examine overly-influential cases. See, for example &lt;a href=&#34;https://stackoverflow.com/questions/39578834/linear-model-diagnostics-for-bayesian-models-using-rstan/39595436&#34;&gt;this discussion on stackoverflow.com&lt;/a&gt; in which several members of the &lt;a href=&#34;http://mc-stan.org&#34;&gt;Stan team&lt;/a&gt; weighed in. The issue is also discussed in &lt;a href=&#34;https://arxiv.org/abs/1507.04544&#34;&gt;this paper&lt;/a&gt;, in the &lt;a href=&#34;https://cran.r-project.org/web/packages/loo/loo.pdf&#34;&gt;loo reference manual&lt;/a&gt;, and in &lt;a href=&#34;https://www.youtube.com/watch?v=FUROJM3u5HQ&amp;amp;feature=youtu.be&amp;amp;a=&#34;&gt;this presentation by Aki Vehtari&lt;/a&gt;. If we explicitly open the &lt;a href=&#34;https://cran.r-project.org/web/packages/loo/index.html&#34;&gt;loo package&lt;/a&gt;, we can use a few convenience functions to leverage &lt;code&gt;pareto_k&lt;/code&gt; for diagnostic purposes. The &lt;code&gt;pareto_k_table()&lt;/code&gt; function will categorize the &lt;code&gt;pareto_k&lt;/code&gt; values and give us a sense of how many values are in problematic ranges.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(loo)

pareto_k_table(loo_b1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Pareto k diagnostic values:
##                          Count Pct.    Min. n_eff
## (-Inf, 0.5]   (good)     98    98.0%   3563      
##  (0.5, 0.7]   (ok)        1     1.0%   348       
##    (0.7, 1]   (bad)       1     1.0%   41        
##    (1, Inf)   (very bad)  0     0.0%   &amp;lt;NA&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Happily, most of our cases were in the “good” range. One pesky case was in the “bad” range [can you guess which one?] and another case was only “ok” [and can you guess that one, too?]. The &lt;code&gt;pareto_k_ids()&lt;/code&gt; function will tell exactly us which cases we’ll want to look at.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pareto_k_ids(loo_b1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1 2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Those numbers correspond to the row numbers in the data, &lt;code&gt;o&lt;/code&gt;. These are exactly the cases that plagued our second OLS model, &lt;code&gt;fit1&lt;/code&gt;, and are also the ones we hand coded to be outliers.&lt;/p&gt;
&lt;p&gt;With the simple &lt;code&gt;plot()&lt;/code&gt; function, we can get a diagnostic plot for the &lt;code&gt;pareto_k&lt;/code&gt; values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(loo_b1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-02-robust-linear-regression-with-the-robust-student-s-t-distribution_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There they are, cases 1 and 2, lurking in the “bad” and “[just] ok” ranges. We can also make a similar plot with ggplot2. Though it takes a little more work, ggplot2 makes it easy to compare &lt;code&gt;pareto_k&lt;/code&gt; plots across models with a little faceting.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;loo_b0$diagnostics$pareto_k %&amp;gt;%  # The well-behaived data
  as_tibble() %&amp;gt;%
  mutate(i = 1:n()) %&amp;gt;%
  bind_rows(  # The data with two outliers
    loo_b1$diagnostics$pareto_k %&amp;gt;% 
      as_tibble() %&amp;gt;%
      mutate(i = 1:n()) 
  ) %&amp;gt;%
  rename(pareto_k = value) %&amp;gt;%
  mutate(fit = rep(c(&amp;quot;fit b0&amp;quot;, &amp;quot;fit b1&amp;quot;), each = n()/2)) %&amp;gt;%
  ggplot(aes(x = i, y = pareto_k)) +
  geom_hline(yintercept = c(.5, .7, 1), color = &amp;quot;white&amp;quot;) +
  geom_point(alpha = .5) +
  geom_text(data = tibble(i = c(3, 6, 2), 
                          pareto_k = c(.45, .65, .95),
                          label = c(&amp;quot;good&amp;quot;, &amp;quot;[just] ok&amp;quot;, &amp;quot;bad&amp;quot;),
                          fit = &amp;quot;fit b0&amp;quot;),
            aes(label = label),
            color = &amp;quot;grey50&amp;quot;) +
  theme(panel.grid = element_blank(),
        axis.title.x = element_text(face = &amp;quot;italic&amp;quot;, family = &amp;quot;Times&amp;quot;)) +
  facet_wrap(~fit)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-02-robust-linear-regression-with-the-robust-student-s-t-distribution_files/figure-html/unnamed-chunk-22-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So with &lt;code&gt;b0&lt;/code&gt;–the model based on the well-behaved multivariate normal data, &lt;code&gt;d&lt;/code&gt;–, all the &lt;code&gt;pareto_k&lt;/code&gt; values hovered around zero in the “good” range. Things got concerning with model &lt;code&gt;b1&lt;/code&gt;. But we know all that. Let’s move forward.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-do-we-do-with-those-overly-influential-outlying-values&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;What do we do with those overly-influential outlying values?&lt;/h4&gt;
&lt;p&gt;A typical way to handle outlying values is to delete them based on some criterion, such as the Mahalanobis distance, Cook’s &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt;, or our new friend the &lt;code&gt;pareto_k&lt;/code&gt;. In our next two models, we’ll do that. In our &lt;code&gt;data&lt;/code&gt; arguments, we can use the &lt;code&gt;slice()&lt;/code&gt; function to omit cases. In model &lt;code&gt;b1.1&lt;/code&gt;, we simply omit the first and most influential case. In model &lt;code&gt;b1.2&lt;/code&gt;, we omitted both unduly-influential cases, the values from rows 1 and 2.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b1.1 &amp;lt;- 
  update(b1, 
         newdata = o %&amp;gt;% slice(2:100))
b1.2 &amp;lt;- 
  update(b1, 
         newdata = o %&amp;gt;% slice(3:100))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here are the summaries for our models based on the &lt;code&gt;slice[d]&lt;/code&gt; data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tidy(b1.1) %&amp;gt;% slice(1:3) %&amp;gt;% mutate_if(is.double, round, digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          term estimate std.error lower upper
## 1 b_Intercept     0.07      0.10 -0.09  0.23
## 2         b_x     0.28      0.12  0.09  0.47
## 3       sigma     0.97      0.07  0.87  1.09&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tidy(b1.2) %&amp;gt;% slice(1:3) %&amp;gt;% mutate_if(is.double, round, digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          term estimate std.error lower upper
## 1 b_Intercept     0.02      0.09 -0.12  0.16
## 2         b_x     0.40      0.10  0.23  0.56
## 3       sigma     0.86      0.06  0.76  0.97&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;They are closer to the true data generating model (i.e., the code we used to make &lt;code&gt;d&lt;/code&gt;), especially &lt;code&gt;b1.2&lt;/code&gt;. However, there are other ways to handle the influential cases without dropping them. Finally, we’re ready to switch to Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;time-to-leave-gauss-for-the-more-general-students-t&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Time to leave Gauss for the more general Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Recall that the normal distribution is equivalent to a Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; with the degrees of freedom parameter, &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt;, set to infinity. That is, &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; is fixed. Here we’ll relax that assumption and estimate &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; from the data just like we estimate &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; with the linear model and &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; as the residual spread. Since &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt;’s now a parameter, we’ll have to give it a prior. For our first Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; model, we’ll estimate &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; with the brms default gamma(2, 0.1) prior.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b2 &amp;lt;- 
  brm(data = o, family = student,
      y ~ 1 + x,
      prior = c(prior(normal(0, 10), class = Intercept),
                prior(normal(0, 10), class = b),
                prior(gamma(2, 0.1), class = nu),
                prior(cauchy(0, 1),  class = sigma)),
      seed = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the next model, we’ll switch out that weak gamma(2, 0.1) for a stronger gamma(4, 1). In some disciplines, the gamma distribution is something of an exotic bird. So before fitting the model, it might be useful to take a peek at what these gamma priors looks like. In the plot, below, the orange density in the background is the default gamma(2, 0.1) and the purple density in the foreground is the stronger gamma(4, 1).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# data
tibble(x = seq(from = 0, to = 60, by = .1)) %&amp;gt;% 
  expand(x, nesting(alpha = c(2, 4), 
                    beta  = c(0.1, 1))) %&amp;gt;% 
  mutate(density = dgamma(x, alpha, beta),
         group   = rep(letters[1:2], times = n() / 2)) %&amp;gt;% 
  
  # plot
  ggplot(aes(x = x, ymin = 0, ymax = density, 
             group = group, fill = group)) +
  geom_ribbon(size = 0, alpha = 3/4) +
  scale_fill_viridis_d(option = &amp;quot;B&amp;quot;, direction = -1, 
                       begin = 1/3, end = 2/3) +
  scale_y_continuous(NULL, breaks = NULL) +
  coord_cartesian(xlim = 0:50) +
  theme(panel.grid      = element_blank(),
        legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-02-robust-linear-regression-with-the-robust-student-s-t-distribution_files/figure-html/unnamed-chunk-24-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So the default prior is centered around values in the 2 to 30 range, but has a long gentle-sloping tail, allowing the model to yield much larger values for &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt;, as needed. The prior we use below is almost entirely concentrated in the single-digit range. In this case, that will preference Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; likelihoods with very small &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; parameters and correspondingly thick tails–easily allowing for extreme values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b3 &amp;lt;- 
  update(b2,
         prior = c(prior(normal(0, 10), class = Intercept),
                   prior(normal(0, 10), class = b),
                   prior(gamma(4, 1),   class = nu),
                   prior(cauchy(0, 1),  class = sigma)),
         seed = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For our final model, we’ll fix the &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; parameter in a &lt;code&gt;bf()&lt;/code&gt; statement.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b4 &amp;lt;-
  brm(data = o, family = student,
      bf(y ~ 1 + x, nu = 4),
      prior = c(prior(normal(0, 100), class = Intercept),
                prior(normal(0, 10),  class = b),
                prior(cauchy(0, 1),   class = sigma)),
         seed = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we’ve got all those models, we can gather their results into a sole tibble.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b_estimates &amp;lt;-
  tibble(model = c(&amp;quot;b0&amp;quot;, &amp;quot;b1&amp;quot;, &amp;quot;b1.1&amp;quot;, &amp;quot;b1.2&amp;quot;, &amp;quot;b2&amp;quot;, &amp;quot;b3&amp;quot;, &amp;quot;b4&amp;quot;)) %&amp;gt;% 
  mutate(fit   = map(model, get)) %&amp;gt;% 
  mutate(tidy  = map(fit, tidy)) %&amp;gt;% 
  unnest(tidy) %&amp;gt;% 
  filter(term %in% c(&amp;quot;b_Intercept&amp;quot;, &amp;quot;b_x&amp;quot;)) %&amp;gt;%
  arrange(term)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To get a sense of what we’ve done, let’s take a peek at our models tibble.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b_estimates %&amp;gt;%
  mutate_if(is.double, round, digits = 2)  # This is just to round the numbers&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 14 x 6
##    model term        estimate std.error  lower upper
##    &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 b0    b_Intercept    -0.01      0.09 -0.15   0.13
##  2 b1    b_Intercept     0.12      0.11 -0.05   0.3 
##  3 b1.1  b_Intercept     0.07      0.1  -0.09   0.23
##  4 b1.2  b_Intercept     0.02      0.09 -0.12   0.16
##  5 b2    b_Intercept     0.04      0.09 -0.11   0.2 
##  6 b3    b_Intercept     0.04      0.09 -0.11   0.19
##  7 b4    b_Intercept     0.04      0.09 -0.11   0.19
##  8 b0    b_x             0.44      0.1   0.290  0.61
##  9 b1    b_x             0.15      0.13 -0.05   0.36
## 10 b1.1  b_x             0.28      0.12  0.09   0.47
## 11 b1.2  b_x             0.4       0.1   0.23   0.56
## 12 b2    b_x             0.35      0.11  0.17   0.53
## 13 b3    b_x             0.36      0.1   0.19   0.53
## 14 b4    b_x             0.37      0.1   0.2    0.54&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The models differ by their intercepts, slopes, sigmas, and &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt;s. For the sake of this post, we’ll focus on the slopes. Here we compare the different Bayesian models’ slopes by their posterior means and 95% intervals in a coefficient plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b_estimates %&amp;gt;%
  filter(term == &amp;quot;b_x&amp;quot;) %&amp;gt;% # b_Intercept b_x
  
  ggplot(aes(x = model)) +
  geom_pointrange(aes(y    = estimate,
                      ymin = lower,
                      ymax = upper),
                  shape = 20) +
  coord_flip(ylim = c(-.2, 1)) +
  labs(title    = &amp;quot;The x slope, varying by model&amp;quot;,
       subtitle = &amp;quot;The dots are the posterior means and the lines the percentile-based 95% intervals.&amp;quot;,
       x        = NULL,
       y        = NULL) +
  theme(panel.grid   = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y  = element_text(hjust = 0))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-02-robust-linear-regression-with-the-robust-student-s-t-distribution_files/figure-html/unnamed-chunk-27-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;You might think of the &lt;code&gt;b0&lt;/code&gt; slope as the “true” slope. That’s the one estimated from the well-behaved multivariate normal data, &lt;code&gt;d&lt;/code&gt;. That estimate’s just where we’d want it to be. The &lt;code&gt;b1&lt;/code&gt; slope is a disaster–way lower than the others. The slopes for &lt;code&gt;b1.1&lt;/code&gt; and &lt;code&gt;b1.2&lt;/code&gt; get better, but at the expense of deleting data. All three of our Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; models produced slopes that were pretty close to the &lt;code&gt;b0&lt;/code&gt; slope. They weren’t perfect, but, all in all, Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution did pretty okay.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;we-need-more-loo-and-more-pareto_k.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;We need more LOO and more &lt;code&gt;pareto_k&lt;/code&gt;.&lt;/h3&gt;
&lt;p&gt;We already have loo objects for our first two models, &lt;code&gt;b0&lt;/code&gt; and &lt;code&gt;b1&lt;/code&gt;. Let’s get some for models &lt;code&gt;b2&lt;/code&gt; through &lt;code&gt;b4&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;loo_b2 &amp;lt;- loo(b2)
loo_b3 &amp;lt;- loo(b3)
loo_b4 &amp;lt;- loo(b4)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With a little data wrangling, we can compare our models by how they look in our custom &lt;code&gt;pareto_k&lt;/code&gt; diagnostic plots.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# make a custom function to work with the loo objects in bulk
get_pareto_k &amp;lt;- function(l) {
  l$diagnostics$pareto_k %&amp;gt;% 
    as_tibble() %&amp;gt;%
    mutate(i = 1:n()) %&amp;gt;% 
    rename(pareto_k = value)
}

# wrangle
tibble(name = str_c(&amp;quot;loo_b&amp;quot;, 1:4)) %&amp;gt;% 
  mutate(loo_object = map(name, get)) %&amp;gt;% 
  mutate(pareto_k = map(loo_object, get_pareto_k)) %&amp;gt;% 
  unnest(pareto_k) %&amp;gt;% 
  mutate(fit = rep(c(&amp;quot;fit b1&amp;quot;, &amp;quot;fit b2&amp;quot;, &amp;quot;fit b3&amp;quot;, &amp;quot;fit b4&amp;quot;), each = n() / 4)) %&amp;gt;%
  
  # plot
  ggplot(aes(x = i, y = pareto_k)) +
  geom_hline(yintercept = c(.5, .7),
             color = &amp;quot;white&amp;quot;) +
  geom_point(alpha = .5) +
  scale_y_continuous(breaks = c(0, .5, .7)) +
  theme(panel.grid   = element_blank(),
        axis.title.x = element_text(face = &amp;quot;italic&amp;quot;, family = &amp;quot;Times&amp;quot;)) +
    facet_wrap(~fit)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-02-robust-linear-regression-with-the-robust-student-s-t-distribution_files/figure-html/unnamed-chunk-28-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Oh man, those Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; models worked sweet! In a succession from &lt;code&gt;b2&lt;/code&gt; through &lt;code&gt;b4&lt;/code&gt;, each model looked better by &lt;code&gt;pareto_k&lt;/code&gt;. All were way better than the typical Gaussian model, &lt;code&gt;b1&lt;/code&gt;. While we’re at it, we might compare those by their LOO values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;compare_ic(loo_b1, loo_b2, loo_b3, loo_b4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          LOOIC    SE
## b1      311.26 31.09
## b2      289.97 23.07
## b3      287.64 20.83
## b4      285.95 20.19
## b1 - b2  21.29 11.68
## b1 - b3  23.62 14.58
## b1 - b4  25.31 15.46
## b2 - b3   2.33  3.03
## b2 - b4   4.02  3.95
## b3 - b4   1.69  0.92&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In terms of the LOO, &lt;code&gt;b2&lt;/code&gt; through &lt;code&gt;b4&lt;/code&gt; were about the same, but all looked better than &lt;code&gt;b1&lt;/code&gt;. In fairness, though, the standard errors for the difference scores were a bit on the wide side. If you’re new to using information criteria to compare models, you might sit down and soak in &lt;a href=&#34;https://www.youtube.com/watch?v=t0pRuy1_190&amp;amp;list=PLDcUM9US4XdM9_N6XUUFrhghGJ4K25bFc&amp;amp;index=8&#34;&gt;this lecture on the topic&lt;/a&gt; and &lt;a href=&#34;https://cran.r-project.org/web/packages/loo/vignettes/loo-example.html&#34;&gt;this vignette&lt;/a&gt; on the LOO in particular. For a more technical introduction, you might check out the references in the loo package’s &lt;a href=&#34;https://cran.r-project.org/web/packages/loo/loo.pdf&#34;&gt;reference manual&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For one final LOO-related comparison, we can use the &lt;code&gt;brms::model_weights()&lt;/code&gt; function to see how much relative weight we might put on each of those four models if we were to use a model averaging approach. Here we use the default method, which is model averaging via posterior predictive stacking.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_weights(b1, b2, b3, b4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           b1           b2           b3           b4 
## 6.956356e-07 4.480928e-09 4.036950e-06 9.999953e-01&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you’re not a fan of scientific notation, just tack on &lt;code&gt;round(digits = 2)&lt;/code&gt;. The stacking method suggests that we should place virtually all the weight on &lt;code&gt;b4&lt;/code&gt;, the model in which we fixed our Student-&lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; parameter at 4. To learn more about model stacking, check out Yao, Vehtari, Simpson, and Gelman’s (2018) paper, &lt;a href=&#34;https://projecteuclid.org/euclid.ba/1516093227&#34;&gt;&lt;em&gt;Using stacking to average Bayesian predictive distributions&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lets-compare-a-few-bayesian-models.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Let’s compare a few Bayesian models.&lt;/h3&gt;
&lt;p&gt;That’s enough with coefficients, &lt;code&gt;pareto_k&lt;/code&gt;, and the LOO. Let’s get a sense of the implications of the models by comparing a few in plots. Here we use convenience functions from &lt;a href=&#34;https://twitter.com/mjskay&#34;&gt;Matthew Kay&lt;/a&gt;’s &lt;a href=&#34;https://github.com/mjskay/tidybayes&#34;&gt;tidybayes&lt;/a&gt; package to streamline the data wrangling and plotting. [The method came from a &lt;a href=&#34;https://twitter.com/mjskay/status/1091926564101599232&#34;&gt;kind twitter suggesion from Kay&lt;/a&gt;.]&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidybayes)

# These are the values of x we&amp;#39;d like model-implied summaries for
nd &amp;lt;- tibble(x = seq(from = -4, to = 4, length.out = 50))

# here&amp;#39;s another way to arrange the models
list(b0 = b0, b1 = b1, b3 = b3) %&amp;gt;% 
  # with help from 1tidybayes::add_fitted_draws()`, here we use `fitted()` in bulk
  map_dfr(add_fitted_draws, newdata = nd, .id = &amp;quot;model&amp;quot;) %&amp;gt;% 
  
  # plot
  ggplot(aes(x = x)) +
  stat_lineribbon(aes(y = .value),
                  .width = .95,
                  color = &amp;quot;grey92&amp;quot;, fill = &amp;quot;grey67&amp;quot;) +
  geom_point(data = d %&amp;gt;%
               bind_rows(o, o) %&amp;gt;%
               mutate(model = rep(c(&amp;quot;b0&amp;quot;, &amp;quot;b1&amp;quot;, &amp;quot;b3&amp;quot;), each = 100)), 
             aes(y = y, color = y &amp;gt; 3),
             size = 1, alpha = 3/4) +
  scale_color_viridis_d(option = &amp;quot;A&amp;quot;, end = 4/7) +
  coord_cartesian(xlim = -3:3, 
                  ylim = -3:5) +
  ylab(NULL) +
  theme(panel.grid      = element_blank(),
        legend.position = &amp;quot;none&amp;quot;) +
  facet_wrap(~model)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-02-robust-linear-regression-with-the-robust-student-s-t-distribution_files/figure-html/unnamed-chunk-31-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For each subplot, the gray band is the 95% interval band and the overlapping light gray line is the posterior mean. Model &lt;code&gt;b0&lt;/code&gt;, recall, is our baseline comparison model. This is of the well-behaved no-outlier data, &lt;code&gt;d&lt;/code&gt;, using the good old Gaussian likelihood. Model &lt;code&gt;b1&lt;/code&gt; is of the outlier data, &lt;code&gt;o&lt;/code&gt;, but still using the non-robust Gaussian likelihood. Model &lt;code&gt;b3&lt;/code&gt; uses a robust Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; likelihood with &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; estimated with the fairly narrow gamma(4, 1) prior. For my money, &lt;code&gt;b3&lt;/code&gt; did a pretty good job.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 3.5.1 (2018-07-02)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS High Sierra 10.13.6
## 
## Matrix products: default
## BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] tidybayes_1.0.3 loo_2.0.0       brms_2.7.0      Rcpp_1.0.0     
##  [5] gridExtra_2.3   broom_0.5.1     bindrcpp_0.2.2  forcats_0.3.0  
##  [9] stringr_1.3.1   dplyr_0.7.6     purrr_0.2.5     readr_1.1.1    
## [13] tidyr_0.8.1     tibble_2.0.1    ggplot2_3.1.0   tidyverse_1.2.1
## 
## loaded via a namespace (and not attached):
##   [1] colorspace_1.3-2          ggridges_0.5.0           
##   [3] rsconnect_0.8.8           rprojroot_1.3-2          
##   [5] ggstance_0.3              markdown_0.8             
##   [7] base64enc_0.1-3           rstudioapi_0.7           
##   [9] rstan_2.18.2              svUnit_0.7-12            
##  [11] DT_0.4                    fansi_0.4.0              
##  [13] mvtnorm_1.0-8             lubridate_1.7.4          
##  [15] xml2_1.2.0                bridgesampling_0.4-0     
##  [17] knitr_1.20                shinythemes_1.1.1        
##  [19] bayesplot_1.6.0           jsonlite_1.5             
##  [21] shiny_1.1.0               compiler_3.5.1           
##  [23] httr_1.3.1                backports_1.1.2          
##  [25] assertthat_0.2.0          Matrix_1.2-14            
##  [27] lazyeval_0.2.1            cli_1.0.1                
##  [29] later_0.7.3               htmltools_0.3.6          
##  [31] prettyunits_1.0.2         tools_3.5.1              
##  [33] igraph_1.2.1              coda_0.19-2              
##  [35] gtable_0.2.0              glue_1.3.0               
##  [37] reshape2_1.4.3            cellranger_1.1.0         
##  [39] nlme_3.1-137              blogdown_0.8             
##  [41] crosstalk_1.0.0           xfun_0.3                 
##  [43] ps_1.2.1                  rvest_0.3.2              
##  [45] mime_0.5                  miniUI_0.1.1.1           
##  [47] gtools_3.8.1              MASS_7.3-50              
##  [49] zoo_1.8-2                 scales_1.0.0             
##  [51] colourpicker_1.0          hms_0.4.2                
##  [53] promises_1.0.1            Brobdingnag_1.2-5        
##  [55] parallel_3.5.1            inline_0.3.15            
##  [57] shinystan_2.5.0           yaml_2.1.19              
##  [59] StanHeaders_2.18.0-1      stringi_1.2.3            
##  [61] highr_0.7                 dygraphs_1.1.1.5         
##  [63] pkgbuild_1.0.2            rlang_0.3.1              
##  [65] pkgconfig_2.0.2           matrixStats_0.54.0       
##  [67] evaluate_0.10.1           lattice_0.20-35          
##  [69] bindr_0.1.1               rstantools_1.5.0         
##  [71] htmlwidgets_1.2           labeling_0.3             
##  [73] tidyselect_0.2.4          processx_3.2.1           
##  [75] plyr_1.8.4                magrittr_1.5             
##  [77] bookdown_0.7              R6_2.3.0                 
##  [79] generics_0.0.2            pillar_1.3.1             
##  [81] haven_1.1.2               withr_2.1.2              
##  [83] xts_0.10-2                abind_1.4-5              
##  [85] modelr_0.1.2              crayon_1.3.4             
##  [87] arrayhelpers_1.0-20160527 utf8_1.1.4               
##  [89] rmarkdown_1.10            grid_3.5.1               
##  [91] readxl_1.1.0              callr_3.1.0              
##  [93] threejs_0.3.1             digest_0.6.18            
##  [95] xtable_1.8-2              httpuv_1.4.4.2           
##  [97] stats4_3.5.1              munsell_0.5.0            
##  [99] viridisLite_0.3.0         shinyjs_1.0&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Make rotated Gaussians, Kruschke style</title>
      <link>/post/make-rotated-gaussians-kruschke-style/</link>
      <pubDate>Thu, 20 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/make-rotated-gaussians-kruschke-style/</guid>
      <description>&lt;p&gt;[edited Dec 23, 2018]&lt;/p&gt;
&lt;div id=&#34;tldr&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;tl;dr&lt;/h2&gt;
&lt;p&gt;You too can make sideways Gaussian density curves within the tidyverse. Here’s how.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;heres-the-deal-i-like-making-pictures.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Here’s the deal: I like making pictures.&lt;/h2&gt;
&lt;p&gt;Over the past several months, I’ve been slowly chipping away at John Kruschke’s &lt;a href=&#34;https://sites.google.com/site/doingbayesiandataanalysis/&#34;&gt;&lt;em&gt;Doing Bayesian data analysis, Second Edition: A tutorial with R, JAGS, and Stan&lt;/em&gt;&lt;/a&gt;. Kruschke has a unique plotting style. One of the quirks is once in a while he likes to express the results of his analyses in plots where he shows the data alongside density curves of the model-implied data-generating distributions. Here’s an example from chapter 19 (p. 563).&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/img/Kruschke_sideways_Gaussians.png&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;In this example, he has lifespan data (i.e., &lt;code&gt;Longevity&lt;/code&gt;) for fruit flies from five experimental conditions (i.e., &lt;code&gt;CompanionNumber&lt;/code&gt;). Those are the black circles. In this section of the chapter, he used a Gaussian multilevel model in which the mean value for &lt;code&gt;Longevity&lt;/code&gt; had a grand mean in addition to random effects for the five experimental conditions. Those sideways-turned blue Gaussians are his attempt to express the model-implied data generating distributions for each group.&lt;/p&gt;
&lt;p&gt;If you haven’t gone through Kruschke’s text, you should know he relies on base R and all its &lt;a href=&#34;https://bookdown.org/rdpeng/rprogdatascience/control-structures.html#for-loops&#34;&gt;loop&lt;/a&gt;y glory. If you carefully go through his code, you can reproduce his plots in that fashion. I’m a &lt;a href=&#34;https://www.tidyverse.org&#34;&gt;tidyverse&lt;/a&gt; man and prefer to avoid writing a &lt;code&gt;for()&lt;/code&gt; loop at all costs. At first, I tried to work with convenience functions within ggplot2 and friends, but only had limited success. After staring long and hard at Kruschke’s base code, I came up with a robust solution, which I’d like to share here.&lt;/p&gt;
&lt;p&gt;In this post, we’ll practice making sideways Gaussians in the Kruschke style. We’ll do so with a simple intercept-only single-level model and then expand our approach to an intercept-only multilevel model like the one in the picture, above.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;my-assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;My assumptions&lt;/h2&gt;
&lt;p&gt;For the sake of this post, I’m presuming you’re familiar with &lt;a href=&#34;https://bookdown.org/rdpeng/rprogdatascience/history-and-overview-of-r.html&#34;&gt;R&lt;/a&gt;, aware of the &lt;a href=&#34;https://www.rstudio.com/resources/videos/data-science-in-the-tidyverse/&#34;&gt;tidyverse&lt;/a&gt;, and have fit a &lt;a href=&#34;https://www.youtube.com/watch?v=4WVelCswXo4&#34;&gt;Bayesian model&lt;/a&gt; or two. Yes. I admit that’s a narrow crowd. Sometimes the target’s a small one.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;we-need-data.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;We need data.&lt;/h2&gt;
&lt;p&gt;First, we need data. Here we’ll borrow code from Matthew Kay’s nice &lt;a href=&#34;https://mjskay.github.io/tidybayes/articles/tidy-brms.html&#34;&gt;tutorial&lt;/a&gt; on how to use his great &lt;a href=&#34;https://github.com/mjskay/tidybayes&#34;&gt;tidybayes package&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)

set.seed(5)
n           &amp;lt;- 10
n_condition &amp;lt;- 5

abc &amp;lt;-
  tibble(condition = rep(letters[1:5], times = n),
         response  = rnorm(n * 5, mean = c(0, 1, 2, 1, -1), sd = 0.5))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The data structure looks like so.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(abc)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Classes &amp;#39;tbl_df&amp;#39;, &amp;#39;tbl&amp;#39; and &amp;#39;data.frame&amp;#39;:    50 obs. of  2 variables:
##  $ condition: chr  &amp;quot;a&amp;quot; &amp;quot;b&amp;quot; &amp;quot;c&amp;quot; &amp;quot;d&amp;quot; ...
##  $ response : num  -0.42 1.692 1.372 1.035 -0.144 ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With Kay’s code, we have &lt;code&gt;response&lt;/code&gt; values for five &lt;code&gt;condition&lt;/code&gt;s. All follow the normal distribution and share a common standard deviation. However, they differ in their group means.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;abc %&amp;gt;% 
  group_by(condition) %&amp;gt;% 
  summarise(mean = mean(response) %&amp;gt;% round(digits = 2))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 2
##   condition  mean
##   &amp;lt;chr&amp;gt;     &amp;lt;dbl&amp;gt;
## 1 a          0.18
## 2 b          1.01
## 3 c          1.87
## 4 d          1.03
## 5 e         -0.94&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Altogether, the data look like this.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;theme_set(theme_grey() + 
            theme(panel.grid = element_blank()))

abc %&amp;gt;%
  ggplot(aes(y = condition, x = response)) +
  geom_point(shape = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-20-make-rotated-gaussians-kruschke-style_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Let’s get ready to model.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;just-one-intercept&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Just one intercept&lt;/h2&gt;
&lt;p&gt;If you’ve read this far, you know we’re going Bayesian. Let’s open up our favorite Bayesian modeling package, Bürkner’s &lt;a href=&#34;https://github.com/paul-buerkner/brms&#34;&gt;brms&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(brms)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For our first model, we’ll ignore the groups and just estimate a grand mean and a standard deviation. Relative to the scale of the &lt;code&gt;abc&lt;/code&gt; data, our priors are modestly &lt;a href=&#34;https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations&#34;&gt;regularizing&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit1 &amp;lt;- 
  brm(data = abc,
      response ~ 1,
      prior = c(prior(normal(0, 1), class = Intercept),
                prior(student_t(3, 0, 1), class = sigma)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Extract the posterior draws and save them as a data frame we’ll call &lt;code&gt;post&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;post &amp;lt;- posterior_samples(fit1)

glimpse(post)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 4,000
## Variables: 3
## $ b_Intercept &amp;lt;dbl&amp;gt; 0.5987480, 0.5987480, 0.7314609, 0.6445826, 0.5576265, 0.7100258, 0.5000373, …
## $ sigma       &amp;lt;dbl&amp;gt; 1.1177155, 1.1177155, 1.0092032, 1.0192299, 1.1700033, 1.0615338, 1.0849874, …
## $ lp__        &amp;lt;dbl&amp;gt; -76.96158, -76.96158, -77.46269, -77.09759, -77.26516, -77.10602, -77.20185, …&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If all you want is a quick and dirty way to plot a few of the model-implied Gaussians from the simple model, you can just nest &lt;code&gt;stat_function()&lt;/code&gt; within &lt;code&gt;mapply()&lt;/code&gt; and tack on the original data in a &lt;code&gt;geom_jitter()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# How many Gaussians would you like?
n_iter &amp;lt;- 20

tibble(response = c(-4, 4)) %&amp;gt;%
  ggplot(aes(x = response)) +
  mapply(function(mean, sd) {
    stat_function(fun   = dnorm, 
                  args  = list(mean = mean, sd = sd), 
                  alpha = 1/2, 
                  color = &amp;quot;steelblue&amp;quot;)
    }, 
    # Enter means and standard deviations here
    mean = post[1:n_iter, &amp;quot;b_Intercept&amp;quot;],
    sd   = post[1:n_iter, &amp;quot;sigma&amp;quot;]
    ) +
  geom_jitter(data = abc, aes(y = -0.02),
              height = .025, shape = 1, alpha = 2/3) +
  scale_y_continuous(NULL, breaks = NULL)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-20-make-rotated-gaussians-kruschke-style_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This works pretty okay. But notice the orientation is the usual horizontal. Kruschke’s Gaussians were on their sides. If we switch out our &lt;code&gt;scale_y_continuous()&lt;/code&gt; line with &lt;code&gt;scale_y_reverse()&lt;/code&gt; and add in &lt;code&gt;coord_flip()&lt;/code&gt;, we’ll have it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tibble(response = c(-4, 4)) %&amp;gt;%
  ggplot(aes(x = response)) +
  mapply(function(mean, sd) {
    stat_function(fun   = dnorm, 
                  args  = list(mean = mean, sd = sd), 
                  alpha = 1/2, 
                  color = &amp;quot;steelblue&amp;quot;)
    }, 
    mean = post[1:n_iter, &amp;quot;b_Intercept&amp;quot;],
    sd   = post[1:n_iter, &amp;quot;sigma&amp;quot;]
    ) +
  geom_jitter(data = abc, aes(y = -0.02),
              height = .025, shape = 1, alpha = 2/3) +
  scale_y_reverse(NULL, breaks = NULL) +
  coord_flip() &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-20-make-rotated-gaussians-kruschke-style_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;288&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Boom. It won’t always be this easy, though.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;multiple-intercepts&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Multiple intercepts&lt;/h2&gt;
&lt;p&gt;Since the &lt;code&gt;response&lt;/code&gt; values are from a combination of five &lt;code&gt;condition&lt;/code&gt; groups, we can fit a multilevel model to compute both the grand mean and the group-level deviations from the grand mean.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit2 &amp;lt;- 
  brm(data = abc,
      response ~ 1 + (1 | condition),
      prior = c(prior(normal(0, 1), class = Intercept),
                prior(student_t(3, 0, 1), class = sigma),
                prior(student_t(3, 0, 1), class = sd)),
      cores = 4)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;“Wait. Whoa. I’m so confused”—you say. “What’s a multilevel model, again?” Read this &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34;&gt;book&lt;/a&gt;, or this &lt;a href=&#34;https://sites.google.com/site/doingbayesiandataanalysis/&#34;&gt;book&lt;/a&gt;; start &lt;a href=&#34;https://www.youtube.com/watch?v=2sTQ7TG_85Q&#34;&gt;here&lt;/a&gt; on this lecture series; or even check out &lt;a href=&#34;https://bookdown.org/connect/#/apps/1850/access&#34;&gt;my project&lt;/a&gt;, starting with chapter 12.&lt;/p&gt;
&lt;p&gt;Once again, extract the posterior draws and save them as a data frame, &lt;code&gt;post&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;post &amp;lt;- posterior_samples(fit2)

str(post)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;#39;data.frame&amp;#39;:    4000 obs. of  9 variables:
##  $ b_Intercept             : num  0.0379 0.102 -0.048 -1.0037 0.0231 ...
##  $ sd_condition__Intercept : num  2.08 2.13 1.94 1.99 2.21 ...
##  $ sigma                   : num  0.473 0.468 0.475 0.648 0.527 ...
##  $ r_condition[a,Intercept]: num  -0.01062 0.00219 0.23764 1.40189 0.08825 ...
##  $ r_condition[b,Intercept]: num  0.877 0.911 0.781 1.944 1.233 ...
##  $ r_condition[c,Intercept]: num  1.46 1.62 2.03 3.15 1.74 ...
##  $ r_condition[d,Intercept]: num  0.995 1.096 1.014 2.217 0.876 ...
##  $ r_condition[e,Intercept]: num  -1.111 -1.144 -1.005 0.234 -0.906 ...
##  $ lp__                    : num  -51.8 -49.2 -50 -53.5 -48.7 ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is where our task becomes difficult. Now each level of &lt;code&gt;condition&lt;/code&gt; has its own mean estimate, which is a combination of the grand mean &lt;code&gt;b_Intercept&lt;/code&gt; and the group-specific deviation, &lt;code&gt;r_condition[a,Intercept]&lt;/code&gt; through &lt;code&gt;r_condition[e,Intercept]&lt;/code&gt;. If all we wanted to do was show the model-implied Gaussians for, say, &lt;code&gt;condition == a&lt;/code&gt;, that’d be a small extension of our last approach.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tibble(response = c(-4, 4)) %&amp;gt;%
  ggplot(aes(x = response)) +
  mapply(function(mean, sd) {
    stat_function(fun   = dnorm, 
                  args  = list(mean = mean, sd = sd), 
                  alpha = 1/2, 
                  color = &amp;quot;steelblue&amp;quot;)
    }, 
    # Here&amp;#39;s the small extension, part a
    mean = post[1:n_iter, &amp;quot;b_Intercept&amp;quot;] + post[1:n_iter, &amp;quot;r_condition[a,Intercept]&amp;quot;],
    sd   = post[1:n_iter, &amp;quot;sigma&amp;quot;]
    ) +
  # The small extension, part b:
  geom_jitter(data = abc %&amp;gt;% filter(condition == &amp;quot;a&amp;quot;), aes(y = 0),
              height = .025, shape = 1, alpha = 2/3) +
  scale_y_reverse(NULL, breaks = NULL) +
  coord_flip() +
  labs(subtitle = &amp;quot;This is just for condition a&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-20-make-rotated-gaussians-kruschke-style_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;288&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The main thing we did was add to the definition of the &lt;code&gt;mean&lt;/code&gt; within &lt;code&gt;mapply()&lt;/code&gt;: &lt;code&gt;mean = post[1:n_iter, &amp;quot;b_Intercept&amp;quot;] + post[1:n_iter, &amp;quot;r_condition[a,Intercept]&amp;quot;]&lt;/code&gt;. Within &lt;code&gt;geom_jitter()&lt;/code&gt;, we also isolated the &lt;code&gt;condition == &amp;quot;a&amp;quot;&lt;/code&gt; cases with &lt;code&gt;filter()&lt;/code&gt;. Simple. However, it’s more of a pickle if we want multiple densities stacked atop/next to one another within the same plot.&lt;/p&gt;
&lt;p&gt;Unfortunately, we can’t extend our &lt;code&gt;mapply(stat_function())&lt;/code&gt; method to the group-level estimates–at least not that I’m aware. But there are other ways. We’ll need a little help from &lt;code&gt;tidybayes::spread_draws()&lt;/code&gt;, about which you can learn more &lt;a href=&#34;https://mjskay.github.io/tidybayes/articles/tidy-brms.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidybayes)

sd &amp;lt;-
  fit2 %&amp;gt;% 
  spread_draws(b_Intercept, sigma, r_condition[condition,])
  
head(sd)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 7
## # Groups:   condition [5]
##   .chain .iteration .draw b_Intercept sigma condition r_condition
##    &amp;lt;int&amp;gt;      &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;       &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;           &amp;lt;dbl&amp;gt;
## 1      1          1     1      0.0379 0.473 a            -0.0106 
## 2      1          1     1      0.0379 0.473 b             0.877  
## 3      1          1     1      0.0379 0.473 c             1.46   
## 4      1          1     1      0.0379 0.473 d             0.995  
## 5      1          1     1      0.0379 0.473 e            -1.11   
## 6      1          2     2      0.102  0.468 a             0.00219&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In our &lt;code&gt;sp&lt;/code&gt; &lt;a href=&#34;https://cran.r-project.org/web/packages/tibble/vignettes/tibble.html&#34;&gt;tibble&lt;/a&gt;, we have much of the same information we’d get from &lt;code&gt;brms::posterior_samples()&lt;/code&gt;, but in the long format with respect to the random effects for &lt;code&gt;condition&lt;/code&gt;. Also notice that each row is indexed by the chain, iteration, and draw number. Among those, &lt;code&gt;.draw&lt;/code&gt; is the column that corresponds to a unique row like what we’d get from &lt;code&gt;brms::posterior_samples()&lt;/code&gt;. This is the index that ranges from 1 to the number of chains multiplied by the number of post-warmup iterations (i.e., default 4000 in our case).&lt;/p&gt;
&lt;p&gt;But we need to wrangle a bit. Within the &lt;code&gt;expand()&lt;/code&gt; function, we’ll select the columns we’d like to keep within the &lt;code&gt;nesting()&lt;/code&gt; function and then expand the tibble by adding a sequence of &lt;code&gt;response&lt;/code&gt; values ranging from -4 to 4, for each. This sets us up to use the &lt;code&gt;dnorm()&lt;/code&gt; function in the next line to compute the density for each of those &lt;code&gt;response&lt;/code&gt; values based on 20 unique normal distributions for each of the five &lt;code&gt;condition&lt;/code&gt; groups. “Why 20?” Because we need some reasonably small number and 20’s the one Kruschke tended to use in his text and because, well, we set &lt;code&gt;filter(.draw &amp;lt; 21)&lt;/code&gt;. But choose whatever number you like.&lt;/p&gt;
&lt;p&gt;The difficulty, however, is that all of these densities will have a minimum value of around 0 and all will be on the same basic scale. So we need a way to serially shift the density values up the y-axis in such a way that they’ll be sensibly separated by group. As far as I can figure, this’ll take us a couple steps. For the first step, we’ll create an intermediary variable, &lt;code&gt;g&lt;/code&gt;, with which we’ll arbitrarily assign each of our five groups an integer index ranging from 0 to 4.&lt;/p&gt;
&lt;p&gt;The second step is tricky. There we use our &lt;code&gt;g&lt;/code&gt; integers to sequentially shift the density values up. Since our &lt;code&gt;g&lt;/code&gt; value for &lt;code&gt;a == 0&lt;/code&gt;, those we’ll keep 0 as their baseline. As our &lt;code&gt;g&lt;/code&gt; value for &lt;code&gt;b == 1&lt;/code&gt;, the baseline for those will now increase by 1. And so on for the other groups. But we still need to do a little more fiddling. What we want is for the maximum values of the density estimates to be a little lower than the baselines of the ones one grouping variable up. That is, we want the maximum values for the &lt;code&gt;a&lt;/code&gt; densities to fall a little bit below 1 on the y-axis. It’s with the &lt;code&gt;* .75 / max(density)&lt;/code&gt; part of the code that we accomplish that task. If you want to experiment with more or less room between the top and bottom of each density, play around with increasing/decreasing that .75 value.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sd &amp;lt;-
  sd %&amp;gt;% 
  filter(.draw &amp;lt; 21) %&amp;gt;% 
  expand(nesting(.draw, b_Intercept, sigma, condition, r_condition), 
         response = seq(from = -4, to = 4, length.out = 200)) %&amp;gt;%
  mutate(density = dnorm(response, mean = b_Intercept + r_condition, sd = sigma),
         g       = recode(condition,
                          a = 0,
                          b = 1,
                          c = 2,
                          d = 3,
                          e = 4)) %&amp;gt;% 
  mutate(density = g + density * .75 / max(density))

glimpse(sd)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 20,000
## Variables: 8
## Groups: condition [5]
## $ .draw       &amp;lt;int&amp;gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…
## $ b_Intercept &amp;lt;dbl&amp;gt; 0.03787325, 0.03787325, 0.03787325, 0.03787325, 0.03787325, 0.03787325, 0.037…
## $ sigma       &amp;lt;dbl&amp;gt; 0.4734374, 0.4734374, 0.4734374, 0.4734374, 0.4734374, 0.4734374, 0.4734374, …
## $ condition   &amp;lt;chr&amp;gt; &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a…
## $ r_condition &amp;lt;dbl&amp;gt; -0.0106207, -0.0106207, -0.0106207, -0.0106207, -0.0106207, -0.0106207, -0.01…
## $ response    &amp;lt;dbl&amp;gt; -4.000000, -3.959799, -3.919598, -3.879397, -3.839196, -3.798995, -3.758794, …
## $ density     &amp;lt;dbl&amp;gt; 1.435677e-16, 2.945670e-16, 6.000399e-16, 1.213514e-15, 2.436566e-15, 4.85713…
## $ g           &amp;lt;dbl&amp;gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Since we’ll now be using the same axis for both the densities and the five &lt;code&gt;condition&lt;/code&gt; groups, we’ll need to add a &lt;code&gt;density&lt;/code&gt; column to our &lt;code&gt;abc&lt;/code&gt; data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;abc &amp;lt;-
  abc %&amp;gt;% 
  mutate(density = recode(condition,
                          a = 0,
                          b = 1,
                          c = 2,
                          d = 3,
                          e = 4))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Time to plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sd %&amp;gt;% 
  ggplot(aes(x = response, y = density)) +
  # here we make our density lines
  geom_line(aes(group = interaction(.draw, g)),
            alpha = 1/2, size = 1/3, color = &amp;quot;steelblue&amp;quot;) +
  # use the original data for the jittered points
  geom_jitter(data = abc,
              height = .05, shape = 1, alpha = 2/3) +
  scale_y_continuous(&amp;quot;condition&amp;quot;,
                     breaks = 0:4,
                     labels = letters[1:5])&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-20-make-rotated-gaussians-kruschke-style_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now we’re rolling. Let’s make a cosmetic adjustment. Recall that the full range of the normal distribution spans from &lt;span class=&#34;math inline&#34;&gt;\(-\infty\)&lt;/span&gt; to &lt;span class=&#34;math inline&#34;&gt;\(\infty\)&lt;/span&gt;. At a certain point, it’s just not informative to show the left and right tails. If you look back up at our motivating example, you’ll note Kruschke’s densities stopped well before trailing off into the tails. If you look closely to the code from his text, you’ll see he’s just showing the inner 95-percentile range for each. To follow suit, we can compute those ranges with &lt;code&gt;qnorm()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sd &amp;lt;-
  sd %&amp;gt;% 
  mutate(ll = qnorm(.025, mean = b_Intercept + r_condition, sd = sigma),
         ul = qnorm(.975, mean = b_Intercept + r_condition, sd = sigma))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we have our lower- and upper-level points for each iteration, we can limit the ranges of our Gaussians with &lt;code&gt;filter()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sd %&amp;gt;% 
  filter(response &amp;gt; ll,
         response &amp;lt; ul) %&amp;gt;% 
  
  ggplot(aes(x = response, y = density)) +
  geom_line(aes(group = interaction(.draw, g)),
            alpha = 1/2, size = 1/3, color = &amp;quot;steelblue&amp;quot;) +
  geom_jitter(data = abc,
              height = .05, shape = 1, alpha = 2/3) +
  scale_y_continuous(&amp;quot;condition&amp;quot;,
                     breaks = 0:4,
                     labels = letters[1:5])&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-20-make-rotated-gaussians-kruschke-style_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Oh man, just look how sweet that is. Although I prefer our current method, another difference between it and Kruschke’s example is all of his densities are the same relative height. In all our plots so far, though, the densities differ by their heights. We’ll need a slight adjustment in our &lt;code&gt;sd&lt;/code&gt; workflow for that. All we need to do is insert a &lt;code&gt;group_by()&lt;/code&gt; statement between the two &lt;code&gt;mutate()&lt;/code&gt; lines.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sd &amp;lt;-
  sd %&amp;gt;% 
  mutate(density = dnorm(response, mean = b_Intercept + r_condition, sd = sigma),
         g       = recode(condition,
                          a = 0,
                          b = 1,
                          c = 2,
                          d = 3,
                          e = 4)) %&amp;gt;% 
  # here&amp;#39;s the new line
  group_by(.draw) %&amp;gt;% 
  mutate(density = g + density * .75 / max(density))

# now plot
sd %&amp;gt;% 
  filter(response &amp;gt; ll,
         response &amp;lt; ul) %&amp;gt;% 
  ggplot(aes(x = response, y = density)) +
  geom_line(aes(group = interaction(.draw, g)),
            alpha = 1/2, size = 1/3, color = &amp;quot;steelblue&amp;quot;) +
  geom_jitter(data = abc,
              height = .05, shape = 1, alpha = 2/3) +
  scale_y_continuous(&amp;quot;condition&amp;quot;,
                     breaks = 0:4,
                     labels = letters[1:5])&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-20-make-rotated-gaussians-kruschke-style_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Nice. “But wait!”, you say. “We wanted our Gaussians to be on their sides.” We can do that in at least two ways. At this point, the quickest way is to use our &lt;code&gt;scale_y_reverse() + coord_flip()&lt;/code&gt; combo from before.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sd %&amp;gt;% 
  filter(response &amp;gt; ll,
         response &amp;lt; ul) %&amp;gt;% 
  
  ggplot(aes(x = response, y = density)) +
  geom_line(aes(group = interaction(.draw, g)),
            alpha = 1/2, size = 1/3, color = &amp;quot;steelblue&amp;quot;) +
  geom_jitter(data = abc,
              height = .05, shape = 1, alpha = 2/3) +
  scale_y_reverse(&amp;quot;condition&amp;quot;,
                  breaks = 0:4,
                  labels = letters[1:5]) +
  coord_flip()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-20-make-rotated-gaussians-kruschke-style_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Another way to get those sideways Gaussians is to alter our &lt;code&gt;sd&lt;/code&gt; data workflow. The main differene is this time we change the original &lt;code&gt;mutate(density = g + density * .75 / max(density))&lt;/code&gt; line to &lt;code&gt;mutate(density = g - density * .75 / max(density))&lt;/code&gt;. In case you missed it, the only difference is we changed the &lt;code&gt;+&lt;/code&gt; to a &lt;code&gt;-&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sd &amp;lt;-
  sd %&amp;gt;% 
  # step one: starting fresh
  mutate(density = dnorm(response, mean = b_Intercept + r_condition, sd = sigma)) %&amp;gt;% 
  group_by(.draw) %&amp;gt;% 
  # step two: now SUBTRACTING density from g within the equation
  mutate(density = g - density * .75 / max(density))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now in our global &lt;code&gt;aes()&lt;/code&gt; statement in the plot, we put &lt;code&gt;density&lt;/code&gt; on the x and &lt;code&gt;response&lt;/code&gt; on the y. We need to take a few other subtle steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Switch out &lt;code&gt;geom_line()&lt;/code&gt; for &lt;code&gt;geom_path()&lt;/code&gt; (see &lt;a href=&#34;https://ggplot2.tidyverse.org/reference/geom_path.html&#34;&gt;here&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;Drop the &lt;code&gt;height&lt;/code&gt; argument within &lt;code&gt;geom_jitter()&lt;/code&gt; for &lt;code&gt;width&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Switch out &lt;code&gt;scale_y_continuous()&lt;/code&gt; for &lt;code&gt;scale_x_continuous()&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Though totally not necessary, we’ll add a little something extra by coloring the Gaussians by their means.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sd %&amp;gt;% 
  filter(response &amp;gt; ll,
         response &amp;lt; ul) %&amp;gt;% 
  
  ggplot(aes(x = density, y = response)) +
  geom_path(aes(group = interaction(.draw, g), 
                color = b_Intercept + r_condition),
            alpha = 1/2, size = 1/3, show.legend = F) +
  geom_jitter(data = abc,
              width = .05, shape = 1, alpha = 2/3) +
  scale_x_continuous(&amp;quot;condition&amp;quot;,
                     breaks = 0:4,
                     labels = letters[1:5]) +
  scale_color_viridis_c(option = &amp;quot;A&amp;quot;, end = .92)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-20-make-rotated-gaussians-kruschke-style_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There you have it–Kruschke-style sideways Gaussians for your model plots.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;afterward&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Afterward&lt;/h2&gt;
&lt;p&gt;After releasing the initial version of this post, some of us had a lively twitter discussion on how to improve the code.&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Ah, hrm. Took some digging, but it looks like negative density + setting `min_height = NA` (otherwise negative values are cut off) might work &lt;a href=&#34;https://t.co/gmF9kpo2T7&#34;&gt;pic.twitter.com/gmF9kpo2T7&lt;/a&gt;&lt;/p&gt;&amp;mdash; Matthew Kay (@mjskay) &lt;a href=&#34;https://twitter.com/mjskay/status/1076395687020056576?ref_src=twsrc%5Etfw&#34;&gt;December 22, 2018&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;p&gt;Part of that discussion had to do with the possibility of using functions from &lt;a href=&#34;https://twitter.com/ClausWilke/&#34;&gt;Claus Wilke&lt;/a&gt;’s great &lt;a href=&#34;https://github.com/clauswilke/ggridges&#34;&gt;ggridges package&lt;/a&gt;. After some great efforts, especially from &lt;a href=&#34;https://twitter.com/mjskay/&#34;&gt;Matthew Kay&lt;/a&gt;, we came up with solutions. In this section, we’ll cover them in some detail.&lt;/p&gt;
&lt;p&gt;First, here’s a more compact way to prepare the data for the plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;abc %&amp;gt;%
  distinct(condition) %&amp;gt;%
  add_fitted_draws(fit2, n = 20, dpar = c(&amp;quot;mu&amp;quot;, &amp;quot;sigma&amp;quot;)) %&amp;gt;% 
  mutate(lower    = qnorm(.025, mean = mu, sd = sigma),
         upper    = qnorm(.975, mean = mu, sd = sigma)) %&amp;gt;% 
  mutate(response = map2(lower, upper, seq, length.out = 200)) %&amp;gt;% 
  mutate(density  = pmap(list(response, mu, sigma), dnorm)) %&amp;gt;% 
  unnest() %&amp;gt;% 
  group_by(.draw) %&amp;gt;% 
  mutate(density  = density * .75 / max(density)) %&amp;gt;% 
  
  glimpse()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 20,000
## Variables: 12
## Groups: .draw [20]
## $ condition  &amp;lt;chr&amp;gt; &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;…
## $ .row       &amp;lt;int&amp;gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …
## $ .chain     &amp;lt;int&amp;gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
## $ .iteration &amp;lt;int&amp;gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
## $ .draw      &amp;lt;int&amp;gt; 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24…
## $ .value     &amp;lt;dbl&amp;gt; 0.2041854, 0.2041854, 0.2041854, 0.2041854, 0.2041854, 0.2041854, 0.2041854, 0…
## $ mu         &amp;lt;dbl&amp;gt; 0.2041854, 0.2041854, 0.2041854, 0.2041854, 0.2041854, 0.2041854, 0.2041854, 0…
## $ sigma      &amp;lt;dbl&amp;gt; 0.5729852, 0.5729852, 0.5729852, 0.5729852, 0.5729852, 0.5729852, 0.5729852, 0…
## $ lower      &amp;lt;dbl&amp;gt; -0.918845, -0.918845, -0.918845, -0.918845, -0.918845, -0.918845, -0.918845, -…
## $ upper      &amp;lt;dbl&amp;gt; 1.327216, 1.327216, 1.327216, 1.327216, 1.327216, 1.327216, 1.327216, 1.327216…
## $ response   &amp;lt;dbl&amp;gt; -0.9188450, -0.9075582, -0.8962715, -0.8849847, -0.8736980, -0.8624113, -0.851…
## $ density    &amp;lt;dbl&amp;gt; 0.1098804, 0.1141834, 0.1186089, 0.1231581, 0.1278322, 0.1326322, 0.1375591, 0…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This could use some walking out. With the first two lines, we made a &lt;span class=&#34;math inline&#34;&gt;\(5 \times 1\)&lt;/span&gt; tibble containing the five levels of &lt;code&gt;condition&lt;/code&gt;, &lt;code&gt;a&lt;/code&gt; through &lt;code&gt;f&lt;/code&gt;. The &lt;code&gt;add_fitted_draws()&lt;/code&gt; function comes from tidybayes. The first argument took our brms model fit, &lt;code&gt;fit2&lt;/code&gt;. With the &lt;code&gt;n&lt;/code&gt; argument, we indicated we just wanted &lt;code&gt;20&lt;/code&gt; draws. With &lt;code&gt;dpar&lt;/code&gt;, we requested distributional regression parameters in the output. In our case, those were the &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; values for each level of &lt;code&gt;condition&lt;/code&gt;. Here’s what that looks like.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;abc %&amp;gt;%
  distinct(condition) %&amp;gt;%
  add_fitted_draws(fit2, n = 20, dpar = c(&amp;quot;mu&amp;quot;, &amp;quot;sigma&amp;quot;)) %&amp;gt;% 
  
  head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 8
## # Groups:   condition, .row [1]
##   condition  .row .chain .iteration .draw .value    mu sigma
##   &amp;lt;chr&amp;gt;     &amp;lt;int&amp;gt;  &amp;lt;int&amp;gt;      &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 a             1     NA         NA    55  0.163 0.163 0.458
## 2 a             1     NA         NA   126  0.509 0.509 0.513
## 3 a             1     NA         NA   404  0.472 0.472 0.717
## 4 a             1     NA         NA   813  0.387 0.387 0.537
## 5 a             1     NA         NA  1111  0.154 0.154 0.515
## 6 a             1     NA         NA  1218  0.204 0.204 0.495&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we established the lower- and upper-bounds bounds for the density lines, which were 95% intervals in this example. Within the second &lt;code&gt;mutate()&lt;/code&gt; function, we used the &lt;a href=&#34;https://purrr.tidyverse.org/reference/map2.html&#34;&gt;&lt;code&gt;purrr::map2()&lt;/code&gt;&lt;/a&gt; function to feed those two values into the first two arguments of the &lt;code&gt;seq()&lt;/code&gt; function. Those arguments, recall, are &lt;code&gt;from&lt;/code&gt; and &lt;code&gt;to&lt;/code&gt;. We then hard coded &lt;code&gt;200&lt;/code&gt; into the &lt;code&gt;length.out&lt;/code&gt; argument. As a result, we turned our regular old tibble into a &lt;a href=&#34;https://tidyr.tidyverse.org/reference/nest.html&#34;&gt;nested tibble&lt;/a&gt;. In each row of our new &lt;code&gt;response&lt;/code&gt; column, we now have a &lt;span class=&#34;math inline&#34;&gt;\(200 \times 1\)&lt;/span&gt; data frame containing the &lt;code&gt;seq()&lt;/code&gt; output. If you’re new to nested data structures, I recommend checking out Hadley Wickham’s &lt;a href=&#34;https://www.youtube.com/watch?v=rz3_FDVt9eg&#34;&gt;&lt;em&gt;Managing many models with R&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;abc %&amp;gt;%
  distinct(condition) %&amp;gt;%
  add_fitted_draws(fit2, n = 20, dpar = c(&amp;quot;mu&amp;quot;, &amp;quot;sigma&amp;quot;)) %&amp;gt;% 
  mutate(lower    = qnorm(.025, mean = mu, sd = sigma),
         upper    = qnorm(.975, mean = mu, sd = sigma)) %&amp;gt;% 
  mutate(response = map2(lower, upper, seq, length.out = 200)) %&amp;gt;% 
  
  head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 11
## # Groups:   condition, .row [1]
##   condition  .row .chain .iteration .draw .value     mu sigma  lower upper response   
##   &amp;lt;chr&amp;gt;     &amp;lt;int&amp;gt;  &amp;lt;int&amp;gt;      &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;list&amp;gt;     
## 1 a             1     NA         NA   346 0.278  0.278  0.521 -0.743  1.30 &amp;lt;dbl [200]&amp;gt;
## 2 a             1     NA         NA   696 0.193  0.193  0.498 -0.783  1.17 &amp;lt;dbl [200]&amp;gt;
## 3 a             1     NA         NA   734 0.320  0.320  0.709 -1.07   1.71 &amp;lt;dbl [200]&amp;gt;
## 4 a             1     NA         NA  1214 0.0686 0.0686 0.559 -1.03   1.16 &amp;lt;dbl [200]&amp;gt;
## 5 a             1     NA         NA  1313 0.229  0.229  0.539 -0.828  1.29 &amp;lt;dbl [200]&amp;gt;
## 6 a             1     NA         NA  1348 0.329  0.329  0.589 -0.826  1.48 &amp;lt;dbl [200]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Much as the &lt;code&gt;purrr::map2()&lt;/code&gt; function allowed us to iterate over two arguments, the &lt;code&gt;purrr::pmap()&lt;/code&gt; function will allow us to iterate over an arbitrary number of arguments. In the case of our third &lt;code&gt;mutate()&lt;/code&gt; function, we’ll iterate over the first three arguments of the &lt;code&gt;dnorm()&lt;/code&gt; function. In case you forgot, those arguments are &lt;code&gt;x&lt;/code&gt;, &lt;code&gt;mean&lt;/code&gt;, and &lt;code&gt;sd&lt;/code&gt;, respectively. Within our &lt;code&gt;list()&lt;/code&gt;, we indicated we wanted to insert into them the &lt;code&gt;response&lt;/code&gt;, &lt;code&gt;mu&lt;/code&gt;, and &lt;code&gt;sigma&lt;/code&gt; values. This returns the desired &lt;code&gt;density&lt;/code&gt; values. Since our &lt;code&gt;map2()&lt;/code&gt; and &lt;code&gt;pmap()&lt;/code&gt; operations returned a nested tibble, we then followed them up with the &lt;code&gt;unnest()&lt;/code&gt; function to make it easier to access the results.&lt;/p&gt;
&lt;p&gt;Before &lt;code&gt;unnest&lt;/code&gt;ing, our nested tibble had 100 observations. After &lt;code&gt;unnest()&lt;/code&gt;, we converted it to the long format, resulting in &lt;span class=&#34;math inline&#34;&gt;\(100 \times 200 = 20,000\)&lt;/span&gt; observations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;abc %&amp;gt;%
  distinct(condition) %&amp;gt;%
  add_fitted_draws(fit2, n = 20, dpar = c(&amp;quot;mu&amp;quot;, &amp;quot;sigma&amp;quot;)) %&amp;gt;% 
  mutate(lower    = qnorm(.025, mean = mu, sd = sigma),
         upper    = qnorm(.975, mean = mu, sd = sigma)) %&amp;gt;% 
  mutate(response = map2(lower, upper, seq, length.out = 200)) %&amp;gt;% 
  mutate(density  = pmap(list(response, mu, sigma), dnorm)) %&amp;gt;% 
  unnest() %&amp;gt;% 
  
  glimpse()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 20,000
## Variables: 12
## Groups: condition, .row [5]
## $ condition  &amp;lt;chr&amp;gt; &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;…
## $ .row       &amp;lt;int&amp;gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …
## $ .chain     &amp;lt;int&amp;gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
## $ .iteration &amp;lt;int&amp;gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
## $ .draw      &amp;lt;int&amp;gt; 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79…
## $ .value     &amp;lt;dbl&amp;gt; -0.05142892, -0.05142892, -0.05142892, -0.05142892, -0.05142892, -0.05142892, …
## $ mu         &amp;lt;dbl&amp;gt; -0.05142892, -0.05142892, -0.05142892, -0.05142892, -0.05142892, -0.05142892, …
## $ sigma      &amp;lt;dbl&amp;gt; 0.5490717, 0.5490717, 0.5490717, 0.5490717, 0.5490717, 0.5490717, 0.5490717, 0…
## $ lower      &amp;lt;dbl&amp;gt; -1.12759, -1.12759, -1.12759, -1.12759, -1.12759, -1.12759, -1.12759, -1.12759…
## $ upper      &amp;lt;dbl&amp;gt; 1.024732, 1.024732, 1.024732, 1.024732, 1.024732, 1.024732, 1.024732, 1.024732…
## $ response   &amp;lt;dbl&amp;gt; -1.1275896, -1.1167739, -1.1059582, -1.0951425, -1.0843269, -1.0735112, -1.062…
## $ density    &amp;lt;dbl&amp;gt; 0.1064434, 0.1106119, 0.1148989, 0.1193059, 0.1238338, 0.1284836, 0.1332564, 0…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Hopefully, our last two lines look familiar. We &lt;code&gt;group_by(.draw)&lt;/code&gt; just like in previous examples. However, our final &lt;code&gt;mutate()&lt;/code&gt; line is a little simpler than in previous versions. Before we had to make that intermediary variable, &lt;code&gt;g&lt;/code&gt;. Because we intend to plot these data with help from ggridges, we no longer have need for &lt;code&gt;g&lt;/code&gt;. You’ll see. But the upshot is the only reason we’re adding this last &lt;code&gt;mutate()&lt;/code&gt; line is to scale all the Gaussians to have the same maximum height the way Kruschke did.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;afd &amp;lt;-
  abc %&amp;gt;%
  distinct(condition) %&amp;gt;%
  add_fitted_draws(fit2, n = 20, dpar = c(&amp;quot;mu&amp;quot;, &amp;quot;sigma&amp;quot;)) %&amp;gt;% 
  mutate(lower    = qnorm(.025, mean = mu, sd = sigma),
         upper    = qnorm(.975, mean = mu, sd = sigma)) %&amp;gt;% 
  mutate(response = map2(lower, upper, seq, length.out = 200)) %&amp;gt;% 
  mutate(density  = pmap(list(response, mu, sigma), dnorm)) %&amp;gt;% 
  unnest() %&amp;gt;% 
  group_by(.draw) %&amp;gt;% 
  mutate(density  = density * .75 / max(density))

glimpse(afd)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 20,000
## Variables: 12
## Groups: .draw [20]
## $ condition  &amp;lt;chr&amp;gt; &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;…
## $ .row       &amp;lt;int&amp;gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …
## $ .chain     &amp;lt;int&amp;gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
## $ .iteration &amp;lt;int&amp;gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
## $ .draw      &amp;lt;int&amp;gt; 292, 292, 292, 292, 292, 292, 292, 292, 292, 292, 292, 292, 292, 292, 292, 292…
## $ .value     &amp;lt;dbl&amp;gt; -0.302783, -0.302783, -0.302783, -0.302783, -0.302783, -0.302783, -0.302783, -…
## $ mu         &amp;lt;dbl&amp;gt; -0.302783, -0.302783, -0.302783, -0.302783, -0.302783, -0.302783, -0.302783, -…
## $ sigma      &amp;lt;dbl&amp;gt; 0.5187913, 0.5187913, 0.5187913, 0.5187913, 0.5187913, 0.5187913, 0.5187913, 0…
## $ lower      &amp;lt;dbl&amp;gt; -1.319595, -1.319595, -1.319595, -1.319595, -1.319595, -1.319595, -1.319595, -…
## $ upper      &amp;lt;dbl&amp;gt; 0.7140294, 0.7140294, 0.7140294, 0.7140294, 0.7140294, 0.7140294, 0.7140294, 0…
## $ response   &amp;lt;dbl&amp;gt; -1.3195953, -1.3093761, -1.2991569, -1.2889377, -1.2787185, -1.2684993, -1.258…
## $ density    &amp;lt;dbl&amp;gt; 0.1098804, 0.1141834, 0.1186089, 0.1231581, 0.1278322, 0.1326322, 0.1375591, 0…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s open &lt;a href=&#34;https://github.com/clauswilke/ggridges&#34;&gt;ggridges&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggridges)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note how contrary to before, we set the global y axis to our &lt;code&gt;condition&lt;/code&gt; grouping variable. It’s within the &lt;code&gt;geom_ridgeline()&lt;/code&gt; function that we now specify &lt;code&gt;height = density&lt;/code&gt;. Other than that, the main thing to point out is you might want to adjust the &lt;code&gt;ylim&lt;/code&gt; parameters. Otherwise the margins aren’t the best.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;afd %&amp;gt;%
  
  ggplot(aes(x = response, y = condition)) +
  geom_ridgeline(aes(height = density, group = interaction(condition, .draw)),
                 fill = NA, size = 1/3, color = adjustcolor(&amp;quot;steelblue&amp;quot;, alpha.f = 1/2)) +
  geom_jitter(data = abc,
              height = .05, shape = 1, alpha = 2/3) +
  coord_cartesian(ylim = c(1.25, 5.5))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-20-make-rotated-gaussians-kruschke-style_files/figure-html/unnamed-chunk-28-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;“But I wanted my Gaussians tipped to the left!”, you say. Yep, we can do that, too. Three things: First, we’ll want to adjust the &lt;code&gt;height&lt;/code&gt; parameter to &lt;code&gt;-density&lt;/code&gt;. We want our Gaussians to extend under their baselines. Along with that, we need to include &lt;code&gt;min_height = NA&lt;/code&gt;. Finally, we’ll switch out &lt;code&gt;coord_cartesian()&lt;/code&gt; for good old &lt;code&gt;coord_flip()&lt;/code&gt;. And you can adjust your &lt;code&gt;ylim&lt;/code&gt; parameters as desired.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;afd %&amp;gt;%
  
  ggplot(aes(x = response, y = condition)) +
  geom_ridgeline(aes(height = -density, group = interaction(condition, .draw)),
                 fill = NA, size = 1/3, color = adjustcolor(&amp;quot;steelblue&amp;quot;, alpha.f = 1/2),
                 min_height = NA) +
  geom_jitter(data = abc,
              height = .05, shape = 1, alpha = 2/3) +
  coord_flip(ylim = c(0.5, 4.75))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-20-make-rotated-gaussians-kruschke-style_files/figure-html/unnamed-chunk-29-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I think it’s important to note that I’ve never met any of the people who helped me with this project. Academic twitter, man–it’s a good place to be.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;session-info&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Session info&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 3.5.1 (2018-07-02)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS High Sierra 10.13.6
## 
## Matrix products: default
## BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] ggridges_0.5.0  tidybayes_1.0.3 brms_2.7.0      Rcpp_1.0.0      bindrcpp_0.2.2  forcats_0.3.0  
##  [7] stringr_1.3.1   dplyr_0.7.6     purrr_0.2.5     readr_1.1.1     tidyr_0.8.1     tibble_2.0.1   
## [13] ggplot2_3.1.0   tidyverse_1.2.1
## 
## loaded via a namespace (and not attached):
##   [1] colorspace_1.3-2          rsconnect_0.8.8           rprojroot_1.3-2          
##   [4] ggstance_0.3              markdown_0.8              base64enc_0.1-3          
##   [7] rstudioapi_0.7            rstan_2.18.2              svUnit_0.7-12            
##  [10] DT_0.4                    fansi_0.4.0               mvtnorm_1.0-8            
##  [13] lubridate_1.7.4           xml2_1.2.0                bridgesampling_0.4-0     
##  [16] knitr_1.20                shinythemes_1.1.1         bayesplot_1.6.0          
##  [19] jsonlite_1.5              broom_0.5.1               shiny_1.1.0              
##  [22] compiler_3.5.1            httr_1.3.1                backports_1.1.2          
##  [25] assertthat_0.2.0          Matrix_1.2-14             lazyeval_0.2.1           
##  [28] cli_1.0.1                 later_0.7.3               htmltools_0.3.6          
##  [31] prettyunits_1.0.2         tools_3.5.1               igraph_1.2.1             
##  [34] coda_0.19-2               gtable_0.2.0              glue_1.3.0               
##  [37] reshape2_1.4.3            cellranger_1.1.0          nlme_3.1-137             
##  [40] blogdown_0.8              crosstalk_1.0.0           xfun_0.3                 
##  [43] ps_1.2.1                  rvest_0.3.2               mime_0.5                 
##  [46] miniUI_0.1.1.1            gtools_3.8.1              MASS_7.3-50              
##  [49] zoo_1.8-2                 scales_1.0.0              colourpicker_1.0         
##  [52] hms_0.4.2                 promises_1.0.1            Brobdingnag_1.2-5        
##  [55] parallel_3.5.1            inline_0.3.15             shinystan_2.5.0          
##  [58] yaml_2.1.19               gridExtra_2.3             loo_2.0.0                
##  [61] StanHeaders_2.18.0-1      stringi_1.2.3             dygraphs_1.1.1.5         
##  [64] pkgbuild_1.0.2            rlang_0.3.1               pkgconfig_2.0.2          
##  [67] matrixStats_0.54.0        evaluate_0.10.1           lattice_0.20-35          
##  [70] bindr_0.1.1               rstantools_1.5.0          htmlwidgets_1.2          
##  [73] labeling_0.3              tidyselect_0.2.4          processx_3.2.1           
##  [76] plyr_1.8.4                magrittr_1.5              bookdown_0.7             
##  [79] R6_2.3.0                  generics_0.0.2            pillar_1.3.1             
##  [82] haven_1.1.2               withr_2.1.2               xts_0.10-2               
##  [85] abind_1.4-5               modelr_0.1.2              crayon_1.3.4             
##  [88] arrayhelpers_1.0-20160527 utf8_1.1.4                rmarkdown_1.10           
##  [91] grid_3.5.1                readxl_1.1.0              callr_3.1.0              
##  [94] threejs_0.3.1             digest_0.6.18             xtable_1.8-2             
##  [97] httpuv_1.4.4.2            stats4_3.5.1              munsell_0.5.0            
## [100] viridisLite_0.3.0         shinyjs_1.0&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Bayesian meta-analysis in brms</title>
      <link>/post/bayesian-meta-analysis/</link>
      <pubDate>Sun, 14 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/bayesian-meta-analysis/</guid>
      <description>&lt;p&gt;[edited Feb 27, 2019]&lt;/p&gt;
&lt;div id=&#34;preamble&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Preamble&lt;/h2&gt;
&lt;p&gt;I released the first &lt;a href=&#34;https://bookdown.org&#34;&gt;bookdown&lt;/a&gt; version of my &lt;a href=&#34;https://bookdown.org/connect/#/apps/1850/access&#34;&gt;&lt;em&gt;Statistical Rethinking&lt;/em&gt; with brms, ggplot2, and the tidyverse&lt;/a&gt; project a couple weeks ago. I consider it the 0.9.0 version. I wanted a little time to step back from the project before giving it a final edit for the first major edition. I also wanted to give others a little time to take a look and suggest edits, which some thankfully have.&lt;/p&gt;
&lt;p&gt;Now some time has passed, it’s become clear I’d like to add a bonus section on Bayesian meta-analysis. IMO, this is a natural extension of the hierarchical models McElreath introduced in chapter’s 12 and 13 of &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34;&gt;his text&lt;/a&gt; and of the measurement-error models he introduced in chapter 14. So the purpose of this post is to present a rough draft of how I’d like to introduce fitting meta-analyses with Bürkner’s great brms package.&lt;/p&gt;
&lt;p&gt;I intend to tack this section onto the end of chapter 14. If you have any &lt;a href=&#34;https://github.com/ASKurz/Statistical_Rethinking_with_brms_ggplot2_and_the_tidyverse/issues&#34;&gt;constrictive criticisms, please pass them along&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here’s the rough draft (which I updated on 2018-11-12):&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;rough-draft-meta-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Rough draft: Meta-analysis&lt;/h2&gt;
&lt;p&gt;If your mind isn’t fully blown by those measurement-error and missing-data models, let’s keep building. As it turns out, meta-analyses are often just special kinds of multilevel measurement-error models. Thus, you can use &lt;code&gt;brms::brm()&lt;/code&gt; to fit Bayesian meta-analyses, too.&lt;/p&gt;
&lt;p&gt;Before we proceed, I should acknowledge that this section is heavily influenced by Matti Vourre’s great blog post, &lt;a href=&#34;https://vuorre.netlify.com/post/2016/2016-09-29-bayesian-meta-analysis/&#34;&gt;&lt;em&gt;Meta-analysis is a special case of Bayesian multilevel modeling&lt;/em&gt;&lt;/a&gt;. And since McElreath’s text doesn’t directly address meta-analyses, we’ll take further inspiration from Gelman, Carlin, Stern, Dunson, Vehtari, and Rubin’s &lt;a href=&#34;http://www.stat.columbia.edu/~gelman/book/&#34;&gt;&lt;em&gt;Bayesian data analysis, Third edition&lt;/em&gt;&lt;/a&gt;. We’ll let Gelman and colleagues introduce the topic:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Discussions of meta-analysis are sometimes imprecise about the estimands of interest in the analysis, especially when the primary focus is on testing the null hypothesis of no effect in any of the studies to be combined. Our focus is on estimating meaningful parameters, and for this objective there appear to be three possibilities, accepting the overarching assumption that the studies are comparable in some broad sense. The first possibility is that we view the studies as identical replications of each other, in the sense we regard the individuals in all the studies as independent samples from a common population, with the same outcome measures and so on. A second possibility is that the studies are so different that the results of any one study provide no information about the results of any of the others. A third, more general, possibility is that we regard the studies as exchangeable but not necessarily either identical or completely unrelated; in other words we allow differences from study to study, but such that the differences are not expected &lt;em&gt;a priori&lt;/em&gt; to have predictable effects favoring one study over another.… This third possibility represents a continuum between the two extremes, and it is this exchangeable model (with unknown hyperparameters characterizing the population distribution) that forms the basis of our Bayesian analysis…&lt;/p&gt;
&lt;p&gt;The first potential estimand of a meta-analysis, or a hierarchically structured problem in general, is the mean of the distribution of effect sizes, since this represents the overall ‘average’ effect across all studies that could be regarded as exchangeable with the observed studies. Other possible estimands are the effect size in any of the observed studies and the effect size in another, comparable (exchangeable) unobserved study. (pp. 125—126, &lt;em&gt;emphasis&lt;/em&gt; in the original)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The basic version of a Bayesian meta-analysis follows the form&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_i \sim \text{Normal}(\theta_i, \sigma_i)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; = the point estimate for the effect size of a single study, &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;, which is presumed to have been a draw from a Normal distribution centered on &lt;span class=&#34;math inline&#34;&gt;\(\theta_i\)&lt;/span&gt;. The data in meta-analyses are typically statistical summaries from individual studies. The one clear lesson from this chapter is that those estimates themselves come with error and those errors should be fully expressed in the meta-analytic model. Which we do. The standard error from study &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; is specified &lt;span class=&#34;math inline&#34;&gt;\(\sigma_i\)&lt;/span&gt;, which is also a stand-in for the standard deviation of the Normal distribution from which the point estimate was drawn. Do note, we’re not estimating &lt;span class=&#34;math inline&#34;&gt;\(\sigma_i\)&lt;/span&gt;, here. Those values we take directly from the original studies.&lt;/p&gt;
&lt;p&gt;Building on the model, we further presume that study &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; is itself just one draw from a population of related studies, each of which have their own effect sizes. As such. we presume &lt;span class=&#34;math inline&#34;&gt;\(\theta_i\)&lt;/span&gt; itself has a distribution following the form&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\theta_i \sim \text{Normal} (\mu, \tau)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the meta-analytic effect (i.e., the population mean) and &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; is the variation around that mean, what you might also think of as &lt;span class=&#34;math inline&#34;&gt;\(\sigma_\tau\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Since there’s no example of a meta-analysis in the text, we’ll have to look elsewhere. We’ll focus on Gershoff and Grogan-Kaylor’s (2016) paper, &lt;a href=&#34;https://pdfs.semanticscholar.org/0d03/a2e9f085f0a268b4c0a52f5ac31c17a3e5f3.pdf&#34;&gt;&lt;em&gt;Spanking and Child Outcomes: Old Controversies and New Meta-Analyses&lt;/em&gt;&lt;/a&gt;. From their introduction, we read:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Around the world, most children (80%) are spanked or otherwise physically punished by their parents (&lt;a href=&#34;https://www.unicef.org/publications/index_74865.html&#34;&gt;UNICEF, 2014&lt;/a&gt;). The question of whether parents should spank their children to correct misbehaviors sits at a nexus of arguments from ethical, religious, and human rights perspectives both in the U.S. and around the world (&lt;a href=&#34;https://onlinelibrary.wiley.com/doi/abs/10.1111/cdep.12038&#34;&gt;Gershoff, 2013&lt;/a&gt;). Several hundred studies have been conducted on the associations between parents’ use of spanking or physical punishment and children’s behavioral, emotional, cognitive, and physical outcomes, making spanking one of the most studied aspects of parenting. What has been learned from these hundreds of studies? (p. 453)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Our goal will be to learn Bayesian meta-analysis by answering part of that question. I’ve transcribed the values directly from Gershoff and Grogan-Kaylor’s paper and saved them as a file called &lt;code&gt;spank.xlsx&lt;/code&gt;. You can find the data in &lt;a href=&#34;https://github.com/ASKurz/Statistical_Rethinking_with_brms_ggplot2_and_the_tidyverse&#34;&gt;this project’s GitHub repository&lt;/a&gt;. Let’s load them and &lt;code&gt;glimpse()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spank &amp;lt;- readxl::read_excel(&amp;quot;spank.xlsx&amp;quot;)

library(tidyverse)
glimpse(spank)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 111
## Variables: 8
## $ study   &amp;lt;chr&amp;gt; &amp;quot;Bean and Roberts (1981)&amp;quot;, &amp;quot;Day and Roberts (1983)&amp;quot;, &amp;quot;Mi…
## $ year    &amp;lt;dbl&amp;gt; 1981, 1983, 1971, 1988, 1990, 1961, 1962, 1990, 2002, 20…
## $ outcome &amp;lt;chr&amp;gt; &amp;quot;Immediate defiance&amp;quot;, &amp;quot;Immediate defiance&amp;quot;, &amp;quot;Immediate d…
## $ between &amp;lt;dbl&amp;gt; 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0,…
## $ within  &amp;lt;dbl&amp;gt; 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1,…
## $ d       &amp;lt;dbl&amp;gt; -0.74, 0.36, 0.34, -0.08, 0.10, 0.63, 0.19, 0.47, 0.14, …
## $ ll      &amp;lt;dbl&amp;gt; -1.76, -1.04, -0.09, -1.01, -0.82, 0.16, -0.14, 0.20, -0…
## $ ul      &amp;lt;dbl&amp;gt; 0.28, 1.77, 0.76, 0.84, 1.03, 1.10, 0.53, 0.74, 0.70, 0.…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this paper, the effect size of interest is a &lt;em&gt;Cohen’s d&lt;/em&gt;, derived from the formula&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[d = \frac{\mu_\text{treatment} - \mu_\text{comparison}}{\sigma_{pooled}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\sigma_{pooled} = \sqrt{\frac{((n_1 - 1) \sigma_1^2) + ((n_2 - 1) \sigma_2^2)}{n_1 + n_2 -2}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;To help make the equation for &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; clearer for our example, we might re-express it as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[d = \frac{\mu_\text{spanked} - \mu_\text{not spanked}}{\sigma_{pooled}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;McElreath didn’t really focus on effect sizes in his text. If you need a refresher, you might check out Kelley and Preacher’s &lt;a href=&#34;https://www.researchgate.net/profile/Ken_Kelley/publication/270757972_On_Effect_Size/links/0046351b0cd48217ce000000/On-Effect-Size.pdf&#34;&gt;&lt;em&gt;On effect size&lt;/em&gt;&lt;/a&gt;. But in words, &lt;em&gt;Cohen’s d&lt;/em&gt; is a standardized mean difference between two groups.&lt;/p&gt;
&lt;p&gt;So if you look back up at the results of &lt;code&gt;glimpse(spank)&lt;/code&gt;, you’ll notice the column &lt;code&gt;d&lt;/code&gt;, which is indeed a vector of &lt;em&gt;Cohen’s d&lt;/em&gt; effect sizes. The last two columns, &lt;code&gt;ll&lt;/code&gt; and &lt;code&gt;ul&lt;/code&gt; are the lower and upper limits of the associated 95% frequentist confidence intervals. But we don’t want confidence intervals for our &lt;code&gt;d&lt;/code&gt;-values; we want their standard errors. Fortunately, we can compute those with the following formula&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[SE = \frac{\text{upper limit } – \text{lower limit}}{3.92}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Here it is in code.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spank &amp;lt;-
  spank %&amp;gt;% 
  mutate(se = (ul - ll) / 3.92)

glimpse(spank)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 111
## Variables: 9
## $ study   &amp;lt;chr&amp;gt; &amp;quot;Bean and Roberts (1981)&amp;quot;, &amp;quot;Day and Roberts (1983)&amp;quot;, &amp;quot;Mi…
## $ year    &amp;lt;dbl&amp;gt; 1981, 1983, 1971, 1988, 1990, 1961, 1962, 1990, 2002, 20…
## $ outcome &amp;lt;chr&amp;gt; &amp;quot;Immediate defiance&amp;quot;, &amp;quot;Immediate defiance&amp;quot;, &amp;quot;Immediate d…
## $ between &amp;lt;dbl&amp;gt; 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0,…
## $ within  &amp;lt;dbl&amp;gt; 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1,…
## $ d       &amp;lt;dbl&amp;gt; -0.74, 0.36, 0.34, -0.08, 0.10, 0.63, 0.19, 0.47, 0.14, …
## $ ll      &amp;lt;dbl&amp;gt; -1.76, -1.04, -0.09, -1.01, -0.82, 0.16, -0.14, 0.20, -0…
## $ ul      &amp;lt;dbl&amp;gt; 0.28, 1.77, 0.76, 0.84, 1.03, 1.10, 0.53, 0.74, 0.70, 0.…
## $ se      &amp;lt;dbl&amp;gt; 0.52040816, 0.71683673, 0.21683673, 0.47193878, 0.471938…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now our data are ready, we can express our first Bayesian meta-analysis with the formula&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{eqnarray}
\text{d}_i &amp;amp; \sim &amp;amp; \text{Normal}(\theta_i, \sigma_i = \text{se}_i) \\
\theta_i &amp;amp; \sim &amp;amp; \text{Normal} (\mu, \tau) \\
\mu &amp;amp; \sim &amp;amp; \text{Normal} (0, 1) \\
\tau &amp;amp; \sim &amp;amp; \text{HalfCauchy} (0, 1)
\end{eqnarray}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The last two lines, of course, spell out our priors. In psychology, it’s pretty rare to see &lt;em&gt;Cohen’s d&lt;/em&gt;-values greater than the absolute value of &lt;span class=&#34;math inline&#34;&gt;\(\pm 1\)&lt;/span&gt;. So in the absence of more specific domain knowledge–which I don’t have–, it seems like &lt;span class=&#34;math inline&#34;&gt;\(\text{Normal} (0, 1)\)&lt;/span&gt; is a reasonable place to start. And just like McElreath used &lt;span class=&#34;math inline&#34;&gt;\(\text{HalfCauchy} (0, 1)\)&lt;/span&gt; as the default prior for the group-level standard deviations, &lt;a href=&#34;https://psyarxiv.com/7tbrm/&#34;&gt;it makes sense to use it here&lt;/a&gt; for our meta-analytic &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; parameter.&lt;/p&gt;
&lt;p&gt;Let’s load brms.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(brms)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s the code for the first model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b14.5 &amp;lt;- 
  brm(data = spank, family = gaussian,
      d | se(se) ~ 1 + (1 | study),
      prior = c(prior(normal(0, 1), class = Intercept),
                prior(cauchy(0, 1), class = sd)),
      iter = 2000, warmup = 1000, cores = 4, chains = 4,
      seed = 14)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;One thing you might notice is our &lt;code&gt;se(se)&lt;/code&gt; function excluded the &lt;code&gt;sigma&lt;/code&gt; argument. If you recall from section 14.1, we specified &lt;code&gt;sigma = T&lt;/code&gt; in our measurement-error models. The brms default is that within &lt;code&gt;se()&lt;/code&gt;, &lt;code&gt;sigma = FALSE&lt;/code&gt;. As such, we have no estimate for sigma the way we would if we were doing this analysis with the raw data from the studies. Hopefully this makes sense. The uncertainty around the &lt;code&gt;d&lt;/code&gt;-value for each study &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; has already been encoded in the data as &lt;code&gt;se&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;This brings us to another point. We typically perform meta-analyses on data summaries. In my field and perhaps in yours, this is due to the historical accident that it has not been the norm among researchers to make their data publically available. So effect size summaries were the best we typically had. However, times are changing (e.g., &lt;a href=&#34;https://www.apa.org/monitor/2017/11/trends-open-science.aspx&#34;&gt;here&lt;/a&gt;, &lt;a href=&#34;https://www.blog.google/products/search/making-it-easier-discover-datasets/&#34;&gt;here&lt;/a&gt;). If the raw data from all the studies for your meta-analysis are available, you can just fit a multilevel model in which the data are nested in the studies. Heck, you could even allow the studies to vary by &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; by taking the &lt;a href=&#34;https://cran.r-project.org/web/packages/brms/vignettes/brms_distreg.html#a-simple-distributional-model&#34;&gt;distributional modeling approach&lt;/a&gt; and specify something like &lt;code&gt;sigma ~ 0 + study&lt;/code&gt; or even &lt;code&gt;sigma ~ 1 + (1 | study)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;But enough technical talk. Let’s look at the model results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(b14.5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: d | se(se) ~ 1 + (1 | study) 
##    Data: spank (Number of observations: 111) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Group-Level Effects: 
## ~study (Number of levels: 76) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     0.26      0.03     0.21     0.33        703 1.01
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept     0.37      0.04     0.30     0.44        397 1.01
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Thus, in our simple Bayesian meta-analysis, we have a population &lt;em&gt;Cohen’s d&lt;/em&gt; of about 0.37. Our estimate for &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt;, 0.26, suggests we have quite a bit of between-study variability. One question you might ask is: &lt;em&gt;What exactly are these&lt;/em&gt; Cohen’s d&lt;em&gt;s measuring, anyways?&lt;/em&gt; We’ve encoded that in the &lt;code&gt;outcome&lt;/code&gt; vector of the &lt;code&gt;spank&lt;/code&gt; data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spank %&amp;gt;% 
  distinct(outcome) %&amp;gt;% 
  knitr::kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;outcome&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Immediate defiance&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Low moral internalization&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Child aggression&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Child antisocial behavior&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Child externalizing behavior problems&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Child internalizing behavior problems&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Child mental health problems&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Child alcohol or substance abuse&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Negative parent–child relationship&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Impaired cognitive ability&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Low self-esteem&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Low self-regulation&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Victim of physical abuse&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Adult antisocial behavior&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Adult mental health problems&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Adult alcohol or substance abuse&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Adult support for physical punishment&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;There are a few things to note. First, with the possible exception of &lt;code&gt;Adult support for physical punishment&lt;/code&gt;, all of the outcomes are negative. We prefer conditions associated with lower values for things like &lt;code&gt;Child aggression&lt;/code&gt; and &lt;code&gt;Adult mental health problems&lt;/code&gt;. Second, the way the data are coded, larger effect sizes are interpreted as more negative outcomes associated with children having been spanked. That is, our analysis suggests spanking children is associated with worse outcomes. What might not be immediately apparent is that even though there are 111 cases in the data, there are only 76 distinct studies.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spank %&amp;gt;% 
  distinct(study) %&amp;gt;% 
  count()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 1
##       n
##   &amp;lt;int&amp;gt;
## 1    76&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In other words, some studies have multiple outcomes. In order to better accommodate the &lt;code&gt;study&lt;/code&gt;- and &lt;code&gt;outcome&lt;/code&gt;-level variances, let’s fit a cross-classified Bayesian meta-analysis reminiscent of the cross-classified chimp model from Chapter 13.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b14.6 &amp;lt;- 
  brm(data = spank, family = gaussian,
      d | se(se) ~ 1 + (1 | study) + (1 | outcome),
      prior = c(prior(normal(0, 1), class = Intercept),
                prior(cauchy(0, 1), class = sd)),
      iter = 2000, warmup = 1000, cores = 4, chains = 4,
      seed = 14)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(b14.6)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: d | se(se) ~ 1 + (1 | study) + (1 | outcome) 
##    Data: spank (Number of observations: 111) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Group-Level Effects: 
## ~outcome (Number of levels: 17) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     0.08      0.03     0.04     0.14        950 1.00
## 
## ~study (Number of levels: 76) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     0.25      0.03     0.20     0.32        824 1.00
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept     0.35      0.04     0.27     0.44        654 1.01
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we have two &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; parameters. We might plot them to get a sense of where the variance is at.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posterior_samples(b14.6) %&amp;gt;% 
  select(starts_with(&amp;quot;sd&amp;quot;)) %&amp;gt;% 
  gather(key, tau) %&amp;gt;% 
  mutate(key = str_remove(key, &amp;quot;sd_&amp;quot;) %&amp;gt;% str_remove(., &amp;quot;__Intercept&amp;quot;)) %&amp;gt;% 
  
  ggplot(aes(x = tau, fill = key)) +
  geom_density(color = &amp;quot;transparent&amp;quot;, alpha = 2/3) +
  scale_fill_viridis_d(NULL, end = .85) +
  scale_y_continuous(NULL, breaks = NULL) +
  xlab(expression(tau)) +
  theme(panel.grid = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-10-14-bayesian-meta-analysis_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So at this point, the big story is there’s more variability between the studies than there is the outcomes. But I still want to get a sense of the individual outcomes. Here we’ll use &lt;code&gt;tidybayes::geom_halfeyeh()&lt;/code&gt; to help us make our version of a &lt;a href=&#34;https://cran.r-project.org/web/packages/forestplot/vignettes/forestplot.html&#34;&gt;forest plot&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# load tidybayes
library(tidybayes)

b14.6 %&amp;gt;%
  spread_draws(b_Intercept, r_outcome[outcome,]) %&amp;gt;%
  # add the grand mean to the group-specific deviations
  mutate(mu = b_Intercept + r_outcome) %&amp;gt;%
  ungroup() %&amp;gt;%
  mutate(outcome = str_replace_all(outcome, &amp;quot;[.]&amp;quot;, &amp;quot; &amp;quot;)) %&amp;gt;% 

  # plot
  ggplot(aes(x = mu, y = reorder(outcome, mu))) +
  geom_vline(xintercept = fixef(b14.6)[1, 1], color = &amp;quot;white&amp;quot;, size = 1) +
  geom_vline(xintercept = fixef(b14.6)[1, 3:4], color = &amp;quot;white&amp;quot;, linetype = 2) +
  geom_halfeyeh(.width = .95, size = 2/3) +
  labs(x = expression(italic(&amp;quot;Cohen&amp;#39;s d&amp;quot;)),
       y = NULL) +
  theme(panel.grid   = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y  = element_text(hjust = 0))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-10-14-bayesian-meta-analysis_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The solid and dashed vertical white lines in the background mark off the grand mean (i.e., the meta-analytic effect) and its 95% intervals. But anyway, there’s not a lot of variability across the outcomes. Let’s go one step further with the model. Doubling back to Gelman and colleagues, we read:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;When assuming exchangeability we assume there are no important covariates that might form the basis of a more complex model, and this assumption (perhaps misguidedly) is widely adopted in meta-analysis. What if other information (in addition to the data &lt;span class=&#34;math inline&#34;&gt;\((n, y)\)&lt;/span&gt;) is available to distinguish among the &lt;span class=&#34;math inline&#34;&gt;\(J\)&lt;/span&gt; studies in a meta-analysis, so that an exchangeable model is inappropriate? In this situation, we can expand the framework of the model to be exchangeable in the observed data and covariates, for example using a hierarchical regression model. (p. 126)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;One important covariate Gershoff and Grogan-Kaylor addressed in their meta-analysis was the type of study. The 76 papers they based their meta-analysis on contained both between- and within-participants designs. In the &lt;code&gt;spank&lt;/code&gt; data, we’ve dummy coded that information with the &lt;code&gt;between&lt;/code&gt; and &lt;code&gt;within&lt;/code&gt; vectors. Both are dummy variables and &lt;code&gt;within&lt;/code&gt; = 1 - &lt;code&gt;between&lt;/code&gt;. Here are the counts.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spank %&amp;gt;% 
  count(between)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 2
##   between     n
##     &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
## 1       0    71
## 2       1    40&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When I use dummies in my models, I prefer to have the majority group stand as the reference category. As such, I typically name those variables by the minority group. In this case, most occasions are based on within-participant designs. Thus, we’ll go ahead and add the &lt;code&gt;between&lt;/code&gt; variable to the model. While we’re at it, we’ll practice using the &lt;code&gt;0 + intercept&lt;/code&gt; syntax.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b14.7 &amp;lt;- 
  brm(data = spank, family = gaussian,
      d | se(se) ~ 0 + intercept + between + (1 | study) + (1 | outcome),
      prior = c(prior(normal(0, 1), class = b),
                prior(cauchy(0, 1), class = sd)),
      iter = 2000, warmup = 1000, cores = 4, chains = 4,
      seed = 14)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(b14.7)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: d | se(se) ~ 0 + intercept + between + (1 | study) + (1 | outcome) 
##    Data: spank (Number of observations: 111) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Group-Level Effects: 
## ~outcome (Number of levels: 17) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     0.08      0.02     0.04     0.14       1580 1.00
## 
## ~study (Number of levels: 76) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     0.25      0.03     0.20     0.32       1186 1.00
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## intercept     0.38      0.05     0.28     0.48       1052 1.00
## between      -0.08      0.07    -0.22     0.07        979 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a closer look at &lt;code&gt;b_between&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posterior_samples(b14.7) %&amp;gt;% 
  
  ggplot(aes(x = b_between, y = 0)) +
  geom_halfeyeh(point_interval = median_qi, .width = c(.5, .95)) +
  labs(x = &amp;quot;Overall difference for between- vs within-participant designs&amp;quot;,
       y = NULL) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid   = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-10-14-bayesian-meta-analysis_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;432&#34; /&gt;&lt;/p&gt;
&lt;p&gt;That difference isn’t as large I’d expect it to be. But then again, I’m no spanking researcher. So what do I know?&lt;/p&gt;
&lt;p&gt;There are other things you might do with these data. For example, you might check for trends by year or, as the authors did in their manuscript, distinguish among different severities of corporal punishment. But I think we’ve gone far enough to get you started.&lt;/p&gt;
&lt;p&gt;If you’d like to learn more about these methods, do check out Vourre’s &lt;a href=&#34;https://vuorre.netlify.com/post/2016/2016-09-29-bayesian-meta-analysis/&#34;&gt;&lt;em&gt;Meta-analysis is a special case of Bayesian multilevel modeling&lt;/em&gt;&lt;/a&gt;. From his blog, you’ll learn additional tricks, like making a more traditional-looking forest plot with the &lt;code&gt;brmstools::forest()&lt;/code&gt; function and how our Bayesian brms method compares with Frequentist meta-analyses via the &lt;a href=&#34;http://www.metafor-project.org/doku.php/metafor&#34;&gt;metafor package&lt;/a&gt;. You might also check out Williams, Rast, and Bürkner’s manuscript, &lt;a href=&#34;https://psyarxiv.com/7tbrm/&#34;&gt;&lt;em&gt;Bayesian Meta-Analysis with Weakly Informative Prior Distributions&lt;/em&gt;&lt;/a&gt; to give you an empirical justification for using a half-Cauchy prior for your meta-analysis &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; parameters.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;session-info&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Session info&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 3.5.1 (2018-07-02)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS High Sierra 10.13.6
## 
## Matrix products: default
## BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] tidybayes_1.0.3 brms_2.7.0      Rcpp_1.0.0      bindrcpp_0.2.2 
##  [5] forcats_0.3.0   stringr_1.3.1   dplyr_0.7.6     purrr_0.2.5    
##  [9] readr_1.1.1     tidyr_0.8.1     tibble_2.0.1    ggplot2_3.1.0  
## [13] tidyverse_1.2.1
## 
## loaded via a namespace (and not attached):
##   [1] colorspace_1.3-2          ggridges_0.5.0           
##   [3] rsconnect_0.8.8           rprojroot_1.3-2          
##   [5] ggstance_0.3              markdown_0.8             
##   [7] base64enc_0.1-3           rstudioapi_0.7           
##   [9] rstan_2.18.2              svUnit_0.7-12            
##  [11] DT_0.4                    fansi_0.4.0              
##  [13] mvtnorm_1.0-8             lubridate_1.7.4          
##  [15] xml2_1.2.0                bridgesampling_0.4-0     
##  [17] knitr_1.20                shinythemes_1.1.1        
##  [19] bayesplot_1.6.0           jsonlite_1.5             
##  [21] broom_0.5.1               shiny_1.1.0              
##  [23] compiler_3.5.1            httr_1.3.1               
##  [25] backports_1.1.2           assertthat_0.2.0         
##  [27] Matrix_1.2-14             lazyeval_0.2.1           
##  [29] cli_1.0.1                 later_0.7.3              
##  [31] htmltools_0.3.6           prettyunits_1.0.2        
##  [33] tools_3.5.1               igraph_1.2.1             
##  [35] coda_0.19-2               gtable_0.2.0             
##  [37] glue_1.3.0                reshape2_1.4.3           
##  [39] cellranger_1.1.0          nlme_3.1-137             
##  [41] blogdown_0.8              crosstalk_1.0.0          
##  [43] xfun_0.3                  ps_1.2.1                 
##  [45] rvest_0.3.2               mime_0.5                 
##  [47] miniUI_0.1.1.1            gtools_3.8.1             
##  [49] MASS_7.3-50               zoo_1.8-2                
##  [51] scales_1.0.0              colourpicker_1.0         
##  [53] hms_0.4.2                 promises_1.0.1           
##  [55] Brobdingnag_1.2-5         parallel_3.5.1           
##  [57] inline_0.3.15             shinystan_2.5.0          
##  [59] yaml_2.1.19               gridExtra_2.3            
##  [61] loo_2.0.0                 StanHeaders_2.18.0-1     
##  [63] stringi_1.2.3             highr_0.7                
##  [65] dygraphs_1.1.1.5          pkgbuild_1.0.2           
##  [67] rlang_0.3.1               pkgconfig_2.0.2          
##  [69] matrixStats_0.54.0        evaluate_0.10.1          
##  [71] lattice_0.20-35           bindr_0.1.1              
##  [73] rstantools_1.5.0          htmlwidgets_1.2          
##  [75] labeling_0.3              tidyselect_0.2.4         
##  [77] processx_3.2.1            plyr_1.8.4               
##  [79] magrittr_1.5              bookdown_0.7             
##  [81] R6_2.3.0                  generics_0.0.2           
##  [83] pillar_1.3.1              haven_1.1.2              
##  [85] withr_2.1.2               xts_0.10-2               
##  [87] abind_1.4-5               modelr_0.1.2             
##  [89] crayon_1.3.4              arrayhelpers_1.0-20160527
##  [91] utf8_1.1.4                rmarkdown_1.10           
##  [93] grid_3.5.1                readxl_1.1.0             
##  [95] callr_3.1.0               threejs_0.3.1            
##  [97] digest_0.6.18             xtable_1.8-2             
##  [99] httpuv_1.4.4.2            stats4_3.5.1             
## [101] munsell_0.5.0             viridisLite_0.3.0        
## [103] shinyjs_1.0&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Don&#39;t pay to meditate</title>
      <link>/post/dont-pay-to-meditate/</link>
      <pubDate>Sun, 07 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/dont-pay-to-meditate/</guid>
      <description>&lt;p&gt;The other day, my Twitter feed informed me Penn Jillette just clocked in 1000 consecutive days of meditation using the Headspace app. Now he’s considering checking out Sam Harris’s new Waking Up meditation app. Sam left a congratulatory comment on Penn’s tweet.&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Well done, Penn! &lt;a href=&#34;https://t.co/SZkKocIPEH&#34;&gt;https://t.co/SZkKocIPEH&lt;/a&gt;&lt;/p&gt;&amp;mdash; Sam Harris (@SamHarrisOrg) &lt;a href=&#34;https://twitter.com/SamHarrisOrg/status/1048730683940646914?ref_src=twsrc%5Etfw&#34;&gt;October 7, 2018&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;p&gt;The whole thing was rainbows and kittens. And it reminded me to pass on some advice: &lt;strong&gt;Stop using fee-based meditation apps!&lt;/strong&gt;&lt;/p&gt;
&lt;div id=&#34;what&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What?&lt;/h2&gt;
&lt;p&gt;The &lt;a href=&#34;https://www.headspace.com/headspace-meditation-app&#34;&gt;Headspace app&lt;/a&gt; is popular and highly-rated. It’s free to download and has some nice features, like reminders to meditate. However, if you want full access to its library of guided meditation audio recordings, you’ll need to pay a fee at a monthly, yearly, or lifetime rate.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/post/2018-10-07-dont-pay-to-meditate_files/HS_subscription.PNG&#34; style=&#34;width:33.0%&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;Sam Harris’s &lt;a href=&#34;https://wakingup.com/home-reviews/?_ga=2.267492553.617729158.1538952176-2137086923.1448849490&amp;amp;utm_expid=.4j5YZcqhSKSYqCMuOBBY-A.1&amp;amp;utm_referrer=https%3A%2F%2Fsamharris.org%2F&#34;&gt;Waking Up app&lt;/a&gt; app is also free to download. It’s new and, in fairness, we’ll have to wait and see how its format will unfold. But at present it has more of a course-type format. The free version gives you access to five guided meditations and three lessons. But if you want full access to the app’s content, you also have to subscribe.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/post/2018-10-07-dont-pay-to-meditate_files/WU_subscribe.jpg&#34; style=&#34;width:33.0%&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;I have no problem with the Headspace and Waking Up apps. They have many fine features. And I’m even a fan of a lot Harris’s work. But we have a cheaper, high-quality option:&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;consider-insight-timer&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Consider &lt;a href=&#34;https://insighttimer.com&#34;&gt;Insight Timer&lt;/a&gt;&lt;/h2&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/post/2018-10-07-dont-pay-to-meditate_files/IT_bowl.png&#34; style=&#34;width:50.0%&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;&lt;a href=&#34;https://insighttimer.com&#34;&gt;Insight Timer&lt;/a&gt; comes with a free and pay versions, too. But just download the free version. It’s excellent and all you need for your meditation needs. Let me list the reasons why.&lt;/p&gt;
&lt;div id=&#34;the-free-library-is-extensive.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The free library is extensive.&lt;/h3&gt;
&lt;p&gt;At the time of this writing, my free subscription to Insight Timer gives me access to some 12,000 guided meditation audios. Most of them are in English. But many are offered in other languages, such as Hebrew, Malay, and Spanish.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/post/2018-10-07-dont-pay-to-meditate_files/IT_languages.jpg&#34; style=&#34;width:33.0%&#34; /&gt;

&lt;/div&gt;
&lt;div id=&#34;duration.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Duration.&lt;/h4&gt;
&lt;p&gt;Their durations vary. The bulk of the guided meditations seem to be in the 5-to-20-minute range. But some last more than an hour.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/post/2018-10-07-dont-pay-to-meditate_files/IT_duration.PNG&#34; style=&#34;width:33.0%&#34; /&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;people-and-their-voices.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;People and their voices.&lt;/h4&gt;
&lt;p&gt;Insight Timer’s deep library boasts an impressive cast of meditation teachers. I was happy to see some familiar high-profile meditation teachers, such as Tara Brach and Joseph Goldstein. But I have also discovered new favorites, like Stephen Pende Wormland and Dawn Mauricio. To be sure, the quality of the audio recordings varies. But more importantly, they also vary in terms of vocal tone and pacing. There should be a vocal style to suit just about everyone.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/post/2018-10-07-dont-pay-to-meditate_files/IT_teachers.PNG&#34; style=&#34;width:33.0%&#34; /&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;emphasis.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Emphasis.&lt;/h4&gt;
&lt;p&gt;I’m an academic and generally prefer meditations that are secular and connected to the clinical literature (e.g., &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0272735817303847?via%3Dihub&#34;&gt;this recent meta-analysis&lt;/a&gt;). Happily, the Insight Timer library contains offerings based on mindfulness-based stress reduction (&lt;a href=&#34;https://www.umassmed.edu/cfm/mindfulness-based-programs/mbsr-courses/about-mbsr/history-of-mbsr/&#34;&gt;MBSR&lt;/a&gt;) and its derivatives (e.g., &lt;a href=&#34;http://www.mbct.com&#34;&gt;mindfulness-based cognitive therapy&lt;/a&gt;, &lt;a href=&#34;https://www.mindfulrp.com&#34;&gt;mindfulness-based relapse prevention&lt;/a&gt;).&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/post/2018-10-07-dont-pay-to-meditate_files/IT_mindfulness.PNG&#34; style=&#34;width:33.0%&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;But you can also find meditations grounded within a number of faith traditions.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/post/2018-10-07-dont-pay-to-meditate_files/IT_faith.PNG&#34; style=&#34;width:33.0%&#34; /&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;music.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Music.&lt;/h4&gt;
&lt;p&gt;I’ve focused mainly on vocally-driven meditations. However, Insight Timer also contains music/sound-based recordings. I’m partial to recordings featuring Tibetan singing bowls.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/post/2018-10-07-dont-pay-to-meditate_files/IT_bowls.PNG&#34; style=&#34;width:33.0%&#34; /&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;its-a-timer-too.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;It’s a timer, too.&lt;/h3&gt;
&lt;p&gt;Sometimes you just want a silent meditation. For those occasions, Insight Timer offers a nice timer feature. You can set it like a stopwatch to whatever duration you prefer, and choose among an array of sounds to mark the beginning and end of your sit.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/post/2018-10-07-dont-pay-to-meditate_files/IT_timer.PNG&#34; style=&#34;width:33.0%&#34; /&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;it-tracks.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;It tracks.&lt;/h3&gt;
&lt;p&gt;If you go to the Profile section of the app, you’ll discover it keeps track of your use and displays various summaries in attractive bar plots.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/post/2018-10-07-dont-pay-to-meditate_files/IT_track.PNG&#34; style=&#34;width:33.0%&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;[And yes, I generally agree with Richard McElreath: “The only problem with barplots is that they have bars” (p. 203, &lt;a href=&#34;https://bookdown.org/connect/#/apps/1850/access&#34;&gt;&lt;em&gt;Statistical Rethinking&lt;/em&gt;&lt;/a&gt;). You can’t have everything.]&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;insight-timer-is-great-for-researchers&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Insight Timer is great for researchers&lt;/h2&gt;
&lt;p&gt;Insight Timer allows you to download your data as a CSV file, which you can keep for yourself or email to others. Over the years, I’ve used the app to run group meditations within my research protocols. Since I selected the audios from the app, it allowed me to standardize the instructions across meditation sessions. Although my research assistants and I used the app on our phones to play the audios, our participants would use the timer functions on the apps on their phones to record their sessions. This gave us duplicate attendance records: one on a sign-in sheet and another on their phones. In longitudinal studies, participants could use the app on their own time and each of those sessions were recorded in the app. At the end of our studies, we were then able to download their use records as CSV files ready for pre-analysis data wrangling.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parting-thoughts&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Parting thoughts&lt;/h2&gt;
&lt;p&gt;Insight Timer has other functions, such as social networking and dharma talks. I just don’t care about those things, so you can learn about them on your own. But if you’re interested in learning about meditation or even if you’re a veteran meditator looking for a convenient app to augment your practice with, do consider Insight Timer. There’s no reason to spend your money on the alternatives before you capitalize on such a powerful resource that’s available to you for free.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>bookdown, My Process</title>
      <link>/post/how-bookdown/</link>
      <pubDate>Thu, 04 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/how-bookdown/</guid>
      <description>&lt;div id=&#34;tldr&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;tl;dr&lt;/h2&gt;
&lt;p&gt;I just self-published a book-length version of my project &lt;a href=&#34;https://bookdown.org/connect/#/apps/1850/access&#34;&gt;&lt;em&gt;Statistical Rethinking&lt;/em&gt; with brms, ggplot2, and the tidyverse&lt;/a&gt;. By using Yihui Xie’s &lt;a href=&#34;https://bookdown.org&#34;&gt;bookdown package&lt;/a&gt;, I was able to do it for free. If you’ve never heard of it, bookdown enables &lt;a href=&#34;https://bookdown.org/rdpeng/rprogdatascience/history-and-overview-of-r.html#what-is-r&#34;&gt;R&lt;/a&gt; users to write books and other long-form articles with &lt;a href=&#34;https://rmarkdown.rstudio.com&#34;&gt;R Markdown&lt;/a&gt;. You can save your bookdown products in a variety of formats (e.g., PDF, HTML) and publish them in several ways, too. The purpose of this post is to give readers a sense of how I used bookdown to make my project. I propose there are three fundamental skill sets you need basic fluency in before playing with bookdown. Those three are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;R and R Studio,&lt;/li&gt;
&lt;li&gt;Scripts and R Markdown files, and&lt;/li&gt;
&lt;li&gt;Git and GitHub.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;start-with-r&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Start with &lt;a href=&#34;https://cran.r-project.org&#34;&gt;R&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;First things first. Since bookdown is a package for use in the R environment, you’re going to have to use R. If you’re unfamiliar with it, &lt;a href=&#34;https://bookdown.org/rdpeng/rprogdatascience/history-and-overview-of-r.html&#34;&gt;R is a freely-available programming language particularly well-suited for data analysis&lt;/a&gt;. If you’ve not used R before, learning how to self-publish books is a great incentive to start learning. But unless you already have a background in programming, I think bookdown is poorly-suited for novices. R newbies should check out Roger Peng’s &lt;a href=&#34;https://bookdown.org/rdpeng/rprogdatascience/&#34;&gt;&lt;em&gt;R Programming for Data Science&lt;/em&gt;&lt;/a&gt; or Grolemund and Wickham’s &lt;a href=&#34;http://r4ds.had.co.nz&#34;&gt;&lt;em&gt;R for Data Science&lt;/em&gt;&lt;/a&gt;. Both are freely available online and, as it would turn out, made with bookdown. Also, new users should be aware that although you can interact with R directly, there are a variety of other ways to interface with R. I recommend using &lt;a href=&#34;https://www.rstudio.com&#34;&gt;R Studio&lt;/a&gt;. You can find some nice reasons, &lt;a href=&#34;https://www.theanalysisfactor.com/the-advantages-of-rstudio/&#34;&gt;here&lt;/a&gt;. For basic instructions on how to install R and R Studio, you might start &lt;a href=&#34;http://r4ds.had.co.nz/introduction.html#prerequisites&#34;&gt;here&lt;/a&gt;. And if you prefer video tutorials to help you with the installation, just do a simple search in your favorite video-sharing website and several should pop up.&lt;/p&gt;
&lt;p&gt;Personally, I started using R—via R Studio—during the 2015/2016 winter break before taking a spring semester statistics course based around an R package. [In case you’re curious, it was a structural equation modeling course based around a &lt;a href=&#34;https://blogs.baylor.edu/rlatentvariable/&#34;&gt;text by Beaujean&lt;/a&gt; which featured the &lt;a href=&#34;http://lavaan.ugent.be&#34;&gt;lavaan package&lt;/a&gt;]. At the time, I was already familiar with structural equation modeling, so the course was a nice opportunity to learn R. In addition, I was concurrently enrolled in a course on multilevel modeling based on &lt;a href=&#34;http://gseacademic.harvard.edu/alda/&#34;&gt;Singer and Willet’s classic text&lt;/a&gt;. The professor of that course primarily used SAS to teach the material, but he was flexible and allowed me to do the work with R, instead. So that was my introduction to R–a semester of immersion in &lt;a href=&#34;https://twitter.com/search?q=%23rstats&amp;amp;src=typd&#34;&gt;#rstats&lt;/a&gt;. Here are some other &lt;a href=&#34;https://www.r-bloggers.com/the-5-most-effective-ways-to-learn-r/&#34;&gt;tips on how to learn R&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bookdown-uses-markdown&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;bookdown uses &lt;a href=&#34;https://daringfireball.net/projects/markdown/syntax&#34;&gt;Markdown&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;If you work with R through R Studio, you can do a handful of things through dropdowns. But really, if you’re going to be using R, you’re going to be coding. As it turns out, there are a variety of ways to code in R. One of the most basic ways is via the &lt;a href=&#34;https://support.rstudio.com/hc/en-us/articles/200404846-Working-in-the-Console&#34;&gt;console&lt;/a&gt;, which I’m not going to cover in any detail.&lt;/p&gt;
&lt;p&gt;The console is fine for quick operations, but you’re going to want to do most of your coding in some kind of a script. R Studio allows users to save and execute code in script files, which you can learn more about &lt;a href=&#34;http://r4ds.had.co.nz/workflow-scripts.html&#34;&gt;here&lt;/a&gt;. Basic script files are nice in that they allow you to both save and annotate your code.&lt;/p&gt;
&lt;p&gt;However, the annotation options in R Studio script files are limited. After using R Studio scripts for about a year, I learned about &lt;a href=&#34;https://rmarkdown.rstudio.com/r_notebooks&#34;&gt;R Notebooks&lt;/a&gt;. These are special files that allow you to intermingle your R code with prose and the results of the code. R Notebooks also allow users to transform the working documents into professional-looking reports in various formats (e.g., PDF, HTML). And unlike the primitive annotation options with simple script files, R Notebooks use Markdown to allow users to format their prose with things like headers, italicized font, insert hyperlinks, and even embed images. So &lt;a href=&#34;https://daringfireball.net/projects/markdown/&#34;&gt;Markdown&lt;/a&gt;, then, is a simple language that allows for many of those functions.&lt;/p&gt;
&lt;p&gt;Within the R Studio environment, you can use Markdown with two basic file types: &lt;a href=&#34;https://rmarkdown.rstudio.com/lesson-1.html&#34;&gt;R Markdown&lt;/a&gt; files and &lt;a href=&#34;https://rmarkdown.rstudio.com/r_notebooks&#34;&gt;R Notebook&lt;/a&gt; files. R Notebook files are just special kinds of R Markdown files that have, IMO, a better interface. That is, R Notebooks are the newer nicer version of R Markdown files. The main point here is that when I say “bookdown uses Markdown”, I’m pointing out that one of the important skills you’ll want to develop before making content with bookdown is how to use Markdown within R Studio. It’s not terribly complicated to learn, and you can get an overview of the basics &lt;a href=&#34;https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf&#34;&gt;here&lt;/a&gt; or &lt;a href=&#34;http://r4ds.had.co.nz/r-markdown.html&#34;&gt;here&lt;/a&gt; or &lt;a href=&#34;https://bookdown.org/yihui/bookdown/markdown-syntax.html&#34;&gt;here&lt;/a&gt;, or an exhaustive treatment &lt;a href=&#34;https://bookdown.org/yihui/rmarkdown/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you’re a novice, it’ll take you a few days, weeks, or months to get a firm grasp of R. Not so with R Markdown files. You’ll have the basics of those down in an afternoon. That said, I had been an R Notebook user for more than a year before trying my hand at bookdown.&lt;/p&gt;
&lt;p&gt;The first big edition of my &lt;a href=&#34;https://bookdown.org/connect/#/apps/1850/access&#34;&gt;&lt;em&gt;Statistical Rethinking&lt;/em&gt; with brms, ggplot2, and the tidyverse&lt;/a&gt; project came in the form of R Notebook files and their HTML counterparts stored in one of my projects on the &lt;a href=&#34;https://osf.io/?gclid=EAIaIQobChMI2ZDP9svj3QIVQ7nACh2rYQIHEAAYASAAEgL7avD_BwE&#34;&gt;Open Science Framework&lt;/a&gt;. I don’t update it very often, but you can still find it &lt;a href=&#34;https://osf.io/97t6w/&#34;&gt;here&lt;/a&gt;. If you’re not familiar with it, the OSF is a &lt;a href=&#34;https://osf.io/4znzp/wiki/home/&#34;&gt;“free, open source web application that connects and supports the research workflow, enabling scientists to increase the efficiency and effectiveness of their research.”&lt;/a&gt; In addition to their wiki, you might check out some of their &lt;a href=&#34;https://cos.io/our-services/training-services/cos-training-tutorials/&#34;&gt;video tutorials&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;youll-need-github-too&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;You’ll need &lt;a href=&#34;https://github.com&#34;&gt;GitHub&lt;/a&gt;, too&lt;/h2&gt;
&lt;p&gt;I’m actually not sure whether you need to know how to use Git and GitHub to use bookdown. In his authoritative book, &lt;a href=&#34;https://bookdown.org/yihui/bookdown/&#34;&gt;&lt;em&gt;bookdown: Authoring Books and Technical Documents with R Markdown&lt;/em&gt;&lt;/a&gt;, Yihui Xie mentioned GitHub in every chapter. If you go to your favorite video-sharing website to look for instructional videos on bookdown, you’ll see the instructors take GitHub as a given, too. If you’re stubborn and have enough ingenuity, you might find a way to successfully use bookdown without GitHub, but you may as well go with the flow on this one.&lt;/p&gt;
&lt;p&gt;If you’ve never heard of it before, &lt;a href=&#34;https://git-scm.com/book/en/v2/Getting-Started-About-Version-Control&#34;&gt;Git is a system for version control&lt;/a&gt;. By version control, I mean a system by which you can keep track of changes to your code, over time. Even if you don’t have a background in programming, consider a scenario where you had to keep track of many versions of a writing project, perhaps saving your files as &lt;code&gt;first_draft.docx&lt;/code&gt;, &lt;code&gt;second_draft.docx&lt;/code&gt;, &lt;code&gt;final_draft.docx&lt;/code&gt;, &lt;code&gt;final_draft_2.docx&lt;/code&gt;… This was your own make-shift attempt at version control for writing. I’ve seen a lot of introductory material recommend Git and GitHub by leading with version control. And indeed, they do serve that purpose. But IMO, leading with version control is a rhetorical mistake when talking to non-programmers. I haven’t found Git and GitHub the most intuitive and if version control was the only benefit, they wouldn’t be worth the effort. But there are other good reasons to learn.&lt;/p&gt;
&lt;p&gt;IMO, the best reason to learn Git and GitHub is because they allow you to make your work publically available. When you just use Git, the work stays on your computer. But GitHub allows you to save your files online, too. This makes it easy for others to review them and give you feedback. GitHub also allows you to save things like data files online. So if you’re a working scientist, Git and GitHub might allow you to make a site—a repository—to house the de-identified data and statistical code for one of your projects. It’s another way to do open science. In addition, you can repurpose GitHub to work as blog or an analytic portfolio. And if you’d like to use bookdown, Git and GitHub will be a part of how you manage the files for your projects and make your work more accessible to others.&lt;/p&gt;
&lt;p&gt;If you’re new to all this, you could probably blindly follow along with the steps in Yihui Xie’s bookdown &lt;a href=&#34;https://bookdown.org/yihui/bookdown/&#34;&gt;manual&lt;/a&gt; or any of the online video tutorials. But I suspect that’d be pretty confusing. Before attempting a bookdown project, spend some time getting comfortable with Git and GitHub, first. The best introduction to the topic I’ve seen is Jenny Bryan’s &lt;a href=&#34;http://happygitwithr.com&#34;&gt;&lt;em&gt;Happy Git and GitHub for the useR&lt;/em&gt;&lt;/a&gt;, which, you guessed it, is also freely available and powered by bookdown.&lt;/p&gt;
&lt;p&gt;As I hinted, I found Git and GitHub baffling, at first. I checked out a few online video tutorials, but found them of little help. It really was Bryan’s &lt;a href=&#34;http://happygitwithr.com&#34;&gt;book&lt;/a&gt; that finally got me going. And I’m glad I did. I’ve been slowly working with GitHub for about a year—here’s &lt;a href=&#34;https://github.com/ASKurz&#34;&gt;my profile&lt;/a&gt;—and my first major project was putting together the files for the individual chapters in the &lt;a href=&#34;https://github.com/ASKurz/Statistical_Rethinking_with_brms_ggplot2_and_the_tidyverse&#34;&gt;Statistical_Rethinking_with_brms_ggplot2_and_the_tidyverse&lt;/a&gt; project. They originally lived as R Notebook files, eventually rendered in a &lt;a href=&#34;https://rmarkdown.rstudio.com/github_document_format.html&#34;&gt;GitHub-friendly .md file format&lt;/a&gt;. After a while, I started playing around with &lt;code&gt;README&lt;/code&gt;-only projects, which are basically a poor man’s GitHub version of blog posts (e.g., check out &lt;a href=&#34;https://github.com/ASKurz/James-Stein-and-Bayesian-partial-pooling&#34;&gt;this one&lt;/a&gt;). For me, and probably for your future bookdown projects, the most important GitHub skills to learn are commits, pushes, and forkes.&lt;/p&gt;
&lt;p&gt;I’d fooled around with GitHub a tiny bit before launching my &lt;a href=&#34;https://bookdown.org/connect/#/apps/1850/access&#34;&gt;&lt;em&gt;Statistical Rethinking&lt;/em&gt; with brms, ggplot2, and the tidyverse&lt;/a&gt; project on the OSF. But it was confusing and after an hour or two of trying to make sense of it, I gave up and just figured the OSF would be good enough. After folks started noticing the project, I got a few comments that it’d be more accessible on GitHub. That was what finally influenced me to buckle down learn it in earnest. I’m still a little clunky with it, but I’m functional enough to do things like &lt;a href=&#34;https://bookdown.org/yihui/blogdown/&#34;&gt;make this blog&lt;/a&gt;. With a little patience and practice, you can get there, too.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;let-yihui-xie-guide-you&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Let Yihui Xie guide you&lt;/h2&gt;
&lt;p&gt;So far we’ve covered&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;R and R Studio&lt;/li&gt;
&lt;li&gt;Scripts and R Markdown files&lt;/li&gt;
&lt;li&gt;Git and GitHub&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You don’t have become an expert, but you’ll need to become roughly fluent in all three to make good use of bookdown. Basically, if you are able to load data into R, document a rudimentary analysis in an R Notebook file, and then share the project in a non-embarrassing way in GitHub, you’re ready to use bookdown.&lt;/p&gt;
&lt;p&gt;I’ve already mentioned it, but the authoritative work on bookdown is Yihui Xie’s &lt;a href=&#34;https://bookdown.org/yihui/bookdown/&#34;&gt;&lt;em&gt;bookdown: Authoring Books and Technical Documents with R Markdown&lt;/em&gt;&lt;/a&gt;. Yihui Xie, of course, is the author of the package. It’s probably best to just start there, going bit by bit. He also gave an RStudio webinar, &lt;a href=&#34;https://www.youtube.com/watch?v=dVqVscgwSpw&amp;amp;t=12s&#34;&gt;&lt;em&gt;Authoring Books with R Markdown&lt;/em&gt;&lt;/a&gt;, which I found to be a helpful supplement.&lt;/p&gt;
&lt;p&gt;The complete version of my &lt;a href=&#34;https://bookdown.org/connect/#/apps/1850/access&#34;&gt;&lt;em&gt;Statistical Rethinking&lt;/em&gt; with brms, ggplot2, and the tidyverse&lt;/a&gt; project has 15 chapters and several preamble sections. Almost all the chapters files include a lot of computationally-intensive code, with the simulations for chapter 6 taking multiple hours to compute. I do not recommend starting off with a project like that, at least not all at once. If you follow along with Yihui Xie’s guide, you’ll practice stitching together simple files, first. After learning those basics, I then picked up other helpful tricks, like &lt;a href=&#34;https://bookdown.org/yihui/bookdown/preview-a-chapter.html#&#34;&gt;caching analyses&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Although I didn’t use these resources while I was learning bookdown, you might also benefit from checking out&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sean Kross’s &lt;a href=&#34;http://seankross.com/2016/11/17/How-to-Start-a-Bookdown-Book.html&#34;&gt;&lt;em&gt;How to Start a Bookdown Book&lt;/em&gt;&lt;/a&gt;,&lt;/li&gt;
&lt;li&gt;Karl Broman’s &lt;a href=&#34;https://kbroman.org/blog/2017/05/31/omg-bookdown/&#34;&gt;&lt;em&gt;omg, bookdown!&lt;/em&gt;&lt;/a&gt;,&lt;/li&gt;
&lt;li&gt;Rachael Lappan’s &lt;a href=&#34;https://rachaellappan.github.io/bookdown/&#34;&gt;&lt;em&gt;Using Bookdown for tidy documentation&lt;/em&gt;&lt;/a&gt;, or&lt;/li&gt;
&lt;li&gt;Pablo Casas’s &lt;a href=&#34;https://blog.datascienceheroes.com/how-to-self-publish-a-book/&#34;&gt;&lt;em&gt;How to self-publish a book: A handy list of resources&lt;/em&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Example Page</title>
      <link>/tutorial/example/</link>
      <pubDate>Sun, 09 Sep 2018 00:00:00 -0500</pubDate>
      
      <guid>/tutorial/example/</guid>
      <description>

&lt;p&gt;In this tutorial, I&amp;rsquo;ll share my top 10 tips for getting started with Academic:&lt;/p&gt;

&lt;h2 id=&#34;tip-1&#34;&gt;Tip 1&lt;/h2&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;

&lt;h2 id=&#34;tip-2&#34;&gt;Tip 2&lt;/h2&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Privacy Policy</title>
      <link>/privacy/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 -0500</pubDate>
      
      <guid>/privacy/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>/slides/example-slides/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/slides/example-slides/</guid>
      <description>

&lt;h1 id=&#34;welcome-to-slides&#34;&gt;Welcome to Slides&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://sourcethemes.com/academic/&#34; target=&#34;_blank&#34;&gt;Academic&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;

&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Code block:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
    print(&amp;quot;Eating...&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;

&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;

&lt;p&gt;Block math:&lt;/p&gt;

&lt;p&gt;$$
f\left( x \right) = \;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;

&lt;p&gt;Make content appear incrementally&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;

&lt;p&gt;&lt;span class=&#34;fragment &#34; &gt;
  One
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
  &lt;strong&gt;Two&lt;/strong&gt;
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
  Three
&lt;/span&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;

&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;

&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;


&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/img/boards.jpg&#34;
  &gt;


&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;

&lt;p&gt;Customize the slide style and background&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; slide background-image=&amp;quot;/img/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;

&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.reveal section h1,
.reveal section h2,
.reveal section h3 {
  color: navy;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://discourse.gohugo.io&#34; target=&#34;_blank&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://sourcethemes.com/academic/docs/&#34; target=&#34;_blank&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
