---
title: Bayesian robust correlations with brms (and why you should love Student’s $t$)
author: A. Solomon Kurz
date: '2019-02-10'
slug: bayesian-robust-correlations-with-brms-and-why-you-should-love-student-s-t
categories: []
tags:
  - Bayesian
  - brms
  - outlier
  - R
  - robust
  - tutorial
header:
  caption: ''
  image: ''
---

In this post, we'll show how Student's $t$-distribution can produce better correlation estimates when your data have outliers. As is often the case, we'll do so as Bayesians.

This post is a direct consequence of Adrian Baez-Ortega's great blog, "[Bayesian robust correlation with Stan in R (and why you should use Bayesian methods)](https://baezortega.github.io/2018/05/28/robust-correlation/)". Baez-Ortega worked out the approach and code for direct use with [Stan](http://mc-stan.org) computational environment. That solution is great because Stan is free, open source, and very flexible. However, Stan's interface might be prohibitively technical for non-statistician users. Happily, the [brms](https://github.com/paul-buerkner/brms) package allows users to access the computational power of Stan through a simpler interface. In this post, we show how to extend Baez-Ortega's method to brms. To pay respects where they're due, the synthetic data, priors, and other model settings are largely the same as those Baez-Ortega used in his blog.

## I make assumptions

For this post, I’m presuming you are vaguely familiar with linear regression, know about the basic differences between frequentist and Bayesian approaches to fitting models, and have a sense that the issue of outlier values is a pickle worth contending with. All code in is [R](https://www.r-bloggers.com/why-use-r-five-reasons/), with a heavy use of the [tidyverse](http://style.tidyverse.org)--which you might learn a lot about [here, especially chapter 5](http://r4ds.had.co.nzhttp://r4ds.had.co.nz)--, and, of course, Bürkner's [brms](https://github.com/paul-buerkner/brms).

If you’d like a warmup, consider checking out my related post, [Robust Linear Regression with Student's $t$-Distribution](https://solomonkurz.netlify.com/post/robust-linear-regression-with-the-robust-student-s-t-distribution/).

## What's the deal?

Pearson's correlations are designed to quantify the linear relationship between two normally distributed variables. The normal distribution and its multivariate generalization, the multivariate normal distribution, are sensitive to outliers. When you have well-behaved synthetic data, this isn't an issue. But if you work real-world data, this can be a problem. One can have data for which the vast majority of cases are well-characterized by a nice liner relationship, but have a few odd cases for which that relationship does not hold. And if those odd cases happen to be overly influential--sometimes called leverage points--the resulting Pearson's correlation coefficient might look off.

Recall that the normal distribution is a special case of Student's $t$-distribution with the $\nu$ parameter (i.e., *nu*, degree of freedom) set to infinity. As it turns out, when $\nu$ is small, Student's $t$-distribution is more robust to multivariate outliers. It's less influenced by them. I'm not going to cover why in any detail. For that you've got [Baez-Ortega's blog](https://baezortega.github.io/2018/05/28/robust-correlation/), an even earlier blog from [Rasmus Bååth](http://www.sumsar.net/blog/2013/08/bayesian-estimation-of-correlation/), and textbook treatments on the topic by [Gelman & Hill (2007, chapter 6)](http://www.stat.columbia.edu/~gelman/arm/) and [Kruschke (2014, chapter 16)](https://sites.google.com/site/doingbayesiandataanalysis/). Here we'll get a quick sense of how vulnerable Pearson's correlations--with their reliance on the Gaussian--are to outliers, we'll demonstrate how fitting correlations within the Bayesian paradigm using the conventional Gaussian likelihood is similarly vulnerable to distortion, and then see how Student's $t$-distribution can save the day. And importantly, we'll do the bulk of this with the brms package.

## We need data

To start off, we'll make a multivariate normal simulated data set using the same steps Baez-Ortega's used.

```{r, message = F, warning = F}
library(mvtnorm)
library(tidyverse)

sigma <- c(20, 40)  # the variances
rho   <- -.95       # the desired correlation

# here's the variance/covariance matrix
cov.mat <- 
  matrix(c(sigma[1] ^ 2,
           sigma[1] * sigma[2] * rho,
           sigma[1] * sigma[2] * rho,
           sigma[2] ^ 2),
         nrow = 2, byrow = T)

# after setting our seed, we're ready to simulate with `rmvnorm()`
set.seed(210191)
x.clean <- 
  rmvnorm(n = 40, sigma = cov.mat) %>% 
  as_tibble() %>% 
  rename(x = V1,
         y = V2)
```

Here we make our second data set, `x.noisy`, which is identical to our well-behaved `x.clean` data, but with the first three cases transformed to outlier values.

```{r}
x.noisy <- x.clean

x.noisy[1:3,] <-
  matrix(c(-40, -60,
           20, 100,
           40, 40),
         nrow = 3, byrow = T)
```

Finally, we'll add an `outlier` index to the data sets, which will help us with plotting.

```{r}
x.clean <-
  x.clean %>% 
  mutate(outlier = factor(0))

x.noisy <- 
  x.noisy %>% 
  mutate(outlier = c(rep(1, 3), rep(0, 37)) %>% as.factor(.))
```

The plot below shows what the `x.clean` data look like. I'm a fan of [FiveThirtyEight](http://fivethirtyeight.com), so we'll use a few convenience functions from the handy [ggthemes package](https://github.com/jrnold/ggthemes) to give our plots a FiveThirtyEight-like feel. 

```{r, fig.width = 3.25, fig.height = 3, warning = F, message = F}
library(ggthemes)

x.clean %>% 
  ggplot(aes(x = x, y = y, color = outlier, fill = outlier)) +
  geom_point() +
  stat_ellipse(geom = "polygon", alpha = .15, size = .15, level = .5) +
  stat_ellipse(geom = "polygon", alpha = .15, size = .15, level = .95) +
  scale_color_fivethirtyeight() +
  scale_fill_fivethirtyeight() +
  coord_cartesian(xlim = -50:50,
                  ylim = -100:100) +
  theme_fivethirtyeight() +
  theme(legend.position = "none")
```

And here are the `x.noisy` data.

```{r, fig.width = 3.25, fig.height = 3, warning = F, message = F}
x.noisy %>% 
  ggplot(aes(x = x, y = y, color = outlier, fill = outlier)) +
  geom_point() +
  stat_ellipse(geom = "polygon", alpha = .15, size = .15, level = .5) +
  stat_ellipse(geom = "polygon", alpha = .15, size = .15, level = .95) +
  scale_color_fivethirtyeight() +
  scale_fill_fivethirtyeight() +
  coord_cartesian(xlim = -50:50,
                  ylim = -100:100) +
  theme_fivethirtyeight() +
  theme(legend.position = "none")
```

The three outliers are in red. Even in their presence, the old interocular trauma test suggests there is a pronounced overall trend in the data. I would like a correlation procedure that's capable of capturing that overall trend. Let's examine some candidates.

## How does old Pearson hold up?

A quick way to get a Pearson's correlation coefficient in R is with the `cor()` function, which does a nice job recovering the correlation we simulated the `x.clean` data with:

```{r}
cor(x.clean$x, x.clean$y)
```

However, things fall apart if you use `cor()` on the `x.noisy` data.

```{r}
cor(x.noisy$x, x.noisy$y)
```

So even though most of the `x.noisy` data continue to show a clear strong relation, three outlier values reduced the Pearson's correlation a third of the way toward zero. Let's see what happens when we go Bayesian.

## Bayesian correlations in brms

[Bürkner](https://twitter.com/paulbuerkner)'s brms is a general purpose interface for fitting all manner of Bayesian regression models with [Stan](https://mc-stan.org) as the engine under the hood. It has popular [lme4](https://cran.r-project.org/web/packages/lme4/index.html)-like syntax and offers a variety of convenience functions for post processing. Let's load it up.

```{r, message = F, results = 'hide'}
library(brms)
```

### First with the Gaussian likelihood.

I’m not going to spend a lot of time walking through the syntax in the main brms function, `brm()`. You can learn all about that [here](https://github.com/paul-buerkner/brms) or with my project [*Statistical Rethinking with brms, ggplot2, and the tidyverse*](https://github.com/ASKurz/Statistical_Rethinking_with_brms_ggplot2_and_the_tidyverse#statistical-rethinking-with-brms-ggplot2-and-the-tidyverse). But our particular use of `brm()` requires we make a few fine points.

One doesn’t always think about bivariate correlations within the regression paradigm. But they work just fine. Within brms, you would typically specify the conventional Gaussian likelihood (i.e., `family = gaussian`), use the `cbind()` syntax to set up a [multivariate model](https://cran.r-project.org/web/packages/brms/vignettes/brms_multivariate.html), and fit that model without predictors. For each variable specified in `cbind()`, you’ll estimate an intercept (i.e., mean, $\mu$) and sigma (i.e., $\sigma$, often called a residual variance). Since there are no predictors in the model, the residual variance is just the variance and the brms default for multivariate models is to allow the residual variances to covary. But since variances are parameterized in the standard deviation metric in brms, the residual variances and their covariance are *SD*s and their correlation, respectively. 

Here’s what it looks like in practice.

```{r f0, cache = T, message = F, results = 'hide'}
f0 <- 
  brm(data = x.clean, 
      family = gaussian,
      cbind(x, y) ~ 1,
      prior = c(prior(normal(0, 100), class = Intercept),
                prior(normal(0, 100), class = sigma, resp = x),
                prior(normal(0, 100), class = sigma, resp = y),
                prior(lkj(1), class = rescor)),
      iter = 2000, warmup = 500, chains = 4, cores = 4, 
      seed = 210191)
```

In a typical Bayesian workflow, you’d examine the quality of the chains with trace plots. The easy way to do that in brms is with `plot()`. E.g., to get the trace plots for our first model, you’d code `plot(f0)`. Happily, the trace plots look fine for all models in this post. For the sake of space, I’ll leave their inspection as exercises for interested readers.

Our priors and such mirror those in Baez-Ortega's blog. Here are the results.

```{r}
print(f0)
```

Way down there in the last line in the 'Family Specific Parameters' section we have `rescor(x,y)`, which is our correlation. And indeed, our Gaussian intercept-only multivariate model did a great job recovering the correlation we used to simulate the `x.clean` data with. Look at what happens when we try this approach with `x.noisy`.

```{r f1, cache = T, message = F, results = 'hide'}
f1 <-
  update(f0,
         newdata = x.noisy,
         iter = 2000, warmup = 500, chains = 4, cores = 4, seed = 210191)
```

```{r}
print(f1)
```

And the correlation estimate is `r posterior_summary(f1)["rescor__x__y", 1] %>% weights::rd(., digits = 2)`. As it turns out, `data = x.noisy` + `family = gaussian` in `brm()` failed us just like Pearson's correlation failed us. Time to leave failure behind.

### Now with Student's $t$-distribution.

Before we jump into using `family = student`, we should talk a bit about $\nu$. This is our new parameter which is silently fixed to infinity when we use the Gaussian likelihood. The $\nu$ parameter is bound at zero but, as discussed in Baez-Ortega's blog, is somewhat nonsensical for values below 1. As it turns out, $\nu$ is constrained to be equal to or greater than 1 in brms. So nothing for us to worry about, there. The [Stan team currently recommends the gamma(2, 0.1) prior for $\nu$](https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations), which is also the current brms default. This is what that distribution looks like.

```{r, fig.width = 10, fig.height = 2.5}
tibble(x = seq(from = 1, to = 120, by = .5)) %>% 
  ggplot(aes(x = x, fill = factor(0))) +
  geom_ribbon(aes(ymin = 0, 
                  ymax = dgamma(x, 2, 0.1))) +
  scale_y_continuous(NULL, breaks = NULL) +
  scale_fill_fivethirtyeight() +
  coord_cartesian(xlim = 0:100) +
  ggtitle("gamma(2, 0.1)") +
  theme_fivethirtyeight() +
  theme(legend.position = "none")
```

So gamma(2, 0.1) should gently push the $\nu$ posterior toward low values, but it’s slowly-sloping right tail will allow higher values to emerge.

Following the Stan team's recommendation, the brms default and Baez-Ortega's blog, here's our robust Student's $t$ model for the `x.noisy` data.

```{r f2, cache = T, message = F, results = 'hide'}
f2 <- 
  brm(data = x.noisy, 
      family = student,
      cbind(x, y) ~ 1,
      prior = c(prior(gamma(2, .1), class = nu),
                prior(normal(0, 100), class = Intercept),
                prior(normal(0, 100), class = sigma, resp = x),
                prior(normal(0, 100), class = sigma, resp = y),
                prior(lkj(1), class = rescor)),
      iter = 2000, warmup = 500, chains = 4, cores = 4, 
      seed = 210191)
```

```{r}
print(f2)
```

Whoa, look at that correlation, `rescore(x,y)`! It’s right about what we’d hope for. Sure, it's not a perfect -.95, but that's way better than `r posterior_summary(f1)["rescor__x__y", 1] %>% weights::rd(., digits = 2)`.

While we’re at it, we may as well see what happens when we fit a Student’s $t$ model when we have perfectly multivariate normal data. Here it is with the `x.clean` data.

```{r f3, cache = T, message = F, results = 'hide'}
f3 <- 
  update(f2,
         newdata = x.clean, 
         iter = 2000, warmup = 500, chains = 4, cores = 4, seed = 210191)
```

```{r}
print(f3)
```

So when you don't need Student's $t$, it yields the right answer anyways. That's a nice feature.

We should probably compare the posteriors of the correlations across the four models. First we’ll collect the posterior samples into a tibble.

```{r}
posts <-
  tibble(model = str_c("f", 0:3)) %>% 
  mutate(fit  = map(model, get)) %>% 
  mutate(post = map(fit, posterior_samples)) %>% 
  unnest(post)

head(posts)
```

With the posterior draws in hand, we just need to wrangle a bit before showing the correlation posteriors in a coefficient plot. To make things easier, we'll do so with a couple convenience functions from the [tidybayes](https://github.com/mjskay/tidybayes) package.

```{r, fig.width = 10, fig.height = 1.75, warning = F, message = F}
library(tidybayes)

# wrangle
posts %>% 
  group_by(model) %>% 
  median_qi(rescor__x__y, .width = c(.5, .95)) %>% 
  mutate(key = recode(model, 
                      f0 = "Gaussian likelihood with clean data",
                      f1 = "Gaussian likelihood with noisy data",
                      f2 = "Student likelihood with noisy data",
                      f3 = "Student likelihood with clean data"),
         clean = ifelse(model %in% c("f0", "f3"), "0", "1")) %>%
  
  # plot
  ggplot(aes(x = rescor__x__y, y = key, color = clean)) +
  geom_pointintervalh() +
  scale_color_fivethirtyeight() +
  coord_cartesian(xlim = -1:0) +
  labs(subtitle = expression(paste("The posterior for ", rho, " depends on the likelihood. Why not go robust and use Student's ", italic(t), "?"))) +
  theme_fivethirtyeight() +
  theme(axis.text.y     = element_text(hjust = 0),
        legend.position = "none")
```

From our `tidybayes::median_qi()` code, the dots are the posterior medians, the thick inner lines the 50% intervals, and the thinner outer lines the 95% intervals. The posteriors for the `x.noisy` data are in red and those for the `x.clean` data are in blue. If the data are clean multivariate normal Gaussian or if they’re dirty but fit with robust Student’s $t$, everything is pretty much alright. But whoa, if you fit a correlation with a combination of `family = gaussian` and noisy outlier-laden data, man that's just a mess.

Don't let a few overly-influential outliers make a mess of your analyses. Try the robust Student’s $t$.

```{r}
sessionInfo()
```

## Afterward: Why not explore more correlation options?

Late last night, it occurred to me we had other options to get correlations in brms. In order to explore them, we need to standardize our data. Here are two ways to standardize your data, one with the `scale()` function and the other by manually using the formula 

$$z_x_i = \frac{P(x_i = \overline x)}{\sigma_x}$$

```{r}
x.clean <-
  x.clean %>% 
  mutate(x_s = scale(x) %>% as.vector(),
         y_s = scale(y) %>% as.vector())

x.noisy <-
  x.noisy %>% 
  mutate(x_s = (x - mean(x)) / sd(x),
         y_s = (y - mean(y)) / sd(y))
```

There are at least two broad ways to get correlations out of standardized data in brms. One way uses the typical univariate syntax. The other way is an extension of the multivariate `cbind()` approach we used, above. We'll cover both.

### Start with univariate models.

If you fit a simple univariate model with a single predictor, the coefficient for the slope will be in a correlation metric. Here we do so with our `x.clean` data and the conventional Gaussian likelihood, as well as with the `x.noisy` data and a small-$\nu$ Student-$t$ likelihood.

Since the data are all standardized, it’s easier to use [regularizing priors](https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations). 

```{r f4, cache = T, message = F, results = 'hide'}
f4 <- 
  brm(data = x.clean, 
      family = gaussian,
      y_s ~ 1 + x_s,
      prior = c(prior(normal(0, 1), class = Intercept),
                prior(normal(0, 1), class = b),
                prior(normal(0, 1), class = sigma)),
      iter = 2000, warmup = 500, chains = 4, cores = 4, 
      seed = 210191)

f5 <- 
  brm(data = x.noisy, 
      family = student,
      y_s ~ 1 + x_s,
      prior = c(prior(gamma(2, .1), class = nu),
                prior(normal(0, 1), class = Intercept),
                prior(normal(0, 1), class = b),
                prior(normal(0, 1), class = sigma)),
      iter = 2000, warmup = 500, chains = 4, cores = 4, 
      seed = 210191)
```

Here are the results from the `x.clean` data and the Gaussian likelihood.

```{r}
print(f4)
```

Notice how our `x_s` slope is the same as the correlation. In a completely standardized simple univariate model, the simple slope is the same as the bivariate correlation. It worked the same way for our Student-$t$ model.

```{r}
print(f5)
```

There's another thing I'd like to point out. Plotting the model results will help make the point.

```{r, fig.width = 6.5, fig.height = 3.5, warning = F, message = F}
# make a custom function to get the `fitted()` draws
get_fitted <- function(fit) {
  nd <- tibble(x_s = seq(from = -2.5, to = 2.5, length.out = 40))
  
  fitted(fit,
         newdata = nd) %>% 
    as_tibble() %>% 
    bind_cols(nd %>% rename(x_s_nd = x_s))
}

# wrangle
tibble(name = str_c("f", 4:5)) %>% 
  mutate(fit = map(name, get)) %>% 
  mutate(fitted = map(fit, get_fitted)) %>% 
  unnest(fitted) %>% 
  bind_cols(bind_rows(x.clean, x.noisy)) %>% 
  mutate(strip = ifelse(name == "f4", "x.clean data with `family = gaussian`", "x.noisy data with `family = student`")) %>% 
  
  # plot
  ggplot(aes(color = outlier, fill = outlier)) +
  geom_point(aes(x = x_s, y = y_s)) +
  geom_smooth(aes(x = x_s_nd, y = Estimate, ymin = Q2.5, ymax = Q97.5),
              stat = "identity",
              alpha = 1/4, size = 1/2) +
  scale_color_fivethirtyeight() +
  scale_fill_fivethirtyeight() +
  coord_cartesian(xlim = -2:2,
                  ylim = -2:2) +
  theme_fivethirtyeight() +
  theme(legend.position = "none") +
  facet_wrap(~strip, ncol = 2)
```

Notice how with both models, the data and their respective fitted lines pass through [0, 0]? This is a consequence of modeling standardized data. We should always expect the intercept of a model like this to be 0. And if you look back up at the model summaries we returned by `print()`, you'll see this story told in the `Intercept` rows. So instead of estimating the intercept, why not just bake that into the models?

```{r f6_f7, cache = T, message = F, results = 'hide'}
f6 <- 
  brm(data = x.clean, 
      family = gaussian,
      y_s ~ 0 + x_s,
      prior = c(prior(normal(0, 1), class = b),
                prior(normal(0, 1), class = sigma)),
      iter = 2000, warmup = 500, chains = 4, cores = 4, 
      seed = 210191)

f7 <- 
  brm(data = x.noisy, 
      family = student,
      y_s ~ 0 + x_s,
      prior = c(prior(gamma(2, .1), class = nu),
                prior(normal(0, 1), class = b),
                prior(normal(0, 1), class = sigma)),
      iter = 2000, warmup = 500, chains = 4, cores = 4, 
      seed = 210191)
```

Look at the summaries.

```{r}
print(f6)
print(f7)
```

Even though it may have seemed like we substantially changed the models by fixing the intercepts to 0, the summaries are essentially the same as when we estimated the intercepts. Here we’ll confirm the summaries with plots, like above.

```{r, fig.width = 6.5, fig.height = 3.5, warning = F, message = F}
# wrangle
tibble(name = str_c("f", 6:7)) %>% 
  mutate(fit = map(name, get)) %>% 
  mutate(fitted = map(fit, get_fitted)) %>% 
  unnest(fitted) %>% 
  bind_cols(bind_rows(x.clean, x.noisy)) %>% 
  mutate(strip = ifelse(name == "f6", "x.clean data with `family = gaussian`", "x.noisy data with `family = student`")) %>% 
  
  # plot
  ggplot(aes(color = outlier, fill = outlier)) +
  geom_point(aes(x = x_s, y = y_s)) +
  geom_smooth(aes(x = x_s_nd, y = Estimate, ymin = Q2.5, ymax = Q97.5),
              stat = "identity",
              alpha = 1/4, size = 1/2) +
  scale_color_fivethirtyeight() +
  scale_fill_fivethirtyeight() +
  coord_cartesian(xlim = -2:2,
                  ylim = -2:2) +
  theme_fivethirtyeight() +
  theme(legend.position = "none") +
  facet_wrap(~strip, ncol = 2)
```

It’s pretty subtle, but if anything we increased the precision of our estimates by fixing the intercepts at 0.

### Let’s go multivariate, again.

First, we’ll rehearse what we did, above, with models `f2`. Model `f2`, recall, was the intercepts-only multivariate model with the `x.clean` data and the conventional Gaussian likelihood. This time we’ll apply the model to the standardized data. As such, we’ll tighten up the priors.

```{r f8, cache = T, message = F, results = 'hide'}
f8 <- 
  brm(data = x.clean, 
      family = gaussian,
      cbind(x_s, y_s) ~ 1,
      prior = c(prior(normal(0, 1), class = Intercept),
                prior(normal(1, 1), class = sigma, resp = xs),
                prior(normal(1, 1), class = sigma, resp = ys),
                prior(lkj(2), class = rescor)),
      iter = 2000, warmup = 500, chains = 4, cores = 4, 
      seed = 210191)
```

Behold the summary.

```{r}
print(f8)
```

Like in the earlier multivariate models, the correlation gets expressed in the `rescor(xs,ys)` row. But notice how the intercepts in this model are also hovering around 0, just like in our univariate models. Yep, we can fix those, too.

```{r f9, cache = T, message = F, results = 'hide'}
f9 <-
  brm(data = x.clean, 
      family = gaussian,
      cbind(x_s, y_s) ~ 0,
      prior = c(prior(normal(1, 1), class = sigma, resp = xs),
                prior(normal(1, 1), class = sigma, resp = ys),
                prior(lkj(2), class = rescor)),
      iter = 2000, warmup = 500, chains = 4, cores = 4, 
      seed = 210191)
```

Without the intercepts, the rest of the model is the same within simulation variance.

```{r}
print(f9)
```

If you wanna get silly, we can prune even further. Notice how the estimates for $\sigma$ are all hovering around 1 in `f8` and `f9`. Since we have no predictors, $\sigma$ is just an estimate of the population standard deviation. And since we’re working with standardized data, the population standard deviation has to be 1. Any other estimate would be nonsensical. So why not fix it to 1?

With brms, we can fix those $\sigma$s to 1 with a trick of the nonlinear [distributional modeling syntax](https://cran.r-project.org/web/packages/brms/vignettes/brms_distreg.html). Recall when you model $\sigma$, the brms default is to actually model it’s log. As is turns out, the log of 1 is zero.

```{r}
log(1)
```

So if we fix the log of $\sigma$ to zero, it’s the same as fixing $\sigma$ to 1—the exact value we’d like with standardized data. Here’s how that looks like in a model.

```{r f10, cache = T, message = F, results = 'hide'}
f10 <-
  brm(data = x.clean, 
      family = gaussian,
      bf(cbind(x_s, y_s) ~ 0,
         sigma ~ 0),
      prior = c(prior(lkj(2), class = rescor)),
      iter = 2000, warmup = 500, chains = 4, cores = 4, 
      seed = 210191)
```

Other than the `sigma ~ 0` syntax, the main thing to notice is we’ve wrapped the entire model `formula` into the `bf()` function. Here are the results.

```{r}
print(f10)
```

Now the correlation, `rescor(xs,ys)`, is the only parameter left. 

We should note, however, this method is a little more difficult when you want to generalize to the messy `x.noisy` data and the Student’s $t$-distribution. This is because, when you’re working with the $t$ distribution, $\sigma$ is no longer the same thing as the standard deviation. Well, okay, it is only in the special case for which $\nu$ is at infinity. Otherwise, $\simga$ is termed the *scale*. When $\nu$ is large, the scale is quite close to the standard deviation. But they diverge when $\nu$ shrinks to small numbers. So, unless you have experience with these models, it will be more challenging to set intelligent priors on $\sigma$.

Let’s start with the full model. Here we use the same regularizing prior on the intercepts we did with `f8`. But we put more permissive priors on the $\sigma$s. 

```{r f11, cache = T, message = F, results = 'hide'}
f11 <- 
  brm(data = x.noisy, 
      family = student,
      cbind(x_s, y_s) ~ 1,
      prior = c(prior(gamma(2, .1), class = nu),
                prior(normal(0, 1), class = Intercept),
                prior(normal(1, 10), class = sigma, resp = xs),
                prior(normal(1, 10), class = sigma, resp = ys),
                prior(lkj(2), class = rescor)),
      iter = 2000, warmup = 500, chains = 4, cores = 4, 
      seed = 210191)
```

```{r}
print(f11)
```

The intercepts remain around 0. Let's fix them, like before.

```{r f12, cache = T, message = F, results = 'hide'}
f12 <- 
  brm(data = x.noisy, 
      family = student,
      cbind(x_s, y_s) ~ 0,
      prior = c(prior(gamma(2, .1), class = nu),
                prior(normal(1, 10), class = sigma, resp = xs),
                prior(normal(1, 10), class = sigma, resp = ys),
                prior(lkj(2), class = rescor)),
      iter = 2000, warmup = 500, chains = 4, cores = 4, 
      seed = 210191)
```


```{r}
print(f12)
```

Since the relation between $t$-distribution scale and standard deviation depend on $\nu$ and since we’re estimating $\nu$ with a relatively-wide prior, I wouldn’t recommend attempting to fix sigma in this model like we did with the Gaussian. It just seems incoherent. 

```{r, fig.width = 8, fig.height = 4.5}
tibble(name = str_c("f", 0:3)) %>% 
  mutate(fit = map(name, get)) %>% 
  mutate(post = map(fit, posterior_samples)) %>% 
  unnest(post) %>% 
  select(name, rescor__x__y) %>% 
  rename(rho = rescor__x__y) %>% 
  # collect the correlation posteriors from the univariate models
  bind_rows(tibble(name = str_c("f", 4:7)) %>% 
  mutate(fit = map(name, get)) %>% 
  mutate(post = map(fit, posterior_samples)) %>% 
  unnest(post) %>% 
  select(name, b_x_s) %>% 
  rename(rho = b_x_s))%>% 
  # now bind those with the correlation posteriors from the multivariate models
  bind_rows(
    tibble(name = str_c("f", 8:12)) %>% 
      mutate(fit = map(name, get)) %>% 
      mutate(post = map(fit, posterior_samples)) %>% 
      unnest(post) %>% 
      select(name, rescor__xs__ys) %>% 
      rename(rho = rescor__xs__ys)
  ) %>% 
  # wrangle a bit just to make the y axis easier to understand
  mutate(name = factor(name, 
                       levels = c(str_c("f", 0:12)),
                       labels = c("f0.   unstandardized, multivariate, x.clean, Gaussian",
                                  "f1.   unstandardized, multivariate, x.noisy, Gaussian",
                                  "f2.   unstandardized, multivariate, x.noisy, Student",
                                  "f3.   unstandardized, multivariate, x.clean, Gaussian",
                                  "f4.   standardized, univariate, x.clean, Gaussian",
                                  "f5.   standardized, univariate, x.noisy, Student",
                                  "f6.   standardized, univariate, x.clean, Gaussian, fixed intercepts",
                                  "f7.   standardized, univariate, x.noisy, Student, fixed intercepts",
                                  "f8.   standardized, multivariate, x.clean, Gaussian",
                                  "f9.   standardized, multivariate, x.clean, Gaussian, fixed intercepts",
                                  "f10. standardized, multivariate, x.clean, Gaussian, fixed intercepts and slopes",
                                  "f11. standardized, multivariate, x.noisy, Student",
                                  "f12. standardized, multivariate, x.noisy, Student, fixed intercepts"))) %>% 

  # plot
  ggplot(aes(x = rho, y = name)) +
  geom_halfeyeh(aes(fill = factor(0)), 
                .width = .95, size = 5/4, relative_scale = 5/4) +
  scale_fill_fivethirtyeight() +
  ggtitle(expression(paste("Compare the ", rho, " posteriors."))) +
  coord_cartesian(xlim = c(-1.05, -.5),
                  ylim = c(1.25, 12.9)) +
  theme(panel.grid.major.y = element_blank(),
        axis.text.y = element_text(hjust = 0),
        legend.position = "none")
```







