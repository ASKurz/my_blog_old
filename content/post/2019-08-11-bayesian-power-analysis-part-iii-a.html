---
title: 'Bayesian power analysis: Part III.a. Counts are special.'
author: ''
date: '2019-08-11'
slug: bayesian-power-analysis-part-iii-a
categories: []
tags:
  - Bayesian
  - power
  - R
  - tidyverse
  - tutorial
authors: []
header:
  caption: ''
  image: ''
  preview: yes
bibliography: my_blog.bib
biblio-style: apalike
csl: apa.csl  
link-citations: yes  
---



<div id="version-1.0.1" class="section level2">
<h2>Version 1.0.1</h2>
</div>
<div id="orientation" class="section level2">
<h2>Orientation</h2>
<p>So far we’ve covered Bayesian power simulations from both a null hypothesis orientation (see <a href="https://solomonkurz.netlify.com/post/bayesian-power-analysis-part-i/">part I</a>) and a parameter width perspective (see <a href="https://solomonkurz.netlify.com/post/bayesian-power-analysis-part-ii/">part II</a>). In both instances, we kept things simple and stayed with Gaussian (i.e., normally distributed) data. But not all data follow that form, so it might do us well to expand our skill set a bit. In the next few posts, we’ll cover how we might perform power simulations with other kinds of data. In this post, we’ll focus on how to use the Poisson likelihood to model counts. In follow-up posts, we’ll explore how to model binary and Likert-type data.</p>
</div>
<div id="the-poisson-distribution-is-handy-for-counts." class="section level2">
<h2>The Poisson distribution is handy for counts.</h2>
<p>In the social sciences, count data arise when we ask questions like:</p>
<ul>
<li>How many sexual partners have you had?</li>
<li>How many pets do you have at home?</li>
<li>How many cigarettes did you smoke, yesterday?</li>
</ul>
<p>The values these data will take are discrete<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> in that you’ve either slept with 9 or 10 people, but definitely not 9.5. The values cannot go below zero in that even if you quit smoking cold turkey 15 years ago and have been a health nut since, you still could not have smoked -3 cigarettes, yesterday. Zero is as low as it goes.</p>
<p>The canonical distribution for data of this type–non-negative integers–is the Poisson. It’s named after the French mathematician Siméon Denis Poisson, <a href="https://upload.wikimedia.org/wikipedia/commons/e/e8/E._Marcellot_Siméon-Denis_Poisson_1804.jpg">who had quite the confident stare in his youth</a>. The Poisson distribution has one parameter, <span class="math inline">\(\lambda\)</span>, which controls both its mean and variance. Although the numbers the Poisson describes are counts, the <span class="math inline">\(\lambda\)</span> parameter does not need to be an integer. For example, here’s the plot of 1,000 draws from a Poisson for which <span class="math inline">\(\lambda = 3.2\)</span>.</p>
<pre class="r"><code>library(tidyverse)

theme_set(theme_gray() + theme(panel.grid = element_blank()))

tibble(x = rpois(n = 1e3, lambda = 3.2)) %&gt;% 
  mutate(x = factor(x)) %&gt;% 
  
  ggplot(aes(x = x)) +
  geom_bar()</code></pre>
<p><img src="/post/2019-08-11-bayesian-power-analysis-part-iii-a_files/figure-html/unnamed-chunk-1-1.png" width="384" /></p>
<p>In case you missed it, the key function for generating those data was <code>rpois()</code> (see <code>?rpois</code>). I’m not going to go into a full-blown tutorial on the Poisson distribution or on count regression. For more thorough introductions, check out Atkins et al’s <span class="citation">(<a href="#ref-atkinsTutorialOnCount2013">2013</a>)</span> <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3513584/pdf/nihms396181.pdf"><em>A tutorial on count regression and zero-altered count models for longitudinal substance use data</em></a>, chapters 9 through 11 in McElreath’s <span class="citation">(<a href="#ref-mcelreathStatisticalRethinkingBayesian2015">2015</a>)</span> <a href="https://xcelab.net/rm/statistical-rethinking/"><em>Statistical Rethinking</em></a>, or, if you really want to dive in, Agresti’s <span class="citation">(<a href="#ref-agrestiFoundationsLinearGeneralized2015">2015</a>)</span> <a href="https://www.wiley.com/en-us/Foundations+of+Linear+and+Generalized+Linear+Models-p-9781118730034"><em>Foundations of linear and generalized linear models</em></a>.</p>
<p>For our power example, let’s say you were interested in drinking. Using data from <a href="https://pubs.niaaa.nih.gov/publications/AA70/AA70.htm">the National Epidemiologic Survey on Alcohol and Related Conditions</a> <span class="citation">(Abuse &amp; Alcoholism, <a href="#ref-niaaaNationalEpidemiologicSurvey2006">2006</a>)</span>, Christopher Ingraham <span class="citation">(<a href="#ref-ingrahamThinkYouDrink2014">2014</a>)</span> presented <a href="https://www.washingtonpost.com/news/wonk/wp/2014/09/25/think-you-drink-a-lot-this-chart-will-tell-you/?utm_term=.b81599bbbe25">a data visualization</a> of the average number of alcoholic drinks American adults consume, per week. By decile, the numbers were:</p>
<ol style="list-style-type: decimal">
<li>0.00</li>
<li>0.00</li>
<li>0.00</li>
<li>0.02</li>
<li>0.14</li>
<li>0.63</li>
<li>2.17</li>
<li>6.25</li>
<li>15.28</li>
<li>73.85</li>
</ol>
<p>Let’s say you wanted to run a study where you planned on comparing two demographic groups by their weekly drinking levels. Let’s further say you suspected one of those groups drank like the American adults in the 7<sup>th</sup> decile and the other drank like American adults in the 8<sup>th</sup>. We’ll call them low and high drinkers, respectively. For convenience, let’s further presume you’ll be able to recruit equal numbers of participants from both groups. The objective for our power analysis–or sample size analysis if you prefer to avoid the language of <em>power</em>–is to determine how many you’d need per group to detect reliable differences. Using <span class="math inline">\(n = 50\)</span> as a starting point, here’s what the data for our hypothetical groups might look like.</p>
<pre class="r"><code>mu_7 &lt;- 2.17
mu_8 &lt;- 6.25

n &lt;- 50

set.seed(3)

d &lt;-
  tibble(low  = rpois(n = n, lambda = mu_7),
         high = rpois(n = n, lambda = mu_8)) %&gt;% 
  gather(group, count) 

d %&gt;%
  mutate(count = factor(count)) %&gt;% 
  
  ggplot(aes(x = count)) +
  geom_bar() +
  facet_wrap(~group, ncol = 1)</code></pre>
<p><img src="/post/2019-08-11-bayesian-power-analysis-part-iii-a_files/figure-html/unnamed-chunk-2-1.png" width="384" /></p>
<p>This will be our primary data type. Our next step is to determine how to express our research question as a regression model. Like with our two-group Gaussian models, we can predict counts in terms of an intercept (i.e., standing for the expected value on the reference group) and slope (i.e., standing for the expected difference between the reference group and the comparison group). If we coded our two groups by a <code>high</code> variable for which 0 stood for low drinkers and 1 stood for high drinkers, the basic model would follow the form</p>
<p><span class="math display">\[
\begin{align*}
\text{drinks_per_week}_i         &amp; \sim \operatorname{Poisson}(\lambda_i) \\
\log(\lambda_i)   &amp; = \beta_0 + \beta_1 \text{high}_i.
\end{align*}
\]</span></p>
<p>Here’s how to set the data up for that model.</p>
<pre class="r"><code>d &lt;-
  d %&gt;% 
  mutate(high = ifelse(group == &quot;low&quot;, 0, 1))</code></pre>
<p>If you were attending closely to our model formula, you noticed we ran into a detail. Count regression, such as with the Poisson likelihood, tends to use the log link. <em>Why?</em> you ask. Recall that counts need to be 0 and above. Same deal for our <span class="math inline">\(\lambda\)</span> parameter. In order to make sure our models don’t yield silly estimates for <span class="math inline">\(\lambda\)</span>, like -2 or something, we typically use the log link. You don’t have to, of course. The world is your playground. But this is the method most of your colleagues are likely to use and it’s the one I suggest you use until you have compelling reasons to do otherwise.</p>
<p>So then since we’re now fitting a model with a log link, it might seem challenging to pick good priors. As a place to start, we can use the <code>brms::get_prior()</code> function to see the <strong>brms</strong> defaults.</p>
<pre class="r"><code>library(brms)

get_prior(data = d,
          family = poisson,
          count ~ 0 + Intercept + high)</code></pre>
<pre><code>##   prior class      coef group resp dpar nlpar bound
## 1           b                                      
## 2           b      high                            
## 3           b Intercept</code></pre>
<p>Hopefully two things popped out. First, there’s no prior of <code>class = sigma</code>. Since the Poisson distribution only has one parameter <span class="math inline">\(\lambda\)</span>, we don’t need to set a prior for <span class="math inline">\(\sigma\)</span>. Our model won’t have one. Second, because we’re continuing to use the <code>0 + Intercept</code> syntax for our model intercept, both our intercept and slope are of prior <code>class = b</code> and those currently have default flat priors with <strong>brms</strong>. To be sure, flat priors aren’t the best. But maybe if this was your first time playing around with a Poisson model, default flat priors might seem like a safe place to start. <a href="https://xkcd.com/386/">Feel free to disagree</a>. In the meantime, here’s how to fit that default Poisson model with <code>brms::brm()</code>.</p>
<pre class="r"><code>fit1 &lt;-
  brm(data = d,
      family = poisson,
      count ~ 0 + Intercept + high,
      seed = 3)</code></pre>
<pre class="r"><code>print(fit1)</code></pre>
<pre><code>##  Family: poisson 
##   Links: mu = log 
## Formula: count ~ 0 + Intercept + high 
##    Data: d (Number of observations: 100) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     0.59      0.11     0.38     0.79 1.01      917     1133
## high          1.27      0.12     1.03     1.51 1.01      935     1182
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Since we used the log link, our model results are in the log metric, too. If you’d like them in the metric of the data, you’d work directly with the poster samples and exponentiate.</p>
<pre class="r"><code>post &lt;- 
  posterior_samples(fit1) %&gt;% 
  mutate(`beta_0 (i.e., low)`                       = exp(b_Intercept),
         `beta_1 (i.e., difference score for high)` = exp(b_high))</code></pre>
<p>We can then just summarize our parameters of interest.</p>
<pre class="r"><code>post %&gt;% 
  select(starts_with(&quot;beta_&quot;)) %&gt;% 
  gather() %&gt;% 
  group_by(key) %&gt;% 
  summarise(mean  = mean(value),
            lower = quantile(value, prob = .025),
            upper = quantile(value, prob = .975))</code></pre>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<pre><code>## # A tibble: 2 x 4
##   key                                       mean lower upper
##   &lt;chr&gt;                                    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 beta_0 (i.e., low)                        1.81  1.46  2.21
## 2 beta_1 (i.e., difference score for high)  3.58  2.81  4.53</code></pre>
<p>For the sake of simulation, it’ll be easier if we press on with evaluating the parameters on the log metric, though. If you’re working within a null-hypothesis oriented power paradigm, you’ll be happy to know zero is still the number to beat for evaluating our 95% intervals for <span class="math inline">\(\beta_1\)</span>, even when that parameter is in the log metric. Here it is, again.</p>
<pre class="r"><code>library(broom)

tidy(fit1, prob = .95) %&gt;% 
  filter(term == &quot;b_high&quot;)</code></pre>
<pre><code>##     term estimate std.error    lower    upper
## 1 b_high 1.269044 0.1211455 1.033061 1.510889</code></pre>
<p>So our first fit suggests we’re on good footing to run a quick power simulation holding <span class="math inline">\(n = 50\)</span>. As in the prior blog posts, our lives will be simpler if we set up a custom simulation function. Since we’ll be using it to simulate the data and fit the model in one step, let’s call it <code>sim_data_fit()</code>.</p>
<pre class="r"><code>sim_data_fit &lt;- function(seed, n) {
  
  # define our mus in the function
  mu_7 &lt;- 2.17
  mu_8 &lt;- 6.25

  # make your results reproducible
  set.seed(seed)
  
  # simulate the data
  d &lt;-
    tibble(high  = rep(0:1, each = n),
           count = c(rpois(n = n, lambda = mu_7),
                     rpois(n = n, lambda = mu_8)))
  
  # fit and summarise
  update(fit1,
         newdata = d,
         seed = seed) %&gt;% 
  tidy(prob = .95) %&gt;% 
  filter(term == &quot;b_high&quot;) %&gt;% 
  select(lower:upper)
  
}</code></pre>
<p>Here’s the simulation for a simple 100 iterations.</p>
<pre class="r"><code>sim1 &lt;-
  tibble(seed = 1:100) %&gt;% 
  mutate(ci = map(seed, sim_data_fit, n = 50)) %&gt;% 
  unnest()</code></pre>
<p>That went quick–just a little over a minute on my laptop. Here’s what those 100 <span class="math inline">\(\beta_1\)</span> intervals look like in bulk.</p>
<pre class="r"><code>sim1 %&gt;% 
  ggplot(aes(x = seed, ymin = lower, ymax = upper)) +
  geom_hline(yintercept = 0, color = &quot;white&quot;) +
  geom_linerange() +
  labs(x = &quot;seed (i.e., simulation index)&quot;,
       y = expression(beta[1]))</code></pre>
<p><img src="/post/2019-08-11-bayesian-power-analysis-part-iii-a_files/figure-html/unnamed-chunk-10-1.png" width="768" /></p>
<p>None of them are anywhere near the null value 0. So it appears we’re well above .8 power to reject the typical <span class="math inline">\(H_0\)</span> with <span class="math inline">\(n = 50\)</span>. Switching to the precision orientation, here’s the distribution of their widths.</p>
<pre class="r"><code>sim1 %&gt;% 
  mutate(width = upper - lower) %&gt;% 
  
  ggplot(aes(x = width)) +
  geom_histogram(binwidth = 0.01) +
  geom_rug(size = 1/6)</code></pre>
<p><img src="/post/2019-08-11-bayesian-power-analysis-part-iii-a_files/figure-html/unnamed-chunk-11-1.png" width="384" /></p>
<p>What if we wanted a mean width of 0.25 on the log scale? We might try the simulation with <span class="math inline">\(n = 150\)</span>.</p>
<pre class="r"><code>sim2 &lt;-
  tibble(seed = 1:100) %&gt;% 
  mutate(ci = map(seed, sim_data_fit, n = 150)) %&gt;% 
  unnest()</code></pre>
<p>Here we’ll summarize the widths both in terms of their mean and what proportion were smaller than 0.25.</p>
<pre class="r"><code>sim2 %&gt;% 
  mutate(width = upper - lower) %&gt;% 
  summarise(`mean width` = mean(width),
            `below 0.25` = mean(width &lt; 0.25))</code></pre>
<pre><code>## # A tibble: 1 x 2
##   `mean width` `below 0.25`
##          &lt;dbl&gt;        &lt;dbl&gt;
## 1        0.252         0.43</code></pre>
<p>If we wanted to focus on the mean, we did pretty good. Perhaps set the <span class="math inline">\(n = 155\)</span> and simulate a full 1,000+ iterations for a serious power analysis. But if we wanted to make the stricter criteria of all below 0.25, we’d need to up the <span class="math inline">\(n\)</span> quite a bit more. And of course, once you have a little experience working with Poisson models, you might do the power simulations with more ambitious priors. For example, if your count values are lower than like 1,000, there’s a good chance a <code>normal(0, 6)</code> prior on your <span class="math inline">\(\beta\)</span> parameters will be nearly flat within the reasonable neighborhoods of the parameter space.</p>
</div>
<div id="but-logs-are-hard." class="section level2">
<h2>But logs are hard.</h2>
<p>If we approach our Bayesian power analysis from a precision perspective, it can be difficult to settle on a reasonable interval width when they’re on the log scale. So let’s modify our simulation flow so it converts the width summaries back into the natural metric. Before we go big, let’s practice with a single iteration.</p>
<pre class="r"><code>seed &lt;- 0
set.seed(seed)

# simulate the data
d &lt;-
  tibble(high  = rep(0:1, each = n),
         count = c(rpois(n = n, lambda = mu_7),
                   rpois(n = n, lambda = mu_8)))

# fit the model
fit2 &lt;-
  update(fit1,
       newdata = d,
       seed = seed) </code></pre>
<p>Now summarize.</p>
<pre class="r"><code>library(tidybayes)

fit2 %&gt;% 
  posterior_samples() %&gt;% 
  transmute(`beta_1` = exp(b_high)) %&gt;% 
  mean_qi()</code></pre>
<pre><code>##     beta_1  .lower   .upper .width .point .interval
## 1 2.705404 2.16512 3.341729   0.95   mean        qi</code></pre>
<p>Before we used the handy <code>broom::tidy()</code> function to extract our intervals, which took the <strong>brms</strong> fit object as input. Here we took a different approach. Because we are transforming <span class="math inline">\(\beta_1\)</span>, we used the <code>posterior_samples()</code> function to work directly with the posterior draws. We then exponentiated within <code>transmute()</code>, which returned a single-column tibble, not a <strong>brms</strong> fit object. So instead of <code>broom::tidy()</code>, it’s easier to get our summary statistics with the <code>tidybayes::mean_qi()</code> function. Do note that now our lower and upper levels are named <code>.lower</code> and <code>.upper</code>, respectively (i.e., they now have a <code>.</code> prefix).</p>
<p>Now we’ve practiced with the new flow, let’s redefine our simulation function.</p>
<pre class="r"><code>sim_data_fit &lt;- function(seed, n) {
  
  # define our mus in the function
  mu_7 &lt;- 2.17
  mu_8 &lt;- 6.25

  # make your results reproducible
  set.seed(seed)
  
  # simulate the data
  d &lt;-
    tibble(high  = rep(0:1, each = n),
           count = c(rpois(n = n, lambda = mu_7),
                     rpois(n = n, lambda = mu_8)))
  
  # fit and summarize
  update(fit1,
         newdata = d,
         seed = seed) %&gt;% 
  posterior_samples() %&gt;% 
  transmute(`beta_1` = exp(b_high)) %&gt;% 
  mean_qi()
  
}</code></pre>
<p>Simulate.</p>
<pre class="r"><code>sim3 &lt;-
  tibble(seed = 1:100) %&gt;% 
  mutate(ci = map(seed, sim_data_fit, n = 50)) %&gt;% 
  unnest()</code></pre>
<p>Here’s what those 100 <span class="math inline">\(\beta_1\)</span> intervals look like in bulk.</p>
<pre class="r"><code>sim3 %&gt;% 
  ggplot(aes(x = seed, y = beta_1, ymin = .lower, ymax = .upper)) +
  geom_hline(yintercept = 0, color = &quot;white&quot;) +
  geom_pointrange(fatten = 1) +
  labs(x = &quot;seed (i.e., simulation index)&quot;,
       y = expression(beta[1]))</code></pre>
<p><img src="/post/2019-08-11-bayesian-power-analysis-part-iii-a_files/figure-html/unnamed-chunk-17-1.png" width="768" /></p>
<p>Inspect the distribution of their widths.</p>
<pre class="r"><code>sim3 %&gt;% 
  mutate(width = .upper - .lower) %&gt;% 
  
  ggplot(aes(x = width)) +
  geom_histogram(binwidth = 0.05) +
  geom_rug(size = 1/6)</code></pre>
<p><img src="/post/2019-08-11-bayesian-power-analysis-part-iii-a_files/figure-html/unnamed-chunk-18-1.png" width="384" /></p>
<p>What if we wanted a mean 95% interval width of 1? Let’s run the simulation again, this time with <span class="math inline">\(n = 100\)</span>.</p>
<pre class="r"><code>sim4 &lt;-
  tibble(seed = 1:100) %&gt;% 
  mutate(ci = map(seed, sim_data_fit, n = 100)) %&gt;% 
  unnest() %&gt;% 
  mutate(width = .upper - .lower)</code></pre>
<p>Here’s the new width distribution.</p>
<pre class="r"><code>sim4 %&gt;% 
  ggplot(aes(x = width)) +
  geom_histogram(binwidth = 0.05) +
  geom_rug(size = 1/6)</code></pre>
<p><img src="/post/2019-08-11-bayesian-power-analysis-part-iii-a_files/figure-html/unnamed-chunk-19-1.png" width="384" /></p>
<p>And the mean width is:</p>
<pre class="r"><code>sim4 %&gt;% 
  summarise(mean_width = mean(width))</code></pre>
<pre><code>## # A tibble: 1 x 1
##   mean_width
##        &lt;dbl&gt;
## 1      0.913</code></pre>
<p>Nice! If we want a mean width of 1, it looks like we’re a little <em>overpowered</em> with <span class="math inline">\(n = 100\)</span>. The next step would be to up your iterations to 1,000 or so to do a proper simulation.</p>
<p>Now you’ve got a sense of how to work with the Poisson likelihood, <a href="https://solomonkurz.netlify.app/post/bayesian-power-analysis-part-iii-b/">next time</a> we’ll play with binary data.</p>
</div>
<div id="session-info" class="section level2">
<h2>Session info</h2>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>## R version 3.6.3 (2020-02-29)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS Catalina 10.15.3
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] tidybayes_2.1.1 broom_0.5.5     brms_2.13.0     Rcpp_1.0.5     
##  [5] forcats_0.5.0   stringr_1.4.0   dplyr_1.0.1     purrr_0.3.4    
##  [9] readr_1.3.1     tidyr_1.1.1     tibble_3.0.3    ggplot2_3.3.2  
## [13] tidyverse_1.3.0
## 
## loaded via a namespace (and not attached):
##   [1] TH.data_1.0-10       colorspace_1.4-1     ellipsis_0.3.1      
##   [4] ggridges_0.5.2       rsconnect_0.8.16     estimability_1.3    
##   [7] markdown_1.1         base64enc_0.1-3      fs_1.4.1            
##  [10] rstudioapi_0.11      farver_2.0.3         rstan_2.19.3        
##  [13] svUnit_1.0.3         DT_0.13              fansi_0.4.1         
##  [16] mvtnorm_1.1-0        lubridate_1.7.8      xml2_1.3.1          
##  [19] codetools_0.2-16     splines_3.6.3        bridgesampling_1.0-0
##  [22] knitr_1.28           shinythemes_1.1.2    bayesplot_1.7.1     
##  [25] jsonlite_1.7.0       dbplyr_1.4.2         ggdist_2.1.1        
##  [28] shiny_1.5.0          compiler_3.6.3       httr_1.4.1          
##  [31] emmeans_1.4.5        backports_1.1.8      assertthat_0.2.1    
##  [34] Matrix_1.2-18        fastmap_1.0.1        cli_2.0.2           
##  [37] later_1.1.0.1        htmltools_0.5.0      prettyunits_1.1.1   
##  [40] tools_3.6.3          igraph_1.2.5         coda_0.19-3         
##  [43] gtable_0.3.0         glue_1.4.1           reshape2_1.4.4      
##  [46] cellranger_1.1.0     vctrs_0.3.2          nlme_3.1-144        
##  [49] blogdown_0.18        crosstalk_1.1.0.1    xfun_0.13           
##  [52] ps_1.3.4             rvest_0.3.5          mime_0.9            
##  [55] miniUI_0.1.1.1       lifecycle_0.2.0      gtools_3.8.2        
##  [58] MASS_7.3-51.5        zoo_1.8-7            scales_1.1.1        
##  [61] colourpicker_1.0     hms_0.5.3            promises_1.1.1      
##  [64] Brobdingnag_1.2-6    sandwich_2.5-1       parallel_3.6.3      
##  [67] inline_0.3.15        shinystan_2.5.0      yaml_2.2.1          
##  [70] gridExtra_2.3        StanHeaders_2.21.0-1 loo_2.2.0           
##  [73] stringi_1.4.6        dygraphs_1.1.1.6     pkgbuild_1.1.0      
##  [76] rlang_0.4.7          pkgconfig_2.0.3      matrixStats_0.56.0  
##  [79] evaluate_0.14        lattice_0.20-38      rstantools_2.0.0    
##  [82] htmlwidgets_1.5.1    labeling_0.3         tidyselect_1.1.0    
##  [85] processx_3.4.3       plyr_1.8.6           magrittr_1.5        
##  [88] bookdown_0.18        R6_2.4.1             generics_0.0.2      
##  [91] multcomp_1.4-13      DBI_1.1.0            pillar_1.4.6        
##  [94] haven_2.2.0          withr_2.2.0          xts_0.12-0          
##  [97] survival_3.1-12      abind_1.4-5          modelr_0.1.6        
## [100] crayon_1.3.4         arrayhelpers_1.1-0   utf8_1.1.4          
## [103] rmarkdown_2.1        grid_3.6.3           readxl_1.3.1        
## [106] callr_3.4.3          threejs_0.3.3        reprex_0.3.0        
## [109] digest_0.6.25        xtable_1.8-4         httpuv_1.5.4        
## [112] stats4_3.6.3         munsell_0.5.0        shinyjs_1.1</code></pre>
</div>
<div id="references" class="section level2 unnumbered">
<h2>References</h2>
<div id="refs" class="references">
<div id="ref-niaaaNationalEpidemiologicSurvey2006">
<p>Abuse, N. I. on A., &amp; Alcoholism. (2006). <em>National epidemiologic survey on alcohol and related conditions</em>. <a href="https://pubs.niaaa.nih.gov/publications/AA70/AA70.htm">https://pubs.niaaa.nih.gov/publications/AA70/AA70.htm</a></p>
</div>
<div id="ref-agrestiFoundationsLinearGeneralized2015">
<p>Agresti, A. (2015). <em>Foundations of linear and generalized linear models</em>. John Wiley &amp; Sons. <a href="https://www.wiley.com/en-us/Foundations+of+Linear+and+Generalized+Linear+Models-p-9781118730034">https://www.wiley.com/en-us/Foundations+of+Linear+and+Generalized+Linear+Models-p-9781118730034</a></p>
</div>
<div id="ref-atkinsTutorialOnCount2013">
<p>Atkins, D. C., Baldwin, S. A., Zheng, C., Gallop, R. J., &amp; Neighbors, C. (2013). A tutorial on count regression and zero-altered count models for longitudinal substance use data. <em>Psychology of Addictive Behaviors</em>, <em>27</em>(1), 166. <a href="https://doi.org/10.1037/a0029508">https://doi.org/10.1037/a0029508</a></p>
</div>
<div id="ref-ingrahamThinkYouDrink2014">
<p>Ingraham, C. (2014). Think you drink a lot? This chart will tell you. <em>Wonkblog. The Washington Post</em>. <a href="https://www.washingtonpost.com/news/wonk/wp/2014/09/25/think-you-drink-a-lot-this-chart-will-tell-you/?utm_term=.b81599bbbe25">https://www.washingtonpost.com/news/wonk/wp/2014/09/25/think-you-drink-a-lot-this-chart-will-tell-you/?utm_term=.b81599bbbe25</a></p>
</div>
<div id="ref-mcelreathStatisticalRethinkingBayesian2015">
<p>McElreath, R. (2015). <em>Statistical rethinking: A Bayesian course with examples in R and Stan</em>. CRC press. <a href="https://xcelab.net/rm/statistical-rethinking/">https://xcelab.net/rm/statistical-rethinking/</a></p>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Yes, one can smoke half a cigarette or drink 1/3 of a drink. Ideally, we’d have the exact amount of nicotine in your blood at a given moment and over time and the same for the amount of alcohol in your system relative to your blood volume and such. But in practice, substance use researchers just don’t tend to have access to data of that quality. Instead, we’re typically stuck with simple counts. And I look forward to the day the right team of engineers, computer scientists, and substance use researchers (and whoever else I forgot to mention) release the cheap, non-invasive technology we need to passively measure these things. Until then: <em>How many standard servings of alcohol did you drink, last night?</em><a href="#fnref1" class="footnote-back">↩</a></p></li>
</ol>
</div>
