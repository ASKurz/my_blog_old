
@book{agrestiFoundationsLinearGeneralized2015,
  title = {Foundations of Linear and Generalized Linear Models},
  author = {Agresti, Alan},
  year = {2015},
  month = jan,
  publisher = {{John Wiley \& Sons}},
  url = {https://www.wiley.com/en-us/Foundations+of+Linear+and+Generalized+Linear+Models-p-9781118730034},
  abstract = {A valuable overview of the most important ideas and results in statistical modeling Written by a highly-experienced author, Foundations of Linear and Generalized Linear Models is a clear and comprehensive guide to the key concepts and results of linearstatistical models. The book presents a broad, in-depth overview of the most commonly usedstatistical models by discussing the theory underlying the models, R software applications,and examples with crafted models to elucidate key ideas and promote practical modelbuilding. The book begins by illustrating the fundamentals of linear models, such as how the model-fitting projects the data onto a model vector subspace and how orthogonal decompositions of the data yield information about the effects of explanatory variables. Subsequently, the book covers the most popular generalized linear models, which include binomial and multinomial logistic regression for categorical data, and Poisson and negative binomial loglinear models for count data. Focusing on the theoretical underpinnings of these models, Foundations ofLinear and Generalized Linear Models also features:  An introduction to quasi-likelihood methods that require weaker distributional assumptions, such as generalized estimating equation methods An overview of linear mixed models and generalized linear mixed models with random effects for clustered correlated data, Bayesian modeling, and extensions to handle problematic cases such as high dimensional problems Numerous examples that use R software for all text data analyses More than 400 exercises for readers to practice and extend the theory, methods, and data analysis A supplementary website with datasets for the examples and exercises  An invaluable textbook for upper-undergraduate and graduate-level students in statistics and biostatistics courses, Foundations of Linear and Generalized Linear Models is also an excellent reference for practicing statisticians and biostatisticians, as well as anyone who is interested in learning about the most important statistical models for analyzing data.},
  googlebooks = {dgIzBgAAQBAJ},
  isbn = {978-1-118-73005-8},
  keywords = {Mathematics / Probability \& Statistics / General,Mathematics / Probability \& Statistics / Stochastic Processes},
  language = {en}
}

@article{atkinsTutorialOnCount2013,
  title = {A Tutorial on Count Regression and Zero-Altered Count Models for Longitudinal Substance Use Data.},
  author = {Atkins, David C and Baldwin, Scott A and Zheng, Cheng and Gallop, Robert J and Neighbors, Clayton},
  year = {2013},
  volume = {27},
  pages = {166},
  publisher = {{American Psychological Association}},
  doi = {10.1037/a0029508},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3513584/pdf/nihms396181.pdf},
  journal = {Psychology of Addictive Behaviors},
  number = {1}
}

@book{brms2020RM,
  title = {{{brms}} Reference Manual, {{Version}} 2.14.4},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2020},
  url = {https://CRAN.R-project.org/package=brms/brms.pdf}
}

@article{BÃ¼rkner2020Parameterization,
  title = {Parameterization of Response Distributions in Brms},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2020},
  url = {https://CRAN.R-project.org/package=brms/vignettes/brms_families.html}
}

@article{burknerAdvancedBayesianMultilevel2018,
  title = {Advanced {{Bayesian}} Multilevel Modeling with the {{R}} Package Brms},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2018},
  volume = {10},
  pages = {395--411},
  doi = {10.32614/RJ-2018-017},
  journal = {The R Journal},
  number = {1}
}

@article{burknerBrmsPackageBayesian2017,
  title = {{{brms}}: {{An R}} Package for {{Bayesian}} Multilevel Models Using {{Stan}}},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2017},
  volume = {80},
  pages = {1--28},
  doi = {10.18637/jss.v080.i01},
  journal = {Journal of Statistical Software},
  number = {1}
}

@book{cohenStatisticalPowerAnalysis1988a,
  title = {Statistical Power Analysis for the Behavioral Sciences},
  author = {Cohen, Jacob},
  year = {1988},
  publisher = {{L. Erlbaum Associates}},
  address = {{Hillsdale, N.J.}},
  url = {https://www.worldcat.org/title/statistical-power-analysis-for-the-behavioral-sciences/oclc/17877467},
  abstract = {This is a nontechnical guide to power analysis in research planning that provides users of applied statistics with the tools they need for more effective analysis. The second edition includes: a chapter covering power analysis in set correlation and multivariate methods; a chapter considering effect size, psychometric reliability, and the efficacy of "qualifying" dependent variables and; expanded power and sample size tables for multiple regression/correlation.},
  annotation = {OCLC: 17877467},
  isbn = {978-0-8058-0283-2},
  language = {English}
}

@misc{comicsexplainedJoeRoganExperience2020,
  title = {Joe {{Rogan Experience}} \#1570 - {{Willie D}} \& {{Mike Judge}}},
  author = {{Comics Explained}},
  year = {2020},
  month = nov,
  url = {https://www.youtube.com/watch?v=bvzs-VbEzds\&t=2580s},
  urldate = {2020-11-26},
  abstract = {Rapper, songwriter, and entrepreneur Willie D is a founding member of the classic hip hop group Geto Boys. In addition to his music career, he has been a candidate for public office, written for a widely-read advice column, and is a former Golden Gloves champion boxer. @Willie D Live  Mike Judge is a writer, director, actor, and filmmaker. He's the creator of Beavis \&amp; Butthead, co-creator of King of the Hill \&amp; also Silicon Valley, and director of movies such as "Office Space" \&amp; "Idiocracy." **The 2nd half of this video is AUDIO ONLY. No video is available due to a hard drive error.** https://www.youtube.com/c/WillieDLive}
}

@techreport{davis-stoberWhenAreSample2017,
  title = {When Are Sample Means Meaningful? {{The}} Role of Modern Estimation in Psychological Science},
  shorttitle = {When Are Sample Means Meaningful?},
  author = {{Davis-Stober}, Clintin and Dana, Jason and Rouder, Jeffrey},
  year = {2017},
  month = apr,
  institution = {{OSF Preprints}},
  doi = {10.31219/osf.io/2ukxj},
  url = {https://osf.io/2ukxj/},
  urldate = {2020-12-07},
  abstract = {Sample means are considered a foundational statistic for understanding experimental psychological data that seemingly can be used in all contexts.  We argue here that contrary to common belief, sample means are not always interpretable, and there are not-so-rare cases where they are useless if not misleading.  We define the sample mean as uninterpretable if in a measurement environment it is outperformed by a nonsense estimator that does not use the data to estimate the relations among experimental conditions.  We consider two such nonsense estimators: one that randomizes the relations among conditions, and another that states that there are no condition effects no matter the data.  We show that there are common cases where these nonsense estimators outperform sample means on average, and these may even occur when effects are detected.  We argue that in these cases, sample means are uninterpretable and should be avoided.  The concept of interpretability highlights regularization in model estimation, such as that used in lasso, ridge, and hierarchical Bayes techniques.  We argue that not only is the interpretation of sample means context dependent, but that modern estimators should replace sample means, even for describing data, because they are interpretable in a wider range of contexts.},
  file = {/Users/solomonkurz/Zotero/storage/AFJJ34CM/Davis-Stober et al. - 2017 - When are sample means meaningful The role of mode.pdf},
  keywords = {Bayesian,Cognitive Psychology,effect sizes,estimation,Experimental Analysis of Behavior,Psychology,Quantitative Psychology,replication,sample means,Social and Behavioral Sciences}
}

@incollection{efronEmpiricalBayesJamesStein2010,
  title = {Empirical {{Bayes}} and the {{James}}-{{Stein}} Estimator},
  booktitle = {Large-Scale Inference: {{Empirical Bayes}} Methods for Estimation, Testing, and Prediction},
  author = {Efron, Bradley},
  year = {2010},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge}},
  url = {https://statweb.stanford.edu/~ckirby/brad/LSI/monograph_CUP.pdf}
}

@article{efronSteinParadoxStatistics1977,
  title = {Stein's Paradox in Statistics},
  author = {Efron, Bradley and Morris, Carl},
  year = {1977},
  volume = {236},
  pages = {119--127},
  publisher = {{Scientific American, a division of Nature America, Inc.}},
  issn = {0036-8733},
  doi = {10.1038/scientificamerican0577-119},
  url = {https://www.jstor.org/stable/24954030},
  urldate = {2020-05-17},
  journal = {Scientific American},
  number = {5}
}

@book{fahrmeirRegressionModelsMethods2013,
  title = {Regression: {{Models}}, Methods and Applications},
  shorttitle = {Regression},
  author = {Fahrmeir, Ludwig and Kneib, Thomas and Lang, Stefan and Marx, Brian},
  year = {2013},
  publisher = {{Springer-Verlag}},
  address = {{Berlin Heidelberg}},
  doi = {10.1007/978-3-642-34333-9},
  url = {https://www.springer.com/us/book/9783642343322},
  urldate = {2020-11-25},
  abstract = {The aim of this book is an applied and unified introduction into parametric, non- and semiparametric regression that closes the gap between theory and application. The most important models and methods in regression are presented on a solid formal basis, and their appropriate application is shown through many real data examples and case studies. Availability of (user-friendly) software has been a major criterion for the methods selected and presented. Thus, the book primarily targets an audience that includes students, teachers and practitioners in social, economic, and life sciences, as well as students and teachers in statistics programs, and mathematicians and computer scientists with interests in statistical modeling and data analysis. It is written on an intermediate mathematical level and assumes only knowledge of basic probability, calculus, and statistics. The most important definitions and statements are concisely summarized in boxes. Two appendices describe required matrix algebra, as well as elements of probability calculus and statistical inference.},
  file = {/Users/solomonkurz/Zotero/storage/T3TWPSEW/9783642343322.html},
  isbn = {978-3-642-34332-2},
  language = {en}
}

@book{gelman2013bayesian,
  title = {Bayesian Data Analysis},
  author = {Gelman, Andrew and Carlin, John B and Stern, Hal S and Dunson, David B and Vehtari, Aki and Rubin, Donald B},
  year = {2013},
  edition = {Third Edition},
  publisher = {{CRC press}},
  url = {https://stat.columbia.edu/~gelman/book/}
}

@book{gelmanDataAnalysisUsing2006,
  title = {Data Analysis Using Regression and Multilevel/Hierarchical Models},
  author = {Gelman, Andrew and Hill, Jennifer},
  year = {2006},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge}},
  doi = {10.1017/CBO9780511790942},
  url = {https://www.cambridge.org/core/books/data-analysis-using-regression-and-multilevelhierarchical-models/32A29531C7FD730C3A68951A17C9D983},
  urldate = {2020-09-17},
  abstract = {Data Analysis Using Regression and Multilevel/Hierarchical Models, first published in 2007, is a comprehensive manual for the applied researcher who wants to perform data analysis using linear and nonlinear regression and multilevel models. The book introduces a wide variety of models, whilst at the same time instructing the reader in how to fit these models using available software packages. The book illustrates the concepts by working through scores of real data examples that have arisen from the authors' own applied research, with programming codes provided for each one. Topics covered include causal inference, including regression, poststratification, matching, regression discontinuity, and instrumental variables, as well as multilevel logistic regression and missing-data imputation. Practical tips regarding building, fitting, and understanding are provided throughout.},
  file = {/Users/solomonkurz/Zotero/storage/KFY9IC96/32A29531C7FD730C3A68951A17C9D983.html},
  isbn = {978-0-521-86706-1},
  series = {Analytical {{Methods}} for {{Social Research}}}
}

@article{gelmanPriorCanOften2017,
  title = {The Prior Can Often Only Be Understood in the Context of the Likelihood},
  author = {Gelman, Andrew and Simpson, Daniel and Betancourt, Michael},
  year = {2017},
  month = oct,
  volume = {19},
  pages = {555},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/e19100555},
  url = {https://www.mdpi.com/1099-4300/19/10/555},
  urldate = {2020-06-12},
  abstract = {A key sticking point of Bayesian analysis is the choice of prior distribution, and there is a vast literature on potential defaults including uniform priors, Jeffreys' priors, reference priors, maximum entropy priors, and weakly informative priors. These methods, however, often manifest a key conceptual tension in prior modeling: a model encoding true prior information should be chosen without reference to the model of the measurement process, but almost all common prior modeling techniques are implicitly motivated by a reference likelihood. In this paper we resolve this apparent paradox by placing the choice of prior into the context of the entire Bayesian analysis, from inference to prediction to model evaluation.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  file = {/Users/solomonkurz/Zotero/storage/GITEJRKC/Gelman et al. - 2017 - The Prior Can Often Only Be Understood in the Cont.pdf;/Users/solomonkurz/Zotero/storage/FD2UD59C/555.html},
  journal = {Entropy},
  keywords = {Bayesian inference,default priors,prior distribution},
  language = {en},
  number = {10}
}

@book{gelmanRegressionOtherStories2020,
  title = {Regression and Other Stories},
  author = {Gelman, Andrew and Hill, Jennifer and Vehtari, Aki},
  year = {2020},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge}},
  doi = {10.1017/9781139161879},
  url = {https://www.cambridge.org/core/books/regression-and-other-stories/DD20DD6C9057118581076E54E40C372C},
  urldate = {2020-12-09},
  abstract = {Most textbooks on regression focus on theory and the simplest of examples. Real statistical problems, however, are complex and subtle. This is not a book about the theory of regression. It is about using regression to solve real problems of comparison, estimation, prediction, and causal inference. Unlike other books, it focuses on practical issues such as sample size and missing data and a wide range of goals and techniques. It jumps right in to methods and computer code you can use immediately. Real examples, real stories from the authors' experience demonstrate what regression can do and its limitations, with practical advice for understanding assumptions and implementing methods for experiments and observational studies. They make a smooth transition to logistic regression and GLM. The emphasis is on computation in R and Stan rather than derivations, with code available online. Graphics and presentation aid understanding of the models and model fitting.},
  file = {/Users/solomonkurz/Zotero/storage/GQITHSNF/DD20DD6C9057118581076E54E40C372C.html},
  isbn = {978-1-107-02398-7},
  series = {Analytical {{Methods}} for {{Social Research}}}
}

@book{grolemundDataScience2017,
  title = {R for Data Science},
  author = {Grolemund, Garrett and Wickham, Hadley},
  year = {2017},
  publisher = {{O'Reilly}},
  url = {https://r4ds.had.co.nz}
}

@article{hauserDissociationMoralJudgments2007,
  title = {A Dissociation between Moral Judgments and Justifications},
  author = {Hauser, Marc and Cushman, Fiery and Young, Liane and Jin, R. Kang-Xing and Mikhail, John},
  year = {2007},
  volume = {22},
  pages = {1--21},
  issn = {1468-0017},
  doi = {10.1111/j.1468-0017.2006.00297.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0017.2006.00297.x},
  urldate = {2020-10-16},
  abstract = {Abstract: To what extent do moral judgments depend on conscious reasoning from explicitly understood principles? We address this question by investigating one particular moral principle, the principle of the double effect. Using web-based technology, we collected a large data set on individuals' responses to a series of moral dilemmas, asking when harm to innocent others is permissible. Each moral dilemma presented a choice between action and inaction, both resulting in lives saved and lives lost. Results showed that: (1) patterns of moral judgments were consistent with the principle of double effect and showed little variation across differences in gender, age, educational level, ethnicity, religion or national affiliation (within the limited range of our sample population) and (2) a majority of subjects failed to provide justifications that could account for their judgments. These results indicate that the principle of the double effect may be operative in our moral judgments but not open to conscious introspection. We discuss these results in light of current psychological theories of moral cognition, emphasizing the need to consider the unconscious appraisal system that mentally represents the causal and intentional properties of human action.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1468-0017.2006.00297.x},
  copyright = {2007 Blackwell Publishing Ltd},
  file = {/Users/solomonkurz/Zotero/storage/XAY75L94/j.1468-0017.2006.00297.html},
  journal = {Mind \& Language},
  language = {en},
  number = {1}
}

@article{ingrahamThinkYouDrink2014,
  title = {Think You Drink a Lot? {{This}} Chart Will Tell You},
  author = {Ingraham, Christopher},
  year = {2014},
  url = {https://www.washingtonpost.com/news/wonk/wp/2014/09/25/think-you-drink-a-lot-this-chart-will-tell-you/?utm_term=.b81599bbbe25},
  journal = {Wonkblog. The Washington Post}
}

@article{josephCommentsBayesianSample1995,
  title = {Some Comments on {{Bayesian}} Sample Size Determination},
  author = {Joseph, Lawrence and Wolfson, David B. and Berger, Roxane Du},
  year = {1995},
  volume = {44},
  pages = {167--171},
  issn = {1467-9884},
  doi = {10.2307/2348442},
  url = {http://www.med.mcgill.ca/epidemiology/Joseph/publications/Methodological/ss_hpd.pdf},
  urldate = {2020-08-15},
  abstract = {Several criteria for Bayesian sample size determination have recently been proposed. Criteria based on highest posterior density (HPD) intervals from the exact posterior distribution in general lead to smaller sample sizes than those based on non-HPD intervals and/or normal approximations to the exact density. The economies are variable, however, and depend both on the prior inputs and the desired posterior accuracy and coverage probability. In our reply we review several properties of sample size methods and discuss the importance of these properties in the context of a binomial experiment. A general algorithm for Bayesian sample size determination that is useful for more complex sampling situations based on Monte Carlo simulations is briefly described.},
  annotation = {\_eprint: https://rss.onlinelibrary.wiley.com/doi/pdf/10.2307/2348442},
  copyright = {\textcopyright{} 1995 Royal Statistical Society},
  file = {/Users/solomonkurz/Zotero/storage/V3ILXR5R/2348442.html},
  journal = {Journal of the Royal Statistical Society: Series D (The Statistician)},
  language = {en},
  number = {2}
}

@article{josephSampleSizeCalculations1995,
  title = {Sample Size Calculations for Binomial Proportions via Highest Posterior Density Intervals},
  author = {Joseph, Lawrence and Wolfson, David B. and Berger, Roxane Du},
  year = {1995},
  volume = {44},
  pages = {143--154},
  issn = {1467-9884},
  doi = {10.2307/2348439},
  url = {https://www.medicine.mcgill.ca/epidemiology/Joseph/publications\%5CMethodological\%5Css_binom.pdf},
  urldate = {2020-08-15},
  abstract = {Three different Bayesian approaches to sample size calculations based on highest posterior density (HPD) intervals are discussed and illustrated in the context of a binomial experiment. The preposterior marginal distribution of the data is used to find the sample size needed to attain an expected HPD coverage probability for a given fixed interval length. Alternatively, one can find the sample size required to attain an expected HPD interval length for a fixed coverage. These two criteria can lead to different sample size requirements. In addition to averaging, a worst possible outcome scenario is also considered. The results presented here provide an exact solution to a problem recently addressed in the literature.},
  annotation = {\_eprint: https://rss.onlinelibrary.wiley.com/doi/pdf/10.2307/2348439},
  copyright = {\textcopyright{} 1995 Royal Statistical Society},
  file = {/Users/solomonkurz/Zotero/storage/QHE97GKD/2348439.html},
  journal = {Journal of the Royal Statistical Society: Series D (The Statistician)},
  keywords = {Bayesian design,Binomial proportions,Sample size calculations},
  language = {en},
  number = {2}
}

@article{kleinManyLabsInvestigating2018,
  title = {Many {{Labs}} 2: {{Investigating}} Variation in Replicability across Samples and Settings},
  shorttitle = {Many {{Labs}} 2},
  author = {Klein, Richard A. and Vianello, Michelangelo and Hasselman, Fred and Adams, Byron G. and Adams, Reginald B. and Alper, Sinan and Aveyard, Mark and Axt, Jordan R. and Babalola, Mayowa T. and Bahn{\'i}k, {\v S}t{\v e}p{\'a}n and Batra, Rishtee and Berkics, Mih{\'a}ly and Bernstein, Michael J. and Berry, Daniel R. and Bialobrzeska, Olga and Binan, Evans Dami and Bocian, Konrad and Brandt, Mark J. and Busching, Robert and R{\'e}dei, Anna Cabak and Cai, Huajian and Cambier, Fanny and Cantarero, Katarzyna and Carmichael, Cheryl L. and Ceric, Francisco and Chandler, Jesse and Chang, Jen-Ho and Chatard, Armand and Chen, Eva E. and Cheong, Winnee and Cicero, David C. and Coen, Sharon and Coleman, Jennifer A. and Collisson, Brian and Conway, Morgan A. and Corker, Katherine S. and Curran, Paul G. and Cushman, Fiery and Dagona, Zubairu K. and Dalgar, Ilker and Dalla Rosa, Anna and Davis, William E. and {de Bruijn}, Maaike and De Schutter, Leander and Devos, Thierry and {de Vries}, Marieke and Do{\u g}ulu, Canay and Dozo, Nerisa and Dukes, Kristin Nicole and Dunham, Yarrow and Durrheim, Kevin and Ebersole, Charles R. and Edlund, John E. and Eller, Anja and English, Alexander Scott and Finck, Carolyn and Frankowska, Natalia and Freyre, Miguel-{\'A}ngel and Friedman, Mike and Galliani, Elisa Maria and Gandi, Joshua C. and Ghoshal, Tanuka and Giessner, Steffen R. and Gill, Tripat and Gnambs, Timo and G{\'o}mez, {\'A}ngel and Gonz{\'a}lez, Roberto and Graham, Jesse and Grahe, Jon E. and Grahek, Ivan and Green, Eva G. T. and Hai, Kakul and Haigh, Matthew and Haines, Elizabeth L. and Hall, Michael P. and Heffernan, Marie E. and Hicks, Joshua A. and Houdek, Petr and Huntsinger, Jeffrey R. and Huynh, Ho Phi and IJzerman, Hans and Inbar, Yoel and {Innes-Ker}, {\AA}se H. and {Jim{\'e}nez-Leal}, William and John, Melissa-Sue and {Joy-Gaba}, Jennifer A. and Kamilo{\u g}lu, Roza G. and Kappes, Heather Barry and Karabati, Serdar and Karick, Haruna and Keller, Victor N. and Kende, Anna and Kervyn, Nicolas and Kne{\v z}evi{\'c}, Goran and Kovacs, Carrie and Krueger, Lacy E. and Kurapov, German and Kurtz, Jamie and Lakens, Dani{\"e}l and Lazarevi{\'c}, Ljiljana B. and Levitan, Carmel A. and Lewis, Neil A. and Lins, Samuel and Lipsey, Nikolette P. and Losee, Joy E. and Maassen, Esther and Maitner, Angela T. and Malingumu, Winfrida and Mallett, Robyn K. and Marotta, Satia A. and Me{\dj}edovi{\'c}, Janko and {Mena-Pacheco}, Fernando and Milfont, Taciano L. and Morris, Wendy L. and Murphy, Sean C. and Myachykov, Andriy and Neave, Nick and Neijenhuijs, Koen and Nelson, Anthony J. and Neto, F{\'e}lix and Lee Nichols, Austin and Ocampo, Aaron and O'Donnell, Susan L. and Oikawa, Haruka and Oikawa, Masanori and Ong, Elsie and Orosz, G{\'a}bor and Osowiecka, Malgorzata and Packard, Grant and {P{\'e}rez-S{\'a}nchez}, Rolando and Petrovi{\'c}, Boban and Pilati, Ronaldo and Pinter, Brad and Podesta, Lysandra and Pogge, Gabrielle and Pollmann, Monique M. H. and Rutchick, Abraham M. and Saavedra, Patricio and Saeri, Alexander K. and Salomon, Erika and Schmidt, Kathleen and Sch{\"o}nbrodt, Felix D. and Sekerdej, Maciej B. and Sirlop{\'u}, David and Skorinko, Jeanine L. M. and Smith, Michael A. and {Smith-Castro}, Vanessa and Smolders, Karin C. H. J. and Sobkow, Agata and Sowden, Walter and Spachtholz, Philipp and Srivastava, Manini and Steiner, Troy G. and Stouten, Jeroen and Street, Chris N. H. and Sundfelt, Oskar K. and Szeto, Stephanie and Szumowska, Ewa and Tang, Andrew C. W. and Tanzer, Norbert and Tear, Morgan J. and Theriault, Jordan and Thomae, Manuela and Torres, David and Traczyk, Jakub and Tybur, Joshua M. and Ujhelyi, Adrienn and {van Aert}, Robbie C. M. and {van Assen}, Marcel A. L. M. and {van der Hulst}, Marije and {van Lange}, Paul A. M. and {van 't Veer}, Anna Elisabeth and {V{\'a}squez- Echeverr{\'i}a}, Alejandro and Ann Vaughn, Leigh and V{\'a}zquez, Alexandra and Vega, Luis Diego and Verniers, Catherine and Verschoor, Mark and Voermans, Ingrid P. J. and Vranka, Marek A. and Welch, Cheryl and Wichman, Aaron L. and Williams, Lisa A. and Wood, Michael and Woodzicka, Julie A. and Wronska, Marta K. and Young, Liane and Zelenski, John M. and Zhijia, Zeng and Nosek, Brian A.},
  year = {2018},
  month = dec,
  volume = {1},
  pages = {443--490},
  publisher = {{SAGE Publications Inc}},
  issn = {2515-2459},
  doi = {10.1177/2515245918810225},
  url = {https://doi.org/10.1177/2515245918810225},
  urldate = {2020-10-16},
  abstract = {We conducted preregistered replications of 28 classic and contemporary published findings, with protocols that were peer reviewed in advance, to examine variation in effect magnitudes across samples and settings. Each protocol was administered to approximately half of 125 samples that comprised 15,305 participants from 36 countries and territories. Using the conventional criterion of statistical significance (p {$<$} .05), we found that 15 (54\%) of the replications provided evidence of a statistically significant effect in the same direction as the original finding. With a strict significance criterion (p {$<$} .0001), 14 (50\%) of the replications still provided such evidence, a reflection of the extremely high-powered design. Seven (25\%) of the replications yielded effect sizes larger than the original ones, and 21 (75\%) yielded effect sizes smaller than the original ones. The median comparable Cohen's ds were 0.60 for the original findings and 0.15 for the replications. The effect sizes were small ({$<$} 0.20) in 16 of the replications (57\%), and 9 effects (32\%) were in the direction opposite the direction of the original effect. Across settings, the Q statistic indicated significant heterogeneity in 11 (39\%) of the replication effects, and most of those were among the findings with the largest overall effect sizes; only 1 effect that was near zero in the aggregate showed significant heterogeneity according to this measure. Only 1 effect had a tau value greater than .20, an indication of moderate heterogeneity. Eight others had tau values near or slightly above .10, an indication of slight heterogeneity. Moderation tests indicated that very little heterogeneity was attributable to the order in which the tasks were performed or whether the tasks were administered in lab versus online. Exploratory comparisons revealed little heterogeneity between Western, educated, industrialized, rich, and democratic (WEIRD) cultures and less WEIRD cultures (i.e., cultures with relatively high and low WEIRDness scores, respectively). Cumulatively, variability in the observed effect sizes was attributable more to the effect being studied than to the sample or setting in which it was studied.},
  file = {/Users/solomonkurz/Zotero/storage/K6K35TFW/Klein et al. - 2018 - Many Labs 2 Investigating Variation in Replicabil.pdf},
  journal = {Advances in Methods and Practices in Psychological Science},
  language = {en},
  number = {4}
}

@book{kruschkeDoingBayesianData2015,
  title = {Doing {{Bayesian}} Data Analysis: {{A}} Tutorial with {{R}}, {{JAGS}}, and {{Stan}}},
  author = {Kruschke, John K.},
  year = {2015},
  publisher = {{Academic Press}},
  url = {https://sites.google.com/site/doingbayesiandataanalysis/}
}

@book{kurzDoingBayesianData2020,
  title = {Doing {{Bayesian}} Data Analysis in Brms and the Tidyverse},
  author = {Kurz, A. Solomon},
  year = {2020},
  month = may,
  edition = {version 0.3.0},
  url = {https://bookdown.org/content/3686/},
  urldate = {2020-05-22},
  abstract = {This project is an attempt to re-express the code in Kruschke's (2015) textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style.},
  file = {/Users/solomonkurz/Zotero/storage/UKHWZ73Z/3686.html}
}

@book{kurzStatisticalRethinkingBrms2020,
  title = {Statistical Rethinking with Brms, Ggplot2, and the Tidyverse},
  author = {Kurz, A. Solomon},
  year = {2020},
  month = mar,
  edition = {version 1.2.0},
  doi = {10.5281/zenodo.3693202},
  url = {https://bookdown.org/content/3890/},
  urldate = {2020-05-16},
  abstract = {This project is an attempt to re-express the code in McElreath's textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style.},
  file = {/Users/solomonkurz/Zotero/storage/MTCXZRHZ/3890.html}
}

@book{kurzStatisticalRethinkingSecondEd2020,
  title = {Statistical Rethinking with Brms, Ggplot2, and the Tidyverse: {{Second}} Edition},
  author = {Kurz, A. Solomon},
  year = {2020},
  month = jun,
  edition = {version 0.1.1},
  url = {https://bookdown.org/content/4857/},
  urldate = {2020-06-30},
  abstract = {This book is an attempt to re-express the code in the second edition of McElreath's textbook, 'Statistical rethinking.' His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style.}
}

@book{loo2020RM,
  title = {{{loo}} Reference Manual, {{Version}} 2.3.1},
  author = {Vehtari, Aki and Gabry, Jonah and Magnusson, Mans and Yao, Yuling and B{\"u}rkner, Paul-Christian and Paananen, Topi and Gelman, Andrew},
  year = {2020},
  month = jul,
  url = {https://CRAN.R-project.org/package=loo/loo.pdf}
}

@article{maxwellSampleSizePlanning2008,
  title = {Sample Size Planning for Statistical Power and Accuracy in Parameter Estimation},
  author = {Maxwell, Scott E. and Kelley, Ken and Rausch, Joseph R.},
  year = {2008},
  volume = {59},
  pages = {537--563},
  doi = {10.1146/annurev.psych.59.103006.093735},
  url = {https://www3.nd.edu/~kkelley/publications/articles/Maxwell_Kelley_Rausch_2008.pdf},
  urldate = {2020-08-14},
  abstract = {This review examines recent advances in sample size planning, not only from the perspective of an individual researcher, but also with regard to the goal of developing cumulative knowledge. Psychologists have traditionally thought of sample size planning in terms of power analysis. Although we review recent advances in power analysis, our main focus is the desirability of achieving accurate parameter estimates, either instead of or in addition to obtaining sufficient power. Accuracy in parameter estimation (AIPE) has taken on increasing importance in light of recent emphasis on effect size estimation and formation of confidence intervals. The review provides an overview of the logic behind sample size planning for AIPE and summarizes recent advances in implementing this approach in designs commonly used in psychological research.},
  annotation = {\_eprint: https://doi.org/10.1146/annurev.psych.59.103006.093735},
  file = {/Users/solomonkurz/Zotero/storage/A3Q2R3HH/Maxwell et al. - 2008 - Sample Size Planning for Statistical Power and Acc.pdf},
  journal = {Annual Review of Psychology},
  number = {1},
  pmid = {17937603}
}

@book{mcelreathStatisticalRethinkingBayesian2015,
  title = {Statistical Rethinking: {{A Bayesian}} Course with Examples in {{R}} and {{Stan}}},
  author = {McElreath, Richard},
  year = {2015},
  publisher = {{CRC press}},
  url = {https://xcelab.net/rm/statistical-rethinking/}
}

@book{mcelreathStatisticalRethinkingBayesian2020,
  title = {Statistical Rethinking: {{A Bayesian}} Course with Examples in {{R}} and {{Stan}}},
  shorttitle = {Statistical {{Rethinking}}},
  author = {McElreath, Richard},
  year = {2020},
  month = mar,
  edition = {Second Edition},
  publisher = {{CRC Press}},
  url = {https://xcelab.net/rm/statistical-rethinking/},
  abstract = {Statistical Rethinking: A Bayesian Course with Examples in R and Stan builds your knowledge of and confidence in making inferences from data. Reflecting the need for scripting in today's model-based statistics, the book pushes you to perform step-by-step calculations that are usually automated. This unique computational approach ensures that you understand enough of the details to make reasonable choices and interpretations in your own modeling work.  The text presents causal inference and generalized linear multilevel models from a simple Bayesian perspective that builds on information theory and maximum entropy. The core material ranges from the basics of regression to advanced multilevel models. It also presents measurement error, missing data, and Gaussian process models for spatial and phylogenetic confounding.  The second edition emphasizes the directed acyclic graph (DAG) approach to causal inference, integrating DAGs into many examples. The new edition also contains new material on the design of prior distributions, splines, ordered categorical predictors, social relations models, cross-validation, importance sampling, instrumental variables, and Hamiltonian Monte Carlo. It ends with an entirely new chapter that goes beyond generalized linear modeling, showing how domain-specific scientific models can be built into statistical analyses.  Features   Integrates working code into the main text   Illustrates concepts through worked data analysis examples   Emphasizes understanding assumptions and how assumptions are reflected in code   Offers more detailed explanations of the mathematics in optional sections   Presents examples of using the dagitty R package to analyze causal graphs   Provides the rethinking R package on the author's website and on GitHub},
  isbn = {978-0-429-63914-2},
  keywords = {Mathematics / Probability \& Statistics / General},
  language = {en}
}

@article{moreyBayesFactorApproaches2011,
  title = {Bayes Factor Approaches for Testing Interval Null Hypotheses},
  author = {Morey, Richard D. and Rouder, Jeffrey N.},
  year = {2011},
  volume = {16},
  pages = {406--419},
  doi = {10.1037/a0024377},
  url = {https://d1wqtxts1xzle7.cloudfront.net/45416179/Bayes_Factor_Approaches_for_Testing_Inte20160506-23207-1t89l96.pdf?1462571611=\&response-content-disposition=inline\%3B+filename\%3DBayes_factor_approaches_for_testing_inte.pdf\&Expires=1597530412\&Signature=QAJQOISIvwxUlHd2uTfzgOMzf2TRcuWTcfwgki7JL4AIoYDziVCAfmDFOgUDi-h1mMEViTKFhOLTJF0-9u2IEyF2lR7-yhM67CYdKhqs8EEJOnhT9iK9MaaM2FBwZM8QoVtOXkOUaOXRHIt7C76UV5dbErTUx0r5Y1yym4a~-hDClb0696a6EB~dj0arYeDdylP7a3tfczmSxbIvrH8pOE4kQeHwsZXoANSh-eKXKYIYf6VD1yed~CSVPRkqlhMq6udOjg4INPZ33QBv3QQqYCk2esRC2DxxNmDF~rRVrIp0ebr6VMZkuMflVaj2~I2BFz7WS32Lb2hGFHT3jHskDA__\&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA},
  journal = {Psychological Methods},
  number = {4}
}

@article{niaaaNationalEpidemiologicSurvey2006,
  title = {National Epidemiologic Survey on Alcohol and Related Conditions},
  author = {{\{\{National Institute on Alcohol Abuse and Alcoholism\}\}}},
  year = {2006},
  publisher = {{National Institutes of Health Washington, DC}},
  url = {https://pubs.niaaa.nih.gov/publications/AA70/AA70.htm}
}

@book{pengProgrammingDataScience2019,
  title = {R Programming for Data Science},
  author = {Peng, Roger D.},
  year = {2019},
  url = {https://bookdown.org/rdpeng/rprogdatascience/}
}

@manual{R-baggr,
  title = {{{baggr}}: {{Bayesian}} Aggregate Treatment Effects},
  author = {Wiecek, Witold and Meager, Rachael},
  year = {2020},
  url = {https://CRAN.R-project.org/package=baggr},
  type = {Manual}
}

@book{R-base,
  title = {R: {{A}} Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  year = {2020},
  publisher = {{R Foundation for Statistical Computing}},
  address = {{Vienna, Austria}},
  url = {https://www.R-project.org/}
}

@book{R-brms,
  title = {{{brms}}: {{Bayesian}} Regression Models Using '{{Stan}}'},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2020},
  url = {https://CRAN.R-project.org/package=brms}
}

@manual{R-broom,
  title = {{{broom}}: {{Convert}} Statistical Analysis Objects into Tidy Tibbles},
  author = {Robinson, David and Hayes, Alex},
  year = {2020},
  url = {https://CRAN.R-project.org/package=broom},
  type = {Manual}
}

@book{R-loo,
  title = {{{loo}}: {{Efficient}} Leave-One-out Cross-Validation and {{WAIC}} for Bayesian Models},
  author = {Vehtari, Aki and Gabry, Jonah and Magnusson, Mans and Yao, Yuling and Gelman, Andrew},
  year = {2019},
  url = {https://CRAN.R-project.org/package=loo/}
}

@book{R-MASS,
  title = {{{MASS}}: {{Support}} Functions and Datasets for Venables and Ripley's {{MASS}}},
  author = {Ripley, Brian},
  year = {2019},
  url = {https://CRAN.R-project.org/package=MASS}
}

@book{R-patchwork,
  title = {{{patchwork}}: {{The}} Composer of Plots},
  author = {Pedersen, Thomas Lin},
  year = {2019},
  url = {https://CRAN.R-project.org/package=patchwork}
}

@book{R-rethinking,
  title = {{{rethinking}} {{R}} Package},
  author = {McElreath, Richard},
  year = {2020},
  url = {https://xcelab.net/rm/software/}
}

@book{R-tidybayes,
  title = {{{tidybayes}}: {{Tidy}} Data and 'geoms' for {{Bayesian}} Models},
  author = {Kay, Matthew},
  year = {2020},
  url = {http://mjskay.github.io/tidybayes}
}

@book{R-tidyverse,
  title = {{{tidyverse}}: {{Easily}} Install and Load the 'Tidyverse'},
  author = {Wickham, Hadley},
  year = {2019},
  url = {https://CRAN.R-project.org/package=tidyverse}
}

@article{rouderBayesianTestsAccepting2009,
  title = {Bayesian t Tests for Accepting and Rejecting the Null Hypothesis},
  author = {Rouder, Jeffrey N. and Speckman, Paul L. and Sun, Dongchu and Morey, Richard D. and Iverson, Geoffrey},
  year = {2009},
  month = apr,
  volume = {16},
  pages = {225--237},
  issn = {1531-5320},
  doi = {10.3758/PBR.16.2.225},
  url = {https://doi.org/10.3758/PBR.16.2.225},
  urldate = {2020-08-15},
  abstract = {Progress in science often comes from discovering invariances in relationships among variables; these invariances often correspond to null hypotheses. As is commonly known, it is not possible to state evidence for the null hypothesis in conventional significance testing. Here we highlight a Bayes factor alternative to the conventional t test that will allow researchers to express preference for either the null hypothesis or the alternative. The Bayes factor has a natural and straightforward interpretation, is based on reasonable assumptions, and has better properties than other methods of inference that have been advocated in the psychological literature. To facilitate use of the Bayes factor, we provide an easy-to-use, Web-based program that performs the necessary calculations.},
  file = {/Users/solomonkurz/Zotero/storage/2WAUSYVQ/Rouder et al. - 2009 - Bayesian t tests for accepting and rejecting the n.pdf},
  journal = {Psychonomic Bulletin \& Review},
  language = {en},
  number = {2}
}

@misc{standevelopmentteamRStanInterfaceStan2020,
  title = {{{RStan}}: The {{R}} Interface to {{Stan}}},
  author = {{Stan Development Team}},
  year = {2020},
  month = feb,
  url = {https://cran.r-project.org/web/packages/rstan/vignettes/rstan.html},
  urldate = {2020-05-22},
  file = {/Users/solomonkurz/Zotero/storage/UNLVDTJP/rstan.html}
}

@book{standevelopmentteamStanReferenceManual2020,
  title = {Stan Reference Manual, {{Version}} 2.25},
  author = {{Stan Development Team}},
  year = {2020},
  url = {https://mc-stan.org/docs/2_25/reference-manual/}
}

@book{standevelopmentteamStanUserGuide2020,
  title = {Stan User's Guide, {{Version}} 2.25},
  author = {{Stan Development Team}},
  year = {2020},
  url = {https://mc-stan.org/docs/2_25/stan-users-guide/index.html}
}

@article{vehtariPracticalBayesianModel2017,
  title = {Practical {{Bayesian}} Model Evaluation Using Leave-One-out Cross-Validation and {{WAIC}}},
  author = {Vehtari, Aki and Gelman, Andrew and Gabry, Jonah},
  year = {2017},
  month = sep,
  volume = {27},
  pages = {1413--1432},
  issn = {1573-1375},
  doi = {10.1007/s11222-016-9696-4},
  url = {https://arxiv.org/pdf/1507.04544.pdf},
  urldate = {2020-06-03},
  abstract = {Leave-one-out cross-validation (LOO) and the widely applicable information criterion (WAIC) are methods for estimating pointwise out-of-sample prediction accuracy from a fitted Bayesian model using the log-likelihood evaluated at the posterior simulations of the parameter values. LOO and WAIC have various advantages over simpler estimates of predictive error such as AIC and DIC but are less used in practice because they involve additional computational steps. Here we lay out fast and stable computations for LOO and WAIC that can be performed using existing simulation draws. We introduce an efficient computation of LOO using Pareto-smoothed importance sampling (PSIS), a new procedure for regularizing importance weights. Although WAIC is asymptotically equal to LOO, we demonstrate that PSIS-LOO is more robust in the finite case with weak priors or influential observations. As a byproduct of our calculations, we also obtain approximate standard errors for estimated predictive errors and for comparison of predictive errors between two models. We implement the computations in an R package called loo and demonstrate using models fit with the Bayesian inference package Stan.},
  file = {/Users/solomonkurz/Zotero/storage/I7HY567V/Vehtari et al. - 2017 - Practical Bayesian model evaluation using leave-on.pdf},
  journal = {Statistics and Computing},
  language = {en},
  number = {5}
}

@misc{vehtariUsingLooPackage2020,
  title = {Using the Loo Package (Version {$>$}= 2.0.0)},
  author = {Vehtari, Aki and Gabry, Jonah},
  year = {2020},
  month = jul,
  url = {https://CRAN.R-project.org/package=loo/vignettes/loo2-example.html},
  urldate = {2020-09-15},
  file = {/Users/solomonkurz/Zotero/storage/QQ6SLVSV/loo2-example.html}
}

@article{wassersteinMovingWorld052019,
  title = {Moving to a {{World Beyond}} ``p {$<$} 0.05''},
  author = {Wasserstein, Ronald L. and Schirm, Allen L. and Lazar, Nicole A.},
  year = {2019},
  month = mar,
  volume = {73},
  pages = {1--19},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1080/00031305.2019.1583913},
  url = {https://doi.org/10.1080/00031305.2019.1583913},
  urldate = {2020-08-15},
  annotation = {\_eprint: https://doi.org/10.1080/00031305.2019.1583913},
  file = {/Users/solomonkurz/Zotero/storage/JSNMWIEI/Wasserstein et al. - 2019 - Moving to a World Beyond âp  0.05â.pdf;/Users/solomonkurz/Zotero/storage/GPI57NZ4/00031305.2019.html},
  journal = {The American Statistician},
  number = {sup1}
}

@book{wickhamTidyverseStyleGuide2020,
  title = {The Tidyverse Style Guide},
  author = {Wickham, Hadley},
  year = {2020},
  url = {https://style.tidyverse.org/}
}

@article{wickhamWelcomeTidyverse2019,
  title = {Welcome to the Tidyverse},
  author = {Wickham, Hadley and Averick, Mara and Bryan, Jennifer and Chang, Winston and McGowan, Lucy D'Agostino and Fran{\c c}ois, Romain and Grolemund, Garrett and Hayes, Alex and Henry, Lionel and Hester, Jim and Kuhn, Max and Pedersen, Thomas Lin and Miller, Evan and Bache, Stephan Milton and M{\"u}ller, Kirill and Ooms, Jeroen and Robinson, David and Seidel, Dana Paige and Spinu, Vitalie and Takahashi, Kohske and Vaughan, Davis and Wilke, Claus and Woo, Kara and Yutani, Hiroaki},
  year = {2019},
  volume = {4},
  pages = {1686},
  doi = {10.21105/joss.01686},
  journal = {Journal of Open Source Software},
  number = {43}
}

@article{williamsBayesianMetaanalysisWeakly2018,
  title = {Bayesian Meta-Analysis with Weakly Informative Prior Distributions},
  author = {Williams, Donald R. and Rast, Philippe and B{\"u}rkner, Paul-Christian},
  year = {2018},
  month = jan,
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/7tbrm},
  url = {https://psyarxiv.com/7tbrm/},
  urldate = {2020-10-11},
  abstract = {Developing meta-analytic methods is an important goal for psychological science. When there are few studies in particular, commonly used methods have several limitations, most notably of which is underestimating between-study variability. Although Bayesian methods are often recommended for small sample situations, their performance has not been thoroughly examined in the context of meta-analysis. Here, we characterize and apply weakly informative priors for estimating meta-analytic models and demonstrate with extensive simulations that fully Bayesian methods overcome boundary estimates of exactly zero between-study variance, better maintain error rates, and have lower frequentist risk according to Kullback-Leibler divergence. While our results show that combining evidence with few studies is non-trivial, we argue that this is an important goal that deserves further consideration in psychology. Further, we suggest that frequentist properties can provide important information for Bayesian modeling. We conclude with meta-analytic guidelines for applied researchers that can be implemented with the provided computer code.}
}

@article{yaoUsingStackingAverage2018,
  title = {Using Stacking to Average {{Bayesian}} Predictive Distributions (with Discussion)},
  author = {Yao, Yuling and Vehtari, Aki and Simpson, Daniel and Gelman, Andrew},
  year = {2018},
  volume = {13},
  pages = {917--1007},
  publisher = {{International Society for Bayesian Analysis}},
  doi = {10.1214/17-BA1091},
  url = {https://projecteuclid.org/download/pdfview_1/euclid.ba/1516093227},
  journal = {Bayesian Analysis},
  number = {3}
}


